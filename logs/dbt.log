2023-06-25 01:02:30.749371 (MainThread): Running with dbt=0.16.0
2023-06-25 01:02:30.787403 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=['+transformations.transform_data'], partial_parse=None, profile=None, profiles_dir='C:\\Users\\Me\\.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2023-06-25 01:02:30.787917 (MainThread): Tracking: tracking
2023-06-25 01:02:30.788402 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020E034A2208>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020E034AD860>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020E034ADDA0>]}
2023-06-25 01:02:30.799901 (MainThread): Partial parsing not enabled
2023-06-25 01:02:30.802401 (MainThread): Parsing macros\core.sql
2023-06-25 01:02:30.805901 (MainThread): Parsing macros\adapters\common.sql
2023-06-25 01:02:30.837371 (MainThread): Parsing macros\etc\datetime.sql
2023-06-25 01:02:30.844372 (MainThread): Parsing macros\etc\get_custom_alias.sql
2023-06-25 01:02:30.844871 (MainThread): Parsing macros\etc\get_custom_database.sql
2023-06-25 01:02:30.845871 (MainThread): Parsing macros\etc\get_custom_schema.sql
2023-06-25 01:02:30.847371 (MainThread): Parsing macros\etc\get_relation_comment.sql
2023-06-25 01:02:30.848871 (MainThread): Parsing macros\etc\is_incremental.sql
2023-06-25 01:02:30.850371 (MainThread): Parsing macros\etc\query.sql
2023-06-25 01:02:30.851372 (MainThread): Parsing macros\materializations\helpers.sql
2023-06-25 01:02:30.856871 (MainThread): Parsing macros\materializations\common\merge.sql
2023-06-25 01:02:30.866871 (MainThread): Parsing macros\materializations\incremental\helpers.sql
2023-06-25 01:02:30.868371 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2023-06-25 01:02:30.872871 (MainThread): Parsing macros\materializations\seed\seed.sql
2023-06-25 01:02:30.888371 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2023-06-25 01:02:30.913400 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2023-06-25 01:02:30.914401 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2023-06-25 01:02:30.926871 (MainThread): Parsing macros\materializations\table\table.sql
2023-06-25 01:02:30.932371 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2023-06-25 01:02:30.935871 (MainThread): Parsing macros\materializations\view\view.sql
2023-06-25 01:02:30.940871 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2023-06-25 01:02:30.942371 (MainThread): Parsing macros\schema_tests\not_null.sql
2023-06-25 01:02:30.942872 (MainThread): Parsing macros\schema_tests\relationships.sql
2023-06-25 01:02:30.943871 (MainThread): Parsing macros\schema_tests\unique.sql
2023-06-25 01:02:30.945371 (MainThread): Parsing macros\adapters.sql
2023-06-25 01:02:30.958371 (MainThread): Parsing macros\catalog.sql
2023-06-25 01:02:30.959871 (MainThread): Parsing macros\relations.sql
2023-06-25 01:02:30.961370 (MainThread): Parsing macros\materializations\snapshot_merge.sql
2023-06-25 01:02:30.973871 (MainThread): Partial parsing not enabled
2023-06-25 01:02:30.992371 (MainThread): Acquiring new postgres connection "model.transform_data.transform_data".
2023-06-25 01:02:30.992371 (MainThread): Opening a new connection, currently in state init
2023-06-25 01:02:31.036814 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020E037032E8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020E036E6908>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020E036CDA20>]}
2023-06-25 01:02:31.036814 (MainThread): Flushing usage events
2023-06-25 01:02:31.247184 (MainThread): Connection 'model.transform_data.transform_data' was properly closed.
2023-06-25 01:02:31.247184 (MainThread): Encountered an error:
2023-06-25 01:02:31.247184 (MainThread): Compilation Error in model transform_data (models\transformations\transform_data.sql)
  Model 'model.transform_data.transform_data' depends on a node named 'extract_data' which was not found or is disabled
2023-06-25 01:02:31.248713 (MainThread): Traceback (most recent call last):
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\main.py", line 81, in main
    results, succeeded = handle_and_check(args)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\main.py", line 159, in handle_and_check
    task, res = run_from_args(parsed)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\main.py", line 212, in run_from_args
    results = task.run()
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\task\runnable.py", line 351, in run
    self._runtime_initialize()
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\task\runnable.py", line 107, in _runtime_initialize
    super()._runtime_initialize()
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\task\runnable.py", line 75, in _runtime_initialize
    self.load_manifest()
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\task\runnable.py", line 63, in load_manifest
    self.manifest = get_full_manifest(self.config)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\perf_utils.py", line 23, in get_full_manifest
    return load_manifest(config, internal, set_header)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\parser\manifest.py", line 646, in load_manifest
    return ManifestLoader.load_all(config, internal_manifest, macro_hook)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\parser\manifest.py", line 338, in load_all
    manifest = loader.create_manifest()
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\parser\manifest.py", line 323, in create_manifest
    self.process_manifest(manifest)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\parser\manifest.py", line 302, in process_manifest
    process_refs(manifest, project_name)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\parser\manifest.py", line 553, in process_refs
    _process_refs_for_node(manifest, current_project, node)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\parser\manifest.py", line 534, in _process_refs_for_node
    disabled=(isinstance(target_model, Disabled))
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\utils.py", line 338, in invalid_ref_fail_unless_test
    target_model_package)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\exceptions.py", line 488, in ref_target_not_found
    raise_compiler_error(msg, model)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\exceptions.py", line 363, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model transform_data (models\transformations\transform_data.sql)
  Model 'model.transform_data.transform_data' depends on a node named 'extract_data' which was not found or is disabled

2023-06-25 01:07:13.860133 (MainThread): Running with dbt=0.16.0
2023-06-25 01:07:13.897636 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=['+transformations.transform_data'], partial_parse=None, profile=None, profiles_dir='C:\\Users\\Me\\.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2023-06-25 01:07:13.898136 (MainThread): Tracking: tracking
2023-06-25 01:07:13.898636 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EE66831978>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EE6683DFD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EE6683DB38>]}
2023-06-25 01:07:13.910136 (MainThread): Partial parsing not enabled
2023-06-25 01:07:13.913136 (MainThread): Parsing macros\core.sql
2023-06-25 01:07:13.916636 (MainThread): Parsing macros\adapters\common.sql
2023-06-25 01:07:13.948136 (MainThread): Parsing macros\etc\datetime.sql
2023-06-25 01:07:13.955136 (MainThread): Parsing macros\etc\get_custom_alias.sql
2023-06-25 01:07:13.956136 (MainThread): Parsing macros\etc\get_custom_database.sql
2023-06-25 01:07:13.957136 (MainThread): Parsing macros\etc\get_custom_schema.sql
2023-06-25 01:07:13.958636 (MainThread): Parsing macros\etc\get_relation_comment.sql
2023-06-25 01:07:13.960136 (MainThread): Parsing macros\etc\is_incremental.sql
2023-06-25 01:07:13.961636 (MainThread): Parsing macros\etc\query.sql
2023-06-25 01:07:13.962136 (MainThread): Parsing macros\materializations\helpers.sql
2023-06-25 01:07:13.968136 (MainThread): Parsing macros\materializations\common\merge.sql
2023-06-25 01:07:13.978135 (MainThread): Parsing macros\materializations\incremental\helpers.sql
2023-06-25 01:07:13.979635 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2023-06-25 01:07:13.984136 (MainThread): Parsing macros\materializations\seed\seed.sql
2023-06-25 01:07:14.000136 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2023-06-25 01:07:14.025635 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2023-06-25 01:07:14.027136 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2023-06-25 01:07:14.039635 (MainThread): Parsing macros\materializations\table\table.sql
2023-06-25 01:07:14.045136 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2023-06-25 01:07:14.048635 (MainThread): Parsing macros\materializations\view\view.sql
2023-06-25 01:07:14.053635 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2023-06-25 01:07:14.055136 (MainThread): Parsing macros\schema_tests\not_null.sql
2023-06-25 01:07:14.055636 (MainThread): Parsing macros\schema_tests\relationships.sql
2023-06-25 01:07:14.056636 (MainThread): Parsing macros\schema_tests\unique.sql
2023-06-25 01:07:14.058136 (MainThread): Parsing macros\adapters.sql
2023-06-25 01:07:14.071138 (MainThread): Parsing macros\catalog.sql
2023-06-25 01:07:14.073635 (MainThread): Parsing macros\relations.sql
2023-06-25 01:07:14.075136 (MainThread): Parsing macros\materializations\snapshot_merge.sql
2023-06-25 01:07:14.087636 (MainThread): Partial parsing not enabled
2023-06-25 01:07:14.107136 (MainThread): Acquiring new postgres connection "model.transform_data.transform_data".
2023-06-25 01:07:14.107136 (MainThread): Opening a new connection, currently in state init
2023-06-25 01:07:14.267636 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:07:14.267636 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:07:14.267636 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:07:14.267636 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:07:14.268136 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:07:14.268136 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:07:14.268136 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:07:14.269637 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:07:14.270636 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:07:14.271136 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:07:14.273637 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:07:14.274636 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:07:14.275636 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:07:14.276136 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:07:14.277636 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:07:14.278136 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:07:14.279136 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:07:14.280137 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:07:14.281137 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:07:14.282137 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:07:14.283137 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:07:14.286136 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:07:14.290137 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:07:14.291136 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:07:14.292637 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:07:14.293637 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:07:14.294636 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:07:14.304137 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:07:14.308136 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:07:14.308136 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:07:14.310136 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:07:14.328637 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:07:14.329637 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:07:14.332137 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:07:14.368636 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:07:14.373636 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:07:14.374636 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:07:14.389136 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:07:14.391636 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:07:14.409137 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:07:14.410637 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:07:14.426137 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:07:14.445636 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:07:14.446636 (MainThread): scipy not found, skipping conversion test.
2023-06-25 01:07:14.447636 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2023-06-25 01:07:14.448136 (MainThread): Found 1 model, 0 tests, 0 snapshots, 0 analyses, 127 macros, 0 operations, 0 seed files, 0 sources
2023-06-25 01:07:14.448636 (MainThread): 
2023-06-25 01:07:14.449136 (MainThread): Acquiring new postgres connection "master".
2023-06-25 01:07:14.449136 (MainThread): Opening a new connection, currently in state init
2023-06-25 01:07:14.452667 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2023-06-25 01:07:14.452667 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2023-06-25 01:07:14.509134 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2023-06-25 01:07:14.509134 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2023-06-25 01:07:14.540419 (ThreadPoolExecutor-0_0): SQL status: SELECT 5 in 0.03 seconds
2023-06-25 01:07:14.545423 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_myschema".
2023-06-25 01:07:14.545923 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2023-06-25 01:07:14.546921 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_myschema".
2023-06-25 01:07:14.546921 (ThreadPoolExecutor-1_0): On list_postgres_myschema: BEGIN
2023-06-25 01:07:14.574483 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.03 seconds
2023-06-25 01:07:14.574483 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_myschema".
2023-06-25 01:07:14.574483 (ThreadPoolExecutor-1_0): On list_postgres_myschema: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_postgres_myschema"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'myschema'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'myschema'
  
2023-06-25 01:07:14.577984 (ThreadPoolExecutor-1_0): SQL status: SELECT 3 in 0.00 seconds
2023-06-25 01:07:14.580012 (ThreadPoolExecutor-1_0): On list_postgres_myschema: ROLLBACK
2023-06-25 01:07:14.585484 (MainThread): Using postgres connection "master".
2023-06-25 01:07:14.585484 (MainThread): On master: BEGIN
2023-06-25 01:07:14.615983 (MainThread): SQL status: BEGIN in 0.03 seconds
2023-06-25 01:07:14.615983 (MainThread): Using postgres connection "master".
2023-06-25 01:07:14.615983 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2023-06-25 01:07:14.620484 (MainThread): SQL status: SELECT 1 in 0.00 seconds
2023-06-25 01:07:14.621484 (MainThread): On master: ROLLBACK
2023-06-25 01:07:14.621484 (MainThread): Using postgres connection "master".
2023-06-25 01:07:14.621984 (MainThread): On master: BEGIN
2023-06-25 01:07:14.621984 (MainThread): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:07:14.621984 (MainThread): On master: COMMIT
2023-06-25 01:07:14.621984 (MainThread): Using postgres connection "master".
2023-06-25 01:07:14.621984 (MainThread): On master: COMMIT
2023-06-25 01:07:14.622484 (MainThread): SQL status: COMMIT in 0.00 seconds
2023-06-25 01:07:14.622484 (MainThread): 21:07:14 | Concurrency: 1 threads (target='dev')
2023-06-25 01:07:14.622484 (MainThread): 21:07:14 | 
2023-06-25 01:07:14.623984 (Thread-1): Began running node model.transform_data.transform_data
2023-06-25 01:07:14.624484 (Thread-1): 21:07:14 | 1 of 1 START view model myschema.transform_data...................... [RUN]
2023-06-25 01:07:14.624484 (Thread-1): Acquiring new postgres connection "model.transform_data.transform_data".
2023-06-25 01:07:14.624484 (Thread-1): Opening a new connection, currently in state init
2023-06-25 01:07:14.624484 (Thread-1): Compiling model.transform_data.transform_data
2023-06-25 01:07:14.633984 (Thread-1): Writing injected SQL for node "model.transform_data.transform_data"
2023-06-25 01:07:14.636484 (Thread-1): finished collecting timing info
2023-06-25 01:07:14.658983 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:07:14.658983 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "default", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */
drop view if exists "postgres"."myschema"."transform_data__dbt_tmp" cascade
2023-06-25 01:07:14.688484 (Thread-1): SQL status: DROP VIEW in 0.03 seconds
2023-06-25 01:07:14.689984 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:07:14.689984 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "default", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */
drop view if exists "postgres"."myschema"."transform_data__dbt_backup" cascade
2023-06-25 01:07:14.690484 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2023-06-25 01:07:14.691483 (Thread-1): Writing runtime SQL for node "model.transform_data.transform_data"
2023-06-25 01:07:14.692485 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:07:14.692485 (Thread-1): On model.transform_data.transform_data: BEGIN
2023-06-25 01:07:14.692983 (Thread-1): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:07:14.692983 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:07:14.692983 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "default", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */

  create view "postgres"."myschema"."transform_data__dbt_tmp" as (
    -- Clear the table before loading new data
TRUNCATE TABLE public.transactions;

-- Insert transformed and filtered data into the table
INSERT INTO public.transactions ("address", "amount", "timestamp")
SELECT
  address,
  amount,
  timestamp
FROM
  public.transactions -- Assuming 'public.transactions' is the source table

-- Apply transformation/filtering logic
WHERE
  timestamp > CURRENT_TIMESTAMP - INTERVAL '2 years';
  );

2023-06-25 01:07:14.692983 (Thread-1): Postgres error: syntax error at or near "TRUNCATE"
LINE 5: TRUNCATE TABLE public.transactions;
        ^

2023-06-25 01:07:14.692983 (Thread-1): On model.transform_data.transform_data: ROLLBACK
2023-06-25 01:07:14.693484 (Thread-1): finished collecting timing info
2023-06-25 01:07:14.693484 (Thread-1): Database Error in model transform_data (models\transformations\transform_data.sql)
  syntax error at or near "TRUNCATE"
  LINE 5: TRUNCATE TABLE public.transactions;
          ^
  compiled SQL at target\run\transform_data\transformations\transform_data.sql
Traceback (most recent call last):
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\postgres\connections.py", line 46, in exception_handler
    yield
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near "TRUNCATE"
LINE 5: TRUNCATE TABLE public.transactions;
        ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 223, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 166, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 268, in run
    return self.execute(compiled_node, manifest)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 450, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 60, in macro
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\base\impl.py", line 220, in execute
    fetch=fetch
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 116, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 82, in add_query
    return connection, cursor
  File "c:\users\me\appdata\local\programs\python\python37\lib\contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\postgres\connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model transform_data (models\transformations\transform_data.sql)
  syntax error at or near "TRUNCATE"
  LINE 5: TRUNCATE TABLE public.transactions;
          ^
  compiled SQL at target\run\transform_data\transformations\transform_data.sql
2023-06-25 01:07:14.695483 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7c5fdd31-72fb-482b-a983-b38f375e44ba', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EE6A5B2C50>]}
2023-06-25 01:07:14.695483 (Thread-1): 21:07:14 | 1 of 1 ERROR creating view model myschema.transform_data............. [ERROR in 0.07s]
2023-06-25 01:07:14.695483 (Thread-1): Finished running node model.transform_data.transform_data
2023-06-25 01:07:14.732707 (MainThread): Using postgres connection "master".
2023-06-25 01:07:14.733208 (MainThread): On master: BEGIN
2023-06-25 01:07:14.733208 (MainThread): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:07:14.733208 (MainThread): On master: COMMIT
2023-06-25 01:07:14.733208 (MainThread): Using postgres connection "master".
2023-06-25 01:07:14.733208 (MainThread): On master: COMMIT
2023-06-25 01:07:14.733707 (MainThread): SQL status: COMMIT in 0.00 seconds
2023-06-25 01:07:14.733707 (MainThread): 21:07:14 | 
2023-06-25 01:07:14.733707 (MainThread): 21:07:14 | Finished running 1 view model in 0.28s.
2023-06-25 01:07:14.733707 (MainThread): Connection 'master' was left open.
2023-06-25 01:07:14.734206 (MainThread): On master: Close
2023-06-25 01:07:14.734206 (MainThread): Connection 'list_postgres' was left open.
2023-06-25 01:07:14.734206 (MainThread): On list_postgres: Close
2023-06-25 01:07:14.734206 (MainThread): Connection 'list_postgres_myschema' was left open.
2023-06-25 01:07:14.734206 (MainThread): On list_postgres_myschema: Close
2023-06-25 01:07:14.734206 (MainThread): Connection 'model.transform_data.transform_data' was left open.
2023-06-25 01:07:14.734706 (MainThread): On model.transform_data.transform_data: Close
2023-06-25 01:07:14.736708 (MainThread): 
2023-06-25 01:07:14.736708 (MainThread): Completed with 1 error and 0 warnings:
2023-06-25 01:07:14.736708 (MainThread): 
2023-06-25 01:07:14.737208 (MainThread): Database Error in model transform_data (models\transformations\transform_data.sql)
2023-06-25 01:07:14.737208 (MainThread):   syntax error at or near "TRUNCATE"
2023-06-25 01:07:14.737208 (MainThread):   LINE 5: TRUNCATE TABLE public.transactions;
2023-06-25 01:07:14.737208 (MainThread):           ^
2023-06-25 01:07:14.737208 (MainThread):   compiled SQL at target\run\transform_data\transformations\transform_data.sql
2023-06-25 01:07:14.737208 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2023-06-25 01:07:14.737208 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EE6A5B22B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EE6A4C96A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EE6A4C96D8>]}
2023-06-25 01:07:14.737707 (MainThread): Flushing usage events
2023-06-25 01:09:45.431804 (MainThread): Running with dbt=0.16.0
2023-06-25 01:09:45.469305 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=['+transformations.transform_data'], partial_parse=None, profile=None, profiles_dir='C:\\Users\\Me\\.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2023-06-25 01:09:45.469804 (MainThread): Tracking: tracking
2023-06-25 01:09:45.470304 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023F8C2F9320>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023F8C30CFD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023F8C30C748>]}
2023-06-25 01:09:45.481805 (MainThread): Partial parsing not enabled
2023-06-25 01:09:45.484305 (MainThread): Parsing macros\core.sql
2023-06-25 01:09:45.487805 (MainThread): Parsing macros\adapters\common.sql
2023-06-25 01:09:45.519804 (MainThread): Parsing macros\etc\datetime.sql
2023-06-25 01:09:45.526804 (MainThread): Parsing macros\etc\get_custom_alias.sql
2023-06-25 01:09:45.527304 (MainThread): Parsing macros\etc\get_custom_database.sql
2023-06-25 01:09:45.528304 (MainThread): Parsing macros\etc\get_custom_schema.sql
2023-06-25 01:09:45.529804 (MainThread): Parsing macros\etc\get_relation_comment.sql
2023-06-25 01:09:45.531304 (MainThread): Parsing macros\etc\is_incremental.sql
2023-06-25 01:09:45.532805 (MainThread): Parsing macros\etc\query.sql
2023-06-25 01:09:45.533804 (MainThread): Parsing macros\materializations\helpers.sql
2023-06-25 01:09:45.539304 (MainThread): Parsing macros\materializations\common\merge.sql
2023-06-25 01:09:45.548804 (MainThread): Parsing macros\materializations\incremental\helpers.sql
2023-06-25 01:09:45.550304 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2023-06-25 01:09:45.554804 (MainThread): Parsing macros\materializations\seed\seed.sql
2023-06-25 01:09:45.570804 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2023-06-25 01:09:45.595804 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2023-06-25 01:09:45.597304 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2023-06-25 01:09:45.609804 (MainThread): Parsing macros\materializations\table\table.sql
2023-06-25 01:09:45.614804 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2023-06-25 01:09:45.618304 (MainThread): Parsing macros\materializations\view\view.sql
2023-06-25 01:09:45.623304 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2023-06-25 01:09:45.624804 (MainThread): Parsing macros\schema_tests\not_null.sql
2023-06-25 01:09:45.625304 (MainThread): Parsing macros\schema_tests\relationships.sql
2023-06-25 01:09:45.626304 (MainThread): Parsing macros\schema_tests\unique.sql
2023-06-25 01:09:45.627804 (MainThread): Parsing macros\adapters.sql
2023-06-25 01:09:45.640304 (MainThread): Parsing macros\catalog.sql
2023-06-25 01:09:45.642304 (MainThread): Parsing macros\relations.sql
2023-06-25 01:09:45.643304 (MainThread): Parsing macros\materializations\snapshot_merge.sql
2023-06-25 01:09:45.656305 (MainThread): Partial parsing not enabled
2023-06-25 01:09:45.675304 (MainThread): Acquiring new postgres connection "model.transform_data.transform_data".
2023-06-25 01:09:45.675304 (MainThread): Opening a new connection, currently in state init
2023-06-25 01:09:45.827804 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:09:45.827804 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:09:45.827804 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:09:45.828304 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:09:45.828304 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:09:45.828304 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:09:45.828304 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:09:45.829805 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:09:45.830805 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:09:45.831305 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:09:45.832804 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:09:45.834305 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:09:45.834805 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:09:45.835305 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:09:45.836305 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:09:45.836805 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:09:45.837805 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:09:45.838805 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:09:45.839305 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:09:45.840305 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:09:45.841305 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:09:45.843804 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:09:45.847306 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:09:45.848305 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:09:45.849305 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:09:45.850304 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:09:45.850804 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:09:45.858304 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:09:45.861805 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:09:45.861805 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:09:45.863304 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:09:45.878804 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:09:45.879804 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:09:45.881804 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:09:45.915305 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:09:45.919805 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:09:45.920305 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:09:45.932804 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:09:45.935305 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:09:45.950805 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:09:45.951805 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:09:45.964805 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:09:45.982805 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:09:45.984305 (MainThread): scipy not found, skipping conversion test.
2023-06-25 01:09:45.985306 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2023-06-25 01:09:45.985808 (MainThread): Found 1 model, 0 tests, 0 snapshots, 0 analyses, 127 macros, 0 operations, 0 seed files, 0 sources
2023-06-25 01:09:45.986306 (MainThread): 
2023-06-25 01:09:45.986306 (MainThread): Acquiring new postgres connection "master".
2023-06-25 01:09:45.986306 (MainThread): Opening a new connection, currently in state init
2023-06-25 01:09:45.990305 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2023-06-25 01:09:45.990305 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2023-06-25 01:09:46.050305 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2023-06-25 01:09:46.050305 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2023-06-25 01:09:46.080807 (ThreadPoolExecutor-0_0): SQL status: SELECT 5 in 0.03 seconds
2023-06-25 01:09:46.086304 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_myschema".
2023-06-25 01:09:46.086304 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2023-06-25 01:09:46.087304 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_myschema".
2023-06-25 01:09:46.087304 (ThreadPoolExecutor-1_0): On list_postgres_myschema: BEGIN
2023-06-25 01:09:46.225270 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.14 seconds
2023-06-25 01:09:46.225270 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_myschema".
2023-06-25 01:09:46.225270 (ThreadPoolExecutor-1_0): On list_postgres_myschema: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_postgres_myschema"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'myschema'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'myschema'
  
2023-06-25 01:09:46.228270 (ThreadPoolExecutor-1_0): SQL status: SELECT 3 in 0.00 seconds
2023-06-25 01:09:46.229770 (ThreadPoolExecutor-1_0): On list_postgres_myschema: ROLLBACK
2023-06-25 01:09:46.235594 (MainThread): Using postgres connection "master".
2023-06-25 01:09:46.235594 (MainThread): On master: BEGIN
2023-06-25 01:09:46.262864 (MainThread): SQL status: BEGIN in 0.03 seconds
2023-06-25 01:09:46.262864 (MainThread): Using postgres connection "master".
2023-06-25 01:09:46.262864 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2023-06-25 01:09:46.266892 (MainThread): SQL status: SELECT 1 in 0.00 seconds
2023-06-25 01:09:46.267863 (MainThread): On master: ROLLBACK
2023-06-25 01:09:46.267863 (MainThread): Using postgres connection "master".
2023-06-25 01:09:46.268363 (MainThread): On master: BEGIN
2023-06-25 01:09:46.268363 (MainThread): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:09:46.268363 (MainThread): On master: COMMIT
2023-06-25 01:09:46.268863 (MainThread): Using postgres connection "master".
2023-06-25 01:09:46.268863 (MainThread): On master: COMMIT
2023-06-25 01:09:46.268863 (MainThread): SQL status: COMMIT in 0.00 seconds
2023-06-25 01:09:46.268863 (MainThread): 21:09:46 | Concurrency: 1 threads (target='dev')
2023-06-25 01:09:46.269363 (MainThread): 21:09:46 | 
2023-06-25 01:09:46.270863 (Thread-1): Began running node model.transform_data.transform_data
2023-06-25 01:09:46.270863 (Thread-1): 21:09:46 | 1 of 1 START view model myschema.transform_data...................... [RUN]
2023-06-25 01:09:46.271363 (Thread-1): Acquiring new postgres connection "model.transform_data.transform_data".
2023-06-25 01:09:46.271363 (Thread-1): Opening a new connection, currently in state init
2023-06-25 01:09:46.271363 (Thread-1): Compiling model.transform_data.transform_data
2023-06-25 01:09:46.280862 (Thread-1): Writing injected SQL for node "model.transform_data.transform_data"
2023-06-25 01:09:46.281363 (Thread-1): finished collecting timing info
2023-06-25 01:09:46.301863 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:09:46.302362 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "default", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */
drop view if exists "postgres"."myschema"."transform_data__dbt_tmp" cascade
2023-06-25 01:09:46.438763 (Thread-1): SQL status: DROP VIEW in 0.14 seconds
2023-06-25 01:09:46.440263 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:09:46.440263 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "default", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */
drop view if exists "postgres"."myschema"."transform_data__dbt_backup" cascade
2023-06-25 01:09:46.440763 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2023-06-25 01:09:46.441264 (Thread-1): Writing runtime SQL for node "model.transform_data.transform_data"
2023-06-25 01:09:46.442207 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:09:46.442207 (Thread-1): On model.transform_data.transform_data: BEGIN
2023-06-25 01:09:46.442207 (Thread-1): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:09:46.442207 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:09:46.442712 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "default", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */

  create view "postgres"."myschema"."transform_data__dbt_tmp" as (
    -- Delete existing rows from the table
DELETE FROM public.transactions;

-- Insert transformed and filtered data into the table
INSERT INTO public.transactions ("address", "amount", "timestamp")
SELECT
  address,
  amount,
  timestamp
FROM
  public.transactions -- Assuming 'public.transactions' is the source table

-- Apply transformation/filtering logic
WHERE
  timestamp > CURRENT_TIMESTAMP - INTERVAL '2 years';
  );

2023-06-25 01:09:46.442712 (Thread-1): Postgres error: syntax error at or near "DELETE"
LINE 5: DELETE FROM public.transactions;
        ^

2023-06-25 01:09:46.442712 (Thread-1): On model.transform_data.transform_data: ROLLBACK
2023-06-25 01:09:46.442712 (Thread-1): finished collecting timing info
2023-06-25 01:09:46.443211 (Thread-1): Database Error in model transform_data (models\transformations\transform_data.sql)
  syntax error at or near "DELETE"
  LINE 5: DELETE FROM public.transactions;
          ^
  compiled SQL at target\run\transform_data\transformations\transform_data.sql
Traceback (most recent call last):
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\postgres\connections.py", line 46, in exception_handler
    yield
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near "DELETE"
LINE 5: DELETE FROM public.transactions;
        ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 223, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 166, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 268, in run
    return self.execute(compiled_node, manifest)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 450, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 60, in macro
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\base\impl.py", line 220, in execute
    fetch=fetch
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 116, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 82, in add_query
    return connection, cursor
  File "c:\users\me\appdata\local\programs\python\python37\lib\contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\postgres\connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model transform_data (models\transformations\transform_data.sql)
  syntax error at or near "DELETE"
  LINE 5: DELETE FROM public.transactions;
          ^
  compiled SQL at target\run\transform_data\transformations\transform_data.sql
2023-06-25 01:09:46.444711 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a30ae17c-f2c2-411b-b234-8fc35c057257', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023F90081CC0>]}
2023-06-25 01:09:46.445212 (Thread-1): 21:09:46 | 1 of 1 ERROR creating view model myschema.transform_data............. [ERROR in 0.17s]
2023-06-25 01:09:46.445212 (Thread-1): Finished running node model.transform_data.transform_data
2023-06-25 01:09:46.478593 (MainThread): Using postgres connection "master".
2023-06-25 01:09:46.479087 (MainThread): On master: BEGIN
2023-06-25 01:09:46.479087 (MainThread): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:09:46.479087 (MainThread): On master: COMMIT
2023-06-25 01:09:46.479087 (MainThread): Using postgres connection "master".
2023-06-25 01:09:46.479087 (MainThread): On master: COMMIT
2023-06-25 01:09:46.479586 (MainThread): SQL status: COMMIT in 0.00 seconds
2023-06-25 01:09:46.479586 (MainThread): 21:09:46 | 
2023-06-25 01:09:46.479586 (MainThread): 21:09:46 | Finished running 1 view model in 0.49s.
2023-06-25 01:09:46.479586 (MainThread): Connection 'master' was left open.
2023-06-25 01:09:46.479586 (MainThread): On master: Close
2023-06-25 01:09:46.480087 (MainThread): Connection 'list_postgres' was left open.
2023-06-25 01:09:46.480087 (MainThread): On list_postgres: Close
2023-06-25 01:09:46.480087 (MainThread): Connection 'list_postgres_myschema' was left open.
2023-06-25 01:09:46.480087 (MainThread): On list_postgres_myschema: Close
2023-06-25 01:09:46.480087 (MainThread): Connection 'model.transform_data.transform_data' was left open.
2023-06-25 01:09:46.480087 (MainThread): On model.transform_data.transform_data: Close
2023-06-25 01:09:46.482586 (MainThread): 
2023-06-25 01:09:46.482586 (MainThread): Completed with 1 error and 0 warnings:
2023-06-25 01:09:46.482586 (MainThread): 
2023-06-25 01:09:46.482586 (MainThread): Database Error in model transform_data (models\transformations\transform_data.sql)
2023-06-25 01:09:46.482586 (MainThread):   syntax error at or near "DELETE"
2023-06-25 01:09:46.482586 (MainThread):   LINE 5: DELETE FROM public.transactions;
2023-06-25 01:09:46.483087 (MainThread):           ^
2023-06-25 01:09:46.483087 (MainThread):   compiled SQL at target\run\transform_data\transformations\transform_data.sql
2023-06-25 01:09:46.483087 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2023-06-25 01:09:46.483087 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023F90081518>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023F8FF91668>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023F8FF916A0>]}
2023-06-25 01:09:46.483087 (MainThread): Flushing usage events
2023-06-25 01:10:44.746390 (MainThread): Running with dbt=0.16.0
2023-06-25 01:10:44.783390 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=['+transformations.transform_data'], partial_parse=None, profile=None, profiles_dir='C:\\Users\\Me\\.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2023-06-25 01:10:44.783390 (MainThread): Tracking: tracking
2023-06-25 01:10:44.783890 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D8D6C70E80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D8D6C7DEB8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D8D6C7D828>]}
2023-06-25 01:10:44.795391 (MainThread): Partial parsing not enabled
2023-06-25 01:10:44.797892 (MainThread): Parsing macros\core.sql
2023-06-25 01:10:44.801393 (MainThread): Parsing macros\adapters\common.sql
2023-06-25 01:10:44.833391 (MainThread): Parsing macros\etc\datetime.sql
2023-06-25 01:10:44.840390 (MainThread): Parsing macros\etc\get_custom_alias.sql
2023-06-25 01:10:44.841390 (MainThread): Parsing macros\etc\get_custom_database.sql
2023-06-25 01:10:44.842390 (MainThread): Parsing macros\etc\get_custom_schema.sql
2023-06-25 01:10:44.843890 (MainThread): Parsing macros\etc\get_relation_comment.sql
2023-06-25 01:10:44.845390 (MainThread): Parsing macros\etc\is_incremental.sql
2023-06-25 01:10:44.846390 (MainThread): Parsing macros\etc\query.sql
2023-06-25 01:10:44.847390 (MainThread): Parsing macros\materializations\helpers.sql
2023-06-25 01:10:44.853390 (MainThread): Parsing macros\materializations\common\merge.sql
2023-06-25 01:10:44.863891 (MainThread): Parsing macros\materializations\incremental\helpers.sql
2023-06-25 01:10:44.865890 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2023-06-25 01:10:44.870390 (MainThread): Parsing macros\materializations\seed\seed.sql
2023-06-25 01:10:44.886890 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2023-06-25 01:10:44.912892 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2023-06-25 01:10:44.914392 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2023-06-25 01:10:44.926890 (MainThread): Parsing macros\materializations\table\table.sql
2023-06-25 01:10:44.932390 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2023-06-25 01:10:44.935890 (MainThread): Parsing macros\materializations\view\view.sql
2023-06-25 01:10:44.940891 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2023-06-25 01:10:44.942390 (MainThread): Parsing macros\schema_tests\not_null.sql
2023-06-25 01:10:44.943390 (MainThread): Parsing macros\schema_tests\relationships.sql
2023-06-25 01:10:44.943890 (MainThread): Parsing macros\schema_tests\unique.sql
2023-06-25 01:10:44.945390 (MainThread): Parsing macros\adapters.sql
2023-06-25 01:10:44.958391 (MainThread): Parsing macros\catalog.sql
2023-06-25 01:10:44.960390 (MainThread): Parsing macros\relations.sql
2023-06-25 01:10:44.961390 (MainThread): Parsing macros\materializations\snapshot_merge.sql
2023-06-25 01:10:44.974390 (MainThread): Partial parsing not enabled
2023-06-25 01:10:44.993390 (MainThread): Acquiring new postgres connection "model.transform_data.transform_data".
2023-06-25 01:10:44.993390 (MainThread): Opening a new connection, currently in state init
2023-06-25 01:10:45.146390 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:10:45.146390 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:10:45.146390 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:10:45.146390 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:10:45.146390 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:10:45.146390 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:10:45.146390 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:10:45.147891 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:10:45.148891 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:10:45.149390 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:10:45.150890 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:10:45.151890 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:10:45.152390 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:10:45.153392 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:10:45.154890 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:10:45.155390 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:10:45.155890 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:10:45.156890 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:10:45.157390 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:10:45.158390 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:10:45.159390 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:10:45.161890 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:10:45.165390 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:10:45.166390 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:10:45.167890 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:10:45.168390 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:10:45.169393 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:10:45.176891 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:10:45.180390 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:10:45.180390 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:10:45.181890 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:10:45.197393 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:10:45.198393 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:10:45.200892 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:10:45.234890 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:10:45.239390 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:10:45.239890 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:10:45.252891 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:10:45.255390 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:10:45.270891 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:10:45.271890 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:10:45.285391 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:10:45.302392 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:10:45.303392 (MainThread): scipy not found, skipping conversion test.
2023-06-25 01:10:45.304392 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2023-06-25 01:10:45.304892 (MainThread): Found 1 model, 0 tests, 0 snapshots, 0 analyses, 127 macros, 0 operations, 0 seed files, 0 sources
2023-06-25 01:10:45.305392 (MainThread): 
2023-06-25 01:10:45.305392 (MainThread): Acquiring new postgres connection "master".
2023-06-25 01:10:45.305893 (MainThread): Opening a new connection, currently in state init
2023-06-25 01:10:45.309391 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2023-06-25 01:10:45.309391 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2023-06-25 01:10:45.365390 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2023-06-25 01:10:45.365891 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2023-06-25 01:10:45.395422 (ThreadPoolExecutor-0_0): SQL status: SELECT 5 in 0.03 seconds
2023-06-25 01:10:45.401390 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_myschema".
2023-06-25 01:10:45.401390 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2023-06-25 01:10:45.402390 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_myschema".
2023-06-25 01:10:45.402390 (ThreadPoolExecutor-1_0): On list_postgres_myschema: BEGIN
2023-06-25 01:10:45.430891 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.03 seconds
2023-06-25 01:10:45.430891 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_myschema".
2023-06-25 01:10:45.430891 (ThreadPoolExecutor-1_0): On list_postgres_myschema: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "default", "target_name": "dev", "connection_name": "list_postgres_myschema"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'myschema'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'myschema'
  
2023-06-25 01:10:45.433890 (ThreadPoolExecutor-1_0): SQL status: SELECT 3 in 0.00 seconds
2023-06-25 01:10:45.435390 (ThreadPoolExecutor-1_0): On list_postgres_myschema: ROLLBACK
2023-06-25 01:10:45.440890 (MainThread): Using postgres connection "master".
2023-06-25 01:10:45.441390 (MainThread): On master: BEGIN
2023-06-25 01:10:45.470390 (MainThread): SQL status: BEGIN in 0.03 seconds
2023-06-25 01:10:45.470390 (MainThread): Using postgres connection "master".
2023-06-25 01:10:45.470890 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "default", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2023-06-25 01:10:45.474390 (MainThread): SQL status: SELECT 1 in 0.00 seconds
2023-06-25 01:10:45.475890 (MainThread): On master: ROLLBACK
2023-06-25 01:10:45.475890 (MainThread): Using postgres connection "master".
2023-06-25 01:10:45.475890 (MainThread): On master: BEGIN
2023-06-25 01:10:45.476390 (MainThread): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:10:45.476390 (MainThread): On master: COMMIT
2023-06-25 01:10:45.476390 (MainThread): Using postgres connection "master".
2023-06-25 01:10:45.476390 (MainThread): On master: COMMIT
2023-06-25 01:10:45.476890 (MainThread): SQL status: COMMIT in 0.00 seconds
2023-06-25 01:10:45.476890 (MainThread): 21:10:45 | Concurrency: 1 threads (target='dev')
2023-06-25 01:10:45.476890 (MainThread): 21:10:45 | 
2023-06-25 01:10:45.478390 (Thread-1): Began running node model.transform_data.transform_data
2023-06-25 01:10:45.478390 (Thread-1): 21:10:45 | 1 of 1 START view model myschema.transform_data...................... [RUN]
2023-06-25 01:10:45.478891 (Thread-1): Acquiring new postgres connection "model.transform_data.transform_data".
2023-06-25 01:10:45.478891 (Thread-1): Opening a new connection, currently in state init
2023-06-25 01:10:45.478891 (Thread-1): Compiling model.transform_data.transform_data
2023-06-25 01:10:45.487890 (Thread-1): Writing injected SQL for node "model.transform_data.transform_data"
2023-06-25 01:10:45.488891 (Thread-1): finished collecting timing info
2023-06-25 01:10:45.509392 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:10:45.509392 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "default", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */
drop view if exists "postgres"."myschema"."transform_data__dbt_tmp" cascade
2023-06-25 01:10:45.538461 (Thread-1): SQL status: DROP VIEW in 0.03 seconds
2023-06-25 01:10:45.539964 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:10:45.540465 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "default", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */
drop view if exists "postgres"."myschema"."transform_data__dbt_backup" cascade
2023-06-25 01:10:45.540465 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2023-06-25 01:10:45.541465 (Thread-1): Writing runtime SQL for node "model.transform_data.transform_data"
2023-06-25 01:10:45.541965 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:10:45.541965 (Thread-1): On model.transform_data.transform_data: BEGIN
2023-06-25 01:10:45.542466 (Thread-1): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:10:45.542466 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:10:45.542466 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "default", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */

  create view "postgres"."myschema"."transform_data__dbt_tmp" as (
    -- Delete existing rows from the table
DELETE FROM public.transactions WHERE true;

-- Insert transformed and filtered data into the table
INSERT INTO public.transactions ("address", "amount", "timestamp")
SELECT
  address,
  amount,
  timestamp
FROM
  public.transactions -- Assuming 'public.transactions' is the source table

-- Apply transformation/filtering logic
WHERE
  timestamp > CURRENT_TIMESTAMP - INTERVAL '2 years';
  );

2023-06-25 01:10:45.542965 (Thread-1): Postgres error: syntax error at or near "DELETE"
LINE 5: DELETE FROM public.transactions WHERE true;
        ^

2023-06-25 01:10:45.542965 (Thread-1): On model.transform_data.transform_data: ROLLBACK
2023-06-25 01:10:45.542965 (Thread-1): finished collecting timing info
2023-06-25 01:10:45.543465 (Thread-1): Database Error in model transform_data (models\transformations\transform_data.sql)
  syntax error at or near "DELETE"
  LINE 5: DELETE FROM public.transactions WHERE true;
          ^
  compiled SQL at target\run\transform_data\transformations\transform_data.sql
Traceback (most recent call last):
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\postgres\connections.py", line 46, in exception_handler
    yield
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near "DELETE"
LINE 5: DELETE FROM public.transactions WHERE true;
        ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 223, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 166, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 268, in run
    return self.execute(compiled_node, manifest)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 450, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 60, in macro
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\base\impl.py", line 220, in execute
    fetch=fetch
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 116, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 82, in add_query
    return connection, cursor
  File "c:\users\me\appdata\local\programs\python\python37\lib\contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\postgres\connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model transform_data (models\transformations\transform_data.sql)
  syntax error at or near "DELETE"
  LINE 5: DELETE FROM public.transactions WHERE true;
          ^
  compiled SQL at target\run\transform_data\transformations\transform_data.sql
2023-06-25 01:10:45.544965 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ae899a28-d915-4695-9be1-2e422209d16d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D8DA9F2F28>]}
2023-06-25 01:10:45.544965 (Thread-1): 21:10:45 | 1 of 1 ERROR creating view model myschema.transform_data............. [ERROR in 0.07s]
2023-06-25 01:10:45.545465 (Thread-1): Finished running node model.transform_data.transform_data
2023-06-25 01:10:45.588742 (MainThread): Using postgres connection "master".
2023-06-25 01:10:45.589242 (MainThread): On master: BEGIN
2023-06-25 01:10:45.590243 (MainThread): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:10:45.590710 (MainThread): On master: COMMIT
2023-06-25 01:10:45.590710 (MainThread): Using postgres connection "master".
2023-06-25 01:10:45.591241 (MainThread): On master: COMMIT
2023-06-25 01:10:45.592243 (MainThread): SQL status: COMMIT in 0.00 seconds
2023-06-25 01:10:45.593246 (MainThread): 21:10:45 | 
2023-06-25 01:10:45.593246 (MainThread): 21:10:45 | Finished running 1 view model in 0.29s.
2023-06-25 01:10:45.593246 (MainThread): Connection 'master' was left open.
2023-06-25 01:10:45.593246 (MainThread): On master: Close
2023-06-25 01:10:45.593721 (MainThread): Connection 'list_postgres' was left open.
2023-06-25 01:10:45.593721 (MainThread): On list_postgres: Close
2023-06-25 01:10:45.593721 (MainThread): Connection 'list_postgres_myschema' was left open.
2023-06-25 01:10:45.593721 (MainThread): On list_postgres_myschema: Close
2023-06-25 01:10:45.593721 (MainThread): Connection 'model.transform_data.transform_data' was left open.
2023-06-25 01:10:45.593721 (MainThread): On model.transform_data.transform_data: Close
2023-06-25 01:10:45.596191 (MainThread): 
2023-06-25 01:10:45.596191 (MainThread): Completed with 1 error and 0 warnings:
2023-06-25 01:10:45.596191 (MainThread): 
2023-06-25 01:10:45.596191 (MainThread): Database Error in model transform_data (models\transformations\transform_data.sql)
2023-06-25 01:10:45.596690 (MainThread):   syntax error at or near "DELETE"
2023-06-25 01:10:45.596690 (MainThread):   LINE 5: DELETE FROM public.transactions WHERE true;
2023-06-25 01:10:45.596690 (MainThread):           ^
2023-06-25 01:10:45.596690 (MainThread):   compiled SQL at target\run\transform_data\transformations\transform_data.sql
2023-06-25 01:10:45.596690 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2023-06-25 01:10:45.596690 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D8DA8FF6D8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D8DA9F6390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D8D9F248D0>]}
2023-06-25 01:10:45.596690 (MainThread): Flushing usage events
2023-06-25 01:15:11.051582 (MainThread): Running with dbt=0.16.0
2023-06-25 01:15:11.088582 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=['+transformations.transform_data'], partial_parse=None, profile=None, profiles_dir='C:\\Users\\Me\\.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2023-06-25 01:15:11.089081 (MainThread): Tracking: tracking
2023-06-25 01:15:11.089081 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CA79162780>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CA79143D30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CA7916CF28>]}
2023-06-25 01:15:11.100581 (MainThread): Partial parsing not enabled
2023-06-25 01:15:11.103081 (MainThread): Parsing macros\core.sql
2023-06-25 01:15:11.106081 (MainThread): Parsing macros\adapters\common.sql
2023-06-25 01:15:11.137114 (MainThread): Parsing macros\etc\datetime.sql
2023-06-25 01:15:11.144082 (MainThread): Parsing macros\etc\get_custom_alias.sql
2023-06-25 01:15:11.145081 (MainThread): Parsing macros\etc\get_custom_database.sql
2023-06-25 01:15:11.146081 (MainThread): Parsing macros\etc\get_custom_schema.sql
2023-06-25 01:15:11.147581 (MainThread): Parsing macros\etc\get_relation_comment.sql
2023-06-25 01:15:11.149081 (MainThread): Parsing macros\etc\is_incremental.sql
2023-06-25 01:15:11.150081 (MainThread): Parsing macros\etc\query.sql
2023-06-25 01:15:11.151082 (MainThread): Parsing macros\materializations\helpers.sql
2023-06-25 01:15:11.156581 (MainThread): Parsing macros\materializations\common\merge.sql
2023-06-25 01:15:11.166581 (MainThread): Parsing macros\materializations\incremental\helpers.sql
2023-06-25 01:15:11.167581 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2023-06-25 01:15:11.172581 (MainThread): Parsing macros\materializations\seed\seed.sql
2023-06-25 01:15:11.188081 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2023-06-25 01:15:11.212581 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2023-06-25 01:15:11.214081 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2023-06-25 01:15:11.226581 (MainThread): Parsing macros\materializations\table\table.sql
2023-06-25 01:15:11.231581 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2023-06-25 01:15:11.235081 (MainThread): Parsing macros\materializations\view\view.sql
2023-06-25 01:15:11.239581 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2023-06-25 01:15:11.241581 (MainThread): Parsing macros\schema_tests\not_null.sql
2023-06-25 01:15:11.242081 (MainThread): Parsing macros\schema_tests\relationships.sql
2023-06-25 01:15:11.243081 (MainThread): Parsing macros\schema_tests\unique.sql
2023-06-25 01:15:11.244081 (MainThread): Parsing macros\adapters.sql
2023-06-25 01:15:11.257083 (MainThread): Parsing macros\catalog.sql
2023-06-25 01:15:11.259082 (MainThread): Parsing macros\relations.sql
2023-06-25 01:15:11.260083 (MainThread): Parsing macros\materializations\snapshot_merge.sql
2023-06-25 01:15:11.273112 (MainThread): Partial parsing not enabled
2023-06-25 01:15:11.291581 (MainThread): Acquiring new postgres connection "model.transform_data.transform_data".
2023-06-25 01:15:11.292081 (MainThread): Opening a new connection, currently in state init
2023-06-25 01:15:11.445580 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:15:11.445580 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:15:11.445580 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:15:11.445580 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:15:11.446081 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:15:11.446081 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:15:11.446081 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:15:11.447581 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:15:11.448080 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:15:11.448580 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:15:11.450082 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:15:11.451113 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:15:11.452111 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:15:11.452611 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:15:11.453611 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:15:11.454110 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:15:11.454610 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:15:11.455611 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:15:11.456112 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:15:11.457113 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:15:11.458110 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:15:11.460580 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:15:11.464080 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:15:11.465080 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:15:11.466080 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:15:11.467081 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:15:11.467580 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:15:11.475081 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:15:11.478581 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:15:11.478581 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:15:11.480081 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:15:11.495081 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:15:11.495580 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:15:11.497580 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:15:11.530580 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:15:11.534580 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:15:11.535580 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:15:11.548083 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:15:11.550083 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:15:11.566111 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:15:11.567082 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:15:11.581104 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:15:11.598580 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:15:11.599580 (MainThread): scipy not found, skipping conversion test.
2023-06-25 01:15:11.600580 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2023-06-25 01:15:11.601081 (MainThread): Found 1 model, 0 tests, 0 snapshots, 0 analyses, 127 macros, 0 operations, 0 seed files, 0 sources
2023-06-25 01:15:11.601581 (MainThread): 
2023-06-25 01:15:11.602082 (MainThread): Acquiring new postgres connection "master".
2023-06-25 01:15:11.602082 (MainThread): Opening a new connection, currently in state init
2023-06-25 01:15:11.605583 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2023-06-25 01:15:11.606082 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2023-06-25 01:15:11.661082 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2023-06-25 01:15:11.661082 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2023-06-25 01:15:11.691696 (ThreadPoolExecutor-0_0): SQL status: SELECT 5 in 0.03 seconds
2023-06-25 01:15:11.697195 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_public".
2023-06-25 01:15:11.697695 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2023-06-25 01:15:11.698727 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_public".
2023-06-25 01:15:11.698727 (ThreadPoolExecutor-1_0): On list_postgres_public: BEGIN
2023-06-25 01:15:11.727695 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.03 seconds
2023-06-25 01:15:11.727695 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_public".
2023-06-25 01:15:11.727695 (ThreadPoolExecutor-1_0): On list_postgres_public: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "list_postgres_public"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2023-06-25 01:15:11.730695 (ThreadPoolExecutor-1_0): SQL status: SELECT 2 in 0.00 seconds
2023-06-25 01:15:11.732227 (ThreadPoolExecutor-1_0): On list_postgres_public: ROLLBACK
2023-06-25 01:15:11.738196 (MainThread): Using postgres connection "master".
2023-06-25 01:15:11.738196 (MainThread): On master: BEGIN
2023-06-25 01:15:11.768197 (MainThread): SQL status: BEGIN in 0.03 seconds
2023-06-25 01:15:11.768197 (MainThread): Using postgres connection "master".
2023-06-25 01:15:11.768696 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2023-06-25 01:15:11.772196 (MainThread): SQL status: SELECT 1 in 0.00 seconds
2023-06-25 01:15:11.773197 (MainThread): On master: ROLLBACK
2023-06-25 01:15:11.773696 (MainThread): Using postgres connection "master".
2023-06-25 01:15:11.773696 (MainThread): On master: BEGIN
2023-06-25 01:15:11.774197 (MainThread): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:15:11.774197 (MainThread): On master: COMMIT
2023-06-25 01:15:11.774197 (MainThread): Using postgres connection "master".
2023-06-25 01:15:11.774197 (MainThread): On master: COMMIT
2023-06-25 01:15:11.774197 (MainThread): SQL status: COMMIT in 0.00 seconds
2023-06-25 01:15:11.774696 (MainThread): 21:15:11 | Concurrency: 1 threads (target='dev')
2023-06-25 01:15:11.774696 (MainThread): 21:15:11 | 
2023-06-25 01:15:11.776196 (Thread-1): Began running node model.transform_data.transform_data
2023-06-25 01:15:11.776196 (Thread-1): 21:15:11 | 1 of 1 START view model public.transform_data........................ [RUN]
2023-06-25 01:15:11.776731 (Thread-1): Acquiring new postgres connection "model.transform_data.transform_data".
2023-06-25 01:15:11.776731 (Thread-1): Opening a new connection, currently in state init
2023-06-25 01:15:11.776731 (Thread-1): Compiling model.transform_data.transform_data
2023-06-25 01:15:11.786232 (Thread-1): Writing injected SQL for node "model.transform_data.transform_data"
2023-06-25 01:15:11.786724 (Thread-1): finished collecting timing info
2023-06-25 01:15:11.807695 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:15:11.807695 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */
drop view if exists "postgres"."public"."transform_data__dbt_tmp" cascade
2023-06-25 01:15:11.836492 (Thread-1): SQL status: DROP VIEW in 0.03 seconds
2023-06-25 01:15:11.837991 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:15:11.837991 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */
drop view if exists "postgres"."public"."transform_data__dbt_backup" cascade
2023-06-25 01:15:11.838491 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2023-06-25 01:15:11.839491 (Thread-1): Writing runtime SQL for node "model.transform_data.transform_data"
2023-06-25 01:15:11.839990 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:15:11.839990 (Thread-1): On model.transform_data.transform_data: BEGIN
2023-06-25 01:15:11.839990 (Thread-1): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:15:11.840491 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:15:11.840491 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */

  create view "postgres"."public"."transform_data__dbt_tmp" as (
    -- Delete existing rows from the table
DELETE FROM public.transactions WHERE true;

-- Insert transformed and filtered data into the table
INSERT INTO public.transactions ("address", "amount", "timestamp")
SELECT
  address,
  amount,
  timestamp
FROM
  public.transactions -- Assuming 'public.transactions' is the source table

-- Apply transformation/filtering logic
WHERE
  timestamp > CURRENT_TIMESTAMP - INTERVAL '2 years';
  );

2023-06-25 01:15:11.840491 (Thread-1): Postgres error: syntax error at or near "DELETE"
LINE 5: DELETE FROM public.transactions WHERE true;
        ^

2023-06-25 01:15:11.840491 (Thread-1): On model.transform_data.transform_data: ROLLBACK
2023-06-25 01:15:11.840991 (Thread-1): finished collecting timing info
2023-06-25 01:15:11.840991 (Thread-1): Database Error in model transform_data (models\transformations\transform_data.sql)
  syntax error at or near "DELETE"
  LINE 5: DELETE FROM public.transactions WHERE true;
          ^
  compiled SQL at target\run\transform_data\transformations\transform_data.sql
Traceback (most recent call last):
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\postgres\connections.py", line 46, in exception_handler
    yield
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near "DELETE"
LINE 5: DELETE FROM public.transactions WHERE true;
        ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 223, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 166, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 268, in run
    return self.execute(compiled_node, manifest)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 450, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 60, in macro
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\base\impl.py", line 220, in execute
    fetch=fetch
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 116, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 82, in add_query
    return connection, cursor
  File "c:\users\me\appdata\local\programs\python\python37\lib\contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\postgres\connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model transform_data (models\transformations\transform_data.sql)
  syntax error at or near "DELETE"
  LINE 5: DELETE FROM public.transactions WHERE true;
          ^
  compiled SQL at target\run\transform_data\transformations\transform_data.sql
2023-06-25 01:15:11.842991 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '04ecb829-dafc-4df5-a9f3-3f58099a17b9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CA7CEC42E8>]}
2023-06-25 01:15:11.842991 (Thread-1): 21:15:11 | 1 of 1 ERROR creating view model public.transform_data............... [ERROR in 0.07s]
2023-06-25 01:15:11.842991 (Thread-1): Finished running node model.transform_data.transform_data
2023-06-25 01:15:11.880765 (MainThread): Using postgres connection "master".
2023-06-25 01:15:11.880765 (MainThread): On master: BEGIN
2023-06-25 01:15:11.881267 (MainThread): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:15:11.881267 (MainThread): On master: COMMIT
2023-06-25 01:15:11.881267 (MainThread): Using postgres connection "master".
2023-06-25 01:15:11.881267 (MainThread): On master: COMMIT
2023-06-25 01:15:11.881766 (MainThread): SQL status: COMMIT in 0.00 seconds
2023-06-25 01:15:11.881766 (MainThread): 21:15:11 | 
2023-06-25 01:15:11.881766 (MainThread): 21:15:11 | Finished running 1 view model in 0.28s.
2023-06-25 01:15:11.881766 (MainThread): Connection 'master' was left open.
2023-06-25 01:15:11.881766 (MainThread): On master: Close
2023-06-25 01:15:11.882265 (MainThread): Connection 'list_postgres' was left open.
2023-06-25 01:15:11.882265 (MainThread): On list_postgres: Close
2023-06-25 01:15:11.882265 (MainThread): Connection 'list_postgres_public' was left open.
2023-06-25 01:15:11.882265 (MainThread): On list_postgres_public: Close
2023-06-25 01:15:11.882265 (MainThread): Connection 'model.transform_data.transform_data' was left open.
2023-06-25 01:15:11.882766 (MainThread): On model.transform_data.transform_data: Close
2023-06-25 01:15:11.885267 (MainThread): 
2023-06-25 01:15:11.885267 (MainThread): Completed with 1 error and 0 warnings:
2023-06-25 01:15:11.885267 (MainThread): 
2023-06-25 01:15:11.885267 (MainThread): Database Error in model transform_data (models\transformations\transform_data.sql)
2023-06-25 01:15:11.885267 (MainThread):   syntax error at or near "DELETE"
2023-06-25 01:15:11.885768 (MainThread):   LINE 5: DELETE FROM public.transactions WHERE true;
2023-06-25 01:15:11.885768 (MainThread):           ^
2023-06-25 01:15:11.885768 (MainThread):   compiled SQL at target\run\transform_data\transformations\transform_data.sql
2023-06-25 01:15:11.885768 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2023-06-25 01:15:11.885768 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CA7CDFD518>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CA7CDA3CF8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CA7CEE02E8>]}
2023-06-25 01:15:11.886268 (MainThread): Flushing usage events
2023-06-25 01:16:04.574914 (MainThread): Running with dbt=0.16.0
2023-06-25 01:16:04.611913 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=['+transformations.transform_data'], partial_parse=None, profile=None, profiles_dir='C:\\Users\\Me\\.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2023-06-25 01:16:04.612413 (MainThread): Tracking: tracking
2023-06-25 01:16:04.612413 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F6DC262320>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F6DC244358>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F6DC26DFD0>]}
2023-06-25 01:16:04.623914 (MainThread): Partial parsing not enabled
2023-06-25 01:16:04.625914 (MainThread): Parsing macros\core.sql
2023-06-25 01:16:04.629414 (MainThread): Parsing macros\adapters\common.sql
2023-06-25 01:16:04.660413 (MainThread): Parsing macros\etc\datetime.sql
2023-06-25 01:16:04.667413 (MainThread): Parsing macros\etc\get_custom_alias.sql
2023-06-25 01:16:04.668413 (MainThread): Parsing macros\etc\get_custom_database.sql
2023-06-25 01:16:04.669413 (MainThread): Parsing macros\etc\get_custom_schema.sql
2023-06-25 01:16:04.670913 (MainThread): Parsing macros\etc\get_relation_comment.sql
2023-06-25 01:16:04.672413 (MainThread): Parsing macros\etc\is_incremental.sql
2023-06-25 01:16:04.673413 (MainThread): Parsing macros\etc\query.sql
2023-06-25 01:16:04.674413 (MainThread): Parsing macros\materializations\helpers.sql
2023-06-25 01:16:04.680413 (MainThread): Parsing macros\materializations\common\merge.sql
2023-06-25 01:16:04.689913 (MainThread): Parsing macros\materializations\incremental\helpers.sql
2023-06-25 01:16:04.690913 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2023-06-25 01:16:04.695413 (MainThread): Parsing macros\materializations\seed\seed.sql
2023-06-25 01:16:04.710915 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2023-06-25 01:16:04.735943 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2023-06-25 01:16:04.737443 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2023-06-25 01:16:04.749913 (MainThread): Parsing macros\materializations\table\table.sql
2023-06-25 01:16:04.754913 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2023-06-25 01:16:04.758413 (MainThread): Parsing macros\materializations\view\view.sql
2023-06-25 01:16:04.762913 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2023-06-25 01:16:04.764413 (MainThread): Parsing macros\schema_tests\not_null.sql
2023-06-25 01:16:04.765413 (MainThread): Parsing macros\schema_tests\relationships.sql
2023-06-25 01:16:04.766413 (MainThread): Parsing macros\schema_tests\unique.sql
2023-06-25 01:16:04.767413 (MainThread): Parsing macros\adapters.sql
2023-06-25 01:16:04.780413 (MainThread): Parsing macros\catalog.sql
2023-06-25 01:16:04.781913 (MainThread): Parsing macros\relations.sql
2023-06-25 01:16:04.783413 (MainThread): Parsing macros\materializations\snapshot_merge.sql
2023-06-25 01:16:04.795913 (MainThread): Partial parsing not enabled
2023-06-25 01:16:04.814413 (MainThread): Acquiring new postgres connection "model.transform_data.transform_data".
2023-06-25 01:16:04.814413 (MainThread): Opening a new connection, currently in state init
2023-06-25 01:16:04.965915 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:16:04.965915 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:16:04.965915 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:16:04.965915 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:16:04.965915 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:16:04.965915 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:16:04.965915 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:16:04.967416 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:16:04.968415 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:16:04.968915 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:16:04.970444 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:16:04.971444 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:16:04.971944 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:16:04.972444 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:16:04.973943 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:16:04.974444 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:16:04.974943 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:16:04.975944 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:16:04.976444 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:16:04.977444 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:16:04.978444 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:16:04.980943 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:16:04.984444 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:16:04.984944 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:16:04.986414 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:16:04.987413 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:16:04.987913 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:16:04.995414 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:16:04.998914 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:16:04.998914 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:16:05.000413 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:16:05.015914 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:16:05.016413 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:16:05.018414 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:16:05.051914 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:16:05.056413 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:16:05.056913 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:16:05.069414 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:16:05.072415 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:16:05.088414 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:16:05.089414 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:16:05.102415 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:16:05.119413 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:16:05.120413 (MainThread): scipy not found, skipping conversion test.
2023-06-25 01:16:05.121413 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2023-06-25 01:16:05.121413 (MainThread): Found 1 model, 0 tests, 0 snapshots, 0 analyses, 127 macros, 0 operations, 0 seed files, 0 sources
2023-06-25 01:16:05.122414 (MainThread): 
2023-06-25 01:16:05.122414 (MainThread): Acquiring new postgres connection "master".
2023-06-25 01:16:05.122414 (MainThread): Opening a new connection, currently in state init
2023-06-25 01:16:05.125914 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2023-06-25 01:16:05.126413 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2023-06-25 01:16:05.181413 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2023-06-25 01:16:05.181413 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2023-06-25 01:16:05.211413 (ThreadPoolExecutor-0_0): SQL status: SELECT 5 in 0.03 seconds
2023-06-25 01:16:05.216913 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_public".
2023-06-25 01:16:05.216913 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2023-06-25 01:16:05.217914 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_public".
2023-06-25 01:16:05.217914 (ThreadPoolExecutor-1_0): On list_postgres_public: BEGIN
2023-06-25 01:16:05.246915 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.03 seconds
2023-06-25 01:16:05.246915 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_public".
2023-06-25 01:16:05.246915 (ThreadPoolExecutor-1_0): On list_postgres_public: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "list_postgres_public"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2023-06-25 01:16:05.249913 (ThreadPoolExecutor-1_0): SQL status: SELECT 2 in 0.00 seconds
2023-06-25 01:16:05.250913 (ThreadPoolExecutor-1_0): On list_postgres_public: ROLLBACK
2023-06-25 01:16:05.256915 (MainThread): Using postgres connection "master".
2023-06-25 01:16:05.256915 (MainThread): On master: BEGIN
2023-06-25 01:16:05.284413 (MainThread): SQL status: BEGIN in 0.03 seconds
2023-06-25 01:16:05.284413 (MainThread): Using postgres connection "master".
2023-06-25 01:16:05.284413 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2023-06-25 01:16:05.288413 (MainThread): SQL status: SELECT 1 in 0.00 seconds
2023-06-25 01:16:05.289414 (MainThread): On master: ROLLBACK
2023-06-25 01:16:05.289414 (MainThread): Using postgres connection "master".
2023-06-25 01:16:05.289414 (MainThread): On master: BEGIN
2023-06-25 01:16:05.289913 (MainThread): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:16:05.289913 (MainThread): On master: COMMIT
2023-06-25 01:16:05.289913 (MainThread): Using postgres connection "master".
2023-06-25 01:16:05.289913 (MainThread): On master: COMMIT
2023-06-25 01:16:05.290413 (MainThread): SQL status: COMMIT in 0.00 seconds
2023-06-25 01:16:05.290413 (MainThread): 21:16:05 | Concurrency: 1 threads (target='dev')
2023-06-25 01:16:05.290413 (MainThread): 21:16:05 | 
2023-06-25 01:16:05.291914 (Thread-1): Began running node model.transform_data.transform_data
2023-06-25 01:16:05.291914 (Thread-1): 21:16:05 | 1 of 1 START view model public.transform_data........................ [RUN]
2023-06-25 01:16:05.291914 (Thread-1): Acquiring new postgres connection "model.transform_data.transform_data".
2023-06-25 01:16:05.291914 (Thread-1): Opening a new connection, currently in state init
2023-06-25 01:16:05.292413 (Thread-1): Compiling model.transform_data.transform_data
2023-06-25 01:16:05.301413 (Thread-1): Writing injected SQL for node "model.transform_data.transform_data"
2023-06-25 01:16:05.301913 (Thread-1): finished collecting timing info
2023-06-25 01:16:05.322413 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:16:05.322413 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */
drop view if exists "postgres"."public"."transform_data__dbt_tmp" cascade
2023-06-25 01:16:05.350413 (Thread-1): SQL status: DROP VIEW in 0.03 seconds
2023-06-25 01:16:05.352413 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:16:05.352413 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */
drop view if exists "postgres"."public"."transform_data__dbt_backup" cascade
2023-06-25 01:16:05.352413 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2023-06-25 01:16:05.353413 (Thread-1): Writing runtime SQL for node "model.transform_data.transform_data"
2023-06-25 01:16:05.353913 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:16:05.353913 (Thread-1): On model.transform_data.transform_data: BEGIN
2023-06-25 01:16:05.354414 (Thread-1): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:16:05.354414 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:16:05.354414 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */

  create view "postgres"."public"."transform_data__dbt_tmp" as (
    -- Insert transformed and filtered data into the table
INSERT INTO public.transactions ("address", "amount", "timestamp")
SELECT
  address,
  amount,
  timestamp
FROM
  public.transactions -- Assuming 'public.transactions' is the source table

-- Apply transformation/filtering logic
WHERE
  timestamp > CURRENT_TIMESTAMP - INTERVAL '2 years';
  );

2023-06-25 01:16:05.354414 (Thread-1): Postgres error: syntax error at or near "INSERT"
LINE 5: INSERT INTO public.transactions ("address", "amount", "times...
        ^

2023-06-25 01:16:05.354913 (Thread-1): On model.transform_data.transform_data: ROLLBACK
2023-06-25 01:16:05.354913 (Thread-1): finished collecting timing info
2023-06-25 01:16:05.354913 (Thread-1): Database Error in model transform_data (models\transformations\transform_data.sql)
  syntax error at or near "INSERT"
  LINE 5: INSERT INTO public.transactions ("address", "amount", "times...
          ^
  compiled SQL at target\run\transform_data\transformations\transform_data.sql
Traceback (most recent call last):
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\postgres\connections.py", line 46, in exception_handler
    yield
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near "INSERT"
LINE 5: INSERT INTO public.transactions ("address", "amount", "times...
        ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 223, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 166, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 268, in run
    return self.execute(compiled_node, manifest)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 450, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 60, in macro
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\base\impl.py", line 220, in execute
    fetch=fetch
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 116, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 82, in add_query
    return connection, cursor
  File "c:\users\me\appdata\local\programs\python\python37\lib\contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\postgres\connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model transform_data (models\transformations\transform_data.sql)
  syntax error at or near "INSERT"
  LINE 5: INSERT INTO public.transactions ("address", "amount", "times...
          ^
  compiled SQL at target\run\transform_data\transformations\transform_data.sql
2023-06-25 01:16:05.356913 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0af1eff0-5878-416b-bf50-f22795d5d435', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F6DFFC2470>]}
2023-06-25 01:16:05.356913 (Thread-1): 21:16:05 | 1 of 1 ERROR creating view model public.transform_data............... [ERROR in 0.06s]
2023-06-25 01:16:05.356913 (Thread-1): Finished running node model.transform_data.transform_data
2023-06-25 01:16:05.395737 (MainThread): Using postgres connection "master".
2023-06-25 01:16:05.396237 (MainThread): On master: BEGIN
2023-06-25 01:16:05.396237 (MainThread): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:16:05.396237 (MainThread): On master: COMMIT
2023-06-25 01:16:05.396237 (MainThread): Using postgres connection "master".
2023-06-25 01:16:05.396237 (MainThread): On master: COMMIT
2023-06-25 01:16:05.396737 (MainThread): SQL status: COMMIT in 0.00 seconds
2023-06-25 01:16:05.396737 (MainThread): 21:16:05 | 
2023-06-25 01:16:05.396737 (MainThread): 21:16:05 | Finished running 1 view model in 0.27s.
2023-06-25 01:16:05.396737 (MainThread): Connection 'master' was left open.
2023-06-25 01:16:05.396737 (MainThread): On master: Close
2023-06-25 01:16:05.397237 (MainThread): Connection 'list_postgres' was left open.
2023-06-25 01:16:05.397237 (MainThread): On list_postgres: Close
2023-06-25 01:16:05.397237 (MainThread): Connection 'list_postgres_public' was left open.
2023-06-25 01:16:05.397237 (MainThread): On list_postgres_public: Close
2023-06-25 01:16:05.397237 (MainThread): Connection 'model.transform_data.transform_data' was left open.
2023-06-25 01:16:05.397237 (MainThread): On model.transform_data.transform_data: Close
2023-06-25 01:16:05.399737 (MainThread): 
2023-06-25 01:16:05.399737 (MainThread): Completed with 1 error and 0 warnings:
2023-06-25 01:16:05.399737 (MainThread): 
2023-06-25 01:16:05.399737 (MainThread): Database Error in model transform_data (models\transformations\transform_data.sql)
2023-06-25 01:16:05.399737 (MainThread):   syntax error at or near "INSERT"
2023-06-25 01:16:05.400237 (MainThread):   LINE 5: INSERT INTO public.transactions ("address", "amount", "times...
2023-06-25 01:16:05.400237 (MainThread):           ^
2023-06-25 01:16:05.400237 (MainThread):   compiled SQL at target\run\transform_data\transformations\transform_data.sql
2023-06-25 01:16:05.400237 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2023-06-25 01:16:05.400237 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F6DFEF5390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F6DFEA2C50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F6E01EBF60>]}
2023-06-25 01:16:05.400237 (MainThread): Flushing usage events
2023-06-25 01:17:07.893001 (MainThread): Running with dbt=0.16.0
2023-06-25 01:17:07.930501 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=['+transformations.transform_data'], partial_parse=None, profile=None, profiles_dir='C:\\Users\\Me\\.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2023-06-25 01:17:07.930501 (MainThread): Tracking: tracking
2023-06-25 01:17:07.931001 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002490F90C8D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002490F8F00B8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002490F8F0908>]}
2023-06-25 01:17:07.942501 (MainThread): Partial parsing not enabled
2023-06-25 01:17:07.945002 (MainThread): Parsing macros\core.sql
2023-06-25 01:17:07.949001 (MainThread): Parsing macros\adapters\common.sql
2023-06-25 01:17:07.980001 (MainThread): Parsing macros\etc\datetime.sql
2023-06-25 01:17:07.987001 (MainThread): Parsing macros\etc\get_custom_alias.sql
2023-06-25 01:17:07.987501 (MainThread): Parsing macros\etc\get_custom_database.sql
2023-06-25 01:17:07.988501 (MainThread): Parsing macros\etc\get_custom_schema.sql
2023-06-25 01:17:07.990002 (MainThread): Parsing macros\etc\get_relation_comment.sql
2023-06-25 01:17:07.991501 (MainThread): Parsing macros\etc\is_incremental.sql
2023-06-25 01:17:07.993001 (MainThread): Parsing macros\etc\query.sql
2023-06-25 01:17:07.994001 (MainThread): Parsing macros\materializations\helpers.sql
2023-06-25 01:17:07.999501 (MainThread): Parsing macros\materializations\common\merge.sql
2023-06-25 01:17:08.009001 (MainThread): Parsing macros\materializations\incremental\helpers.sql
2023-06-25 01:17:08.010501 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2023-06-25 01:17:08.015001 (MainThread): Parsing macros\materializations\seed\seed.sql
2023-06-25 01:17:08.030001 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2023-06-25 01:17:08.054501 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2023-06-25 01:17:08.056001 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2023-06-25 01:17:08.068502 (MainThread): Parsing macros\materializations\table\table.sql
2023-06-25 01:17:08.073501 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2023-06-25 01:17:08.077001 (MainThread): Parsing macros\materializations\view\view.sql
2023-06-25 01:17:08.081501 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2023-06-25 01:17:08.083001 (MainThread): Parsing macros\schema_tests\not_null.sql
2023-06-25 01:17:08.084001 (MainThread): Parsing macros\schema_tests\relationships.sql
2023-06-25 01:17:08.085001 (MainThread): Parsing macros\schema_tests\unique.sql
2023-06-25 01:17:08.086001 (MainThread): Parsing macros\adapters.sql
2023-06-25 01:17:08.099001 (MainThread): Parsing macros\catalog.sql
2023-06-25 01:17:08.100501 (MainThread): Parsing macros\relations.sql
2023-06-25 01:17:08.101501 (MainThread): Parsing macros\materializations\snapshot_merge.sql
2023-06-25 01:17:08.114500 (MainThread): Partial parsing not enabled
2023-06-25 01:17:08.133001 (MainThread): Acquiring new postgres connection "model.transform_data.transform_data".
2023-06-25 01:17:08.133001 (MainThread): Opening a new connection, currently in state init
2023-06-25 01:17:08.281501 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:17:08.282001 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:17:08.282001 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:17:08.282001 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:17:08.282001 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:17:08.282001 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:17:08.282001 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:17:08.283502 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:17:08.284002 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:17:08.285001 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:17:08.286501 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:17:08.287501 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:17:08.288001 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:17:08.288501 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:17:08.290001 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:17:08.290501 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:17:08.291001 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:17:08.292002 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:17:08.292501 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:17:08.293501 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:17:08.294501 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:17:08.297001 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:17:08.300501 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:17:08.301501 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:17:08.302501 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:17:08.303501 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:17:08.304001 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:17:08.311501 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:17:08.315002 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:17:08.315002 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:17:08.316501 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:17:08.332001 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:17:08.333002 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:17:08.335001 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:17:08.368001 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:17:08.372501 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:17:08.373001 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:17:08.386002 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:17:08.388501 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:17:08.404001 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:17:08.405001 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:17:08.418001 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:17:08.434501 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:17:08.435501 (MainThread): scipy not found, skipping conversion test.
2023-06-25 01:17:08.436501 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2023-06-25 01:17:08.437001 (MainThread): Found 1 model, 0 tests, 0 snapshots, 0 analyses, 127 macros, 0 operations, 0 seed files, 0 sources
2023-06-25 01:17:08.437501 (MainThread): 
2023-06-25 01:17:08.438001 (MainThread): Acquiring new postgres connection "master".
2023-06-25 01:17:08.438001 (MainThread): Opening a new connection, currently in state init
2023-06-25 01:17:08.441502 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2023-06-25 01:17:08.441502 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2023-06-25 01:17:08.496501 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2023-06-25 01:17:08.496501 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2023-06-25 01:17:08.527001 (ThreadPoolExecutor-0_0): SQL status: SELECT 5 in 0.03 seconds
2023-06-25 01:17:08.532501 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_public".
2023-06-25 01:17:08.532501 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2023-06-25 01:17:08.533501 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_public".
2023-06-25 01:17:08.533501 (ThreadPoolExecutor-1_0): On list_postgres_public: BEGIN
2023-06-25 01:17:08.562001 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.03 seconds
2023-06-25 01:17:08.562501 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_public".
2023-06-25 01:17:08.562501 (ThreadPoolExecutor-1_0): On list_postgres_public: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "list_postgres_public"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2023-06-25 01:17:08.565501 (ThreadPoolExecutor-1_0): SQL status: SELECT 2 in 0.00 seconds
2023-06-25 01:17:08.566502 (ThreadPoolExecutor-1_0): On list_postgres_public: ROLLBACK
2023-06-25 01:17:08.572501 (MainThread): Using postgres connection "master".
2023-06-25 01:17:08.572501 (MainThread): On master: BEGIN
2023-06-25 01:17:08.601001 (MainThread): SQL status: BEGIN in 0.03 seconds
2023-06-25 01:17:08.601001 (MainThread): Using postgres connection "master".
2023-06-25 01:17:08.601001 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2023-06-25 01:17:08.605001 (MainThread): SQL status: SELECT 1 in 0.00 seconds
2023-06-25 01:17:08.606001 (MainThread): On master: ROLLBACK
2023-06-25 01:17:08.606501 (MainThread): Using postgres connection "master".
2023-06-25 01:17:08.606501 (MainThread): On master: BEGIN
2023-06-25 01:17:08.606501 (MainThread): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:17:08.606501 (MainThread): On master: COMMIT
2023-06-25 01:17:08.606501 (MainThread): Using postgres connection "master".
2023-06-25 01:17:08.607001 (MainThread): On master: COMMIT
2023-06-25 01:17:08.607001 (MainThread): SQL status: COMMIT in 0.00 seconds
2023-06-25 01:17:08.607001 (MainThread): 21:17:08 | Concurrency: 1 threads (target='dev')
2023-06-25 01:17:08.607001 (MainThread): 21:17:08 | 
2023-06-25 01:17:08.608502 (Thread-1): Began running node model.transform_data.transform_data
2023-06-25 01:17:08.609001 (Thread-1): 21:17:08 | 1 of 1 START view model public.transform_data........................ [RUN]
2023-06-25 01:17:08.609001 (Thread-1): Acquiring new postgres connection "model.transform_data.transform_data".
2023-06-25 01:17:08.609001 (Thread-1): Opening a new connection, currently in state init
2023-06-25 01:17:08.609001 (Thread-1): Compiling model.transform_data.transform_data
2023-06-25 01:17:08.618501 (Thread-1): Writing injected SQL for node "model.transform_data.transform_data"
2023-06-25 01:17:08.619001 (Thread-1): finished collecting timing info
2023-06-25 01:17:08.639501 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:17:08.639501 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */
drop view if exists "postgres"."public"."transform_data__dbt_tmp" cascade
2023-06-25 01:17:08.667785 (Thread-1): SQL status: DROP VIEW in 0.03 seconds
2023-06-25 01:17:08.669255 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:17:08.669255 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */
drop view if exists "postgres"."public"."transform_data__dbt_backup" cascade
2023-06-25 01:17:08.669255 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2023-06-25 01:17:08.670256 (Thread-1): Writing runtime SQL for node "model.transform_data.transform_data"
2023-06-25 01:17:08.670756 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:17:08.671255 (Thread-1): On model.transform_data.transform_data: BEGIN
2023-06-25 01:17:08.671255 (Thread-1): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:17:08.671255 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:17:08.671255 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */

  create view "postgres"."public"."transform_data__dbt_tmp" as (
    -- Clear the table before loading new data
TRUNCATE TABLE public.transactions;

-- Insert transformed and filtered data into the table
INSERT INTO public.transactions ("address", "amount", "timestamp")
SELECT
  address,
  amount,
  timestamp
FROM
  public.transactions -- Assuming 'public.transactions' is the source table
WHERE
  timestamp > CURRENT_TIMESTAMP - INTERVAL '2 years';
  );

2023-06-25 01:17:08.671799 (Thread-1): Postgres error: syntax error at or near "TRUNCATE"
LINE 5: TRUNCATE TABLE public.transactions;
        ^

2023-06-25 01:17:08.671799 (Thread-1): On model.transform_data.transform_data: ROLLBACK
2023-06-25 01:17:08.672256 (Thread-1): finished collecting timing info
2023-06-25 01:17:08.672256 (Thread-1): Database Error in model transform_data (models\transformations\transform_data.sql)
  syntax error at or near "TRUNCATE"
  LINE 5: TRUNCATE TABLE public.transactions;
          ^
  compiled SQL at target\run\transform_data\transformations\transform_data.sql
Traceback (most recent call last):
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\postgres\connections.py", line 46, in exception_handler
    yield
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near "TRUNCATE"
LINE 5: TRUNCATE TABLE public.transactions;
        ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 223, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 166, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 268, in run
    return self.execute(compiled_node, manifest)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 450, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 60, in macro
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\base\impl.py", line 220, in execute
    fetch=fetch
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 116, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 82, in add_query
    return connection, cursor
  File "c:\users\me\appdata\local\programs\python\python37\lib\contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\postgres\connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model transform_data (models\transformations\transform_data.sql)
  syntax error at or near "TRUNCATE"
  LINE 5: TRUNCATE TABLE public.transactions;
          ^
  compiled SQL at target\run\transform_data\transformations\transform_data.sql
2023-06-25 01:17:08.673755 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a30521ae-accb-42f0-b00b-4ca5cebef478', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024913662518>]}
2023-06-25 01:17:08.674256 (Thread-1): 21:17:08 | 1 of 1 ERROR creating view model public.transform_data............... [ERROR in 0.06s]
2023-06-25 01:17:08.674256 (Thread-1): Finished running node model.transform_data.transform_data
2023-06-25 01:17:08.716704 (MainThread): Using postgres connection "master".
2023-06-25 01:17:08.716704 (MainThread): On master: BEGIN
2023-06-25 01:17:08.717204 (MainThread): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:17:08.717204 (MainThread): On master: COMMIT
2023-06-25 01:17:08.717204 (MainThread): Using postgres connection "master".
2023-06-25 01:17:08.717204 (MainThread): On master: COMMIT
2023-06-25 01:17:08.717704 (MainThread): SQL status: COMMIT in 0.00 seconds
2023-06-25 01:17:08.717704 (MainThread): 21:17:08 | 
2023-06-25 01:17:08.717704 (MainThread): 21:17:08 | Finished running 1 view model in 0.28s.
2023-06-25 01:17:08.717704 (MainThread): Connection 'master' was left open.
2023-06-25 01:17:08.717704 (MainThread): On master: Close
2023-06-25 01:17:08.718203 (MainThread): Connection 'list_postgres' was left open.
2023-06-25 01:17:08.718203 (MainThread): On list_postgres: Close
2023-06-25 01:17:08.718203 (MainThread): Connection 'list_postgres_public' was left open.
2023-06-25 01:17:08.718203 (MainThread): On list_postgres_public: Close
2023-06-25 01:17:08.718203 (MainThread): Connection 'model.transform_data.transform_data' was left open.
2023-06-25 01:17:08.718203 (MainThread): On model.transform_data.transform_data: Close
2023-06-25 01:17:08.720703 (MainThread): 
2023-06-25 01:17:08.721204 (MainThread): Completed with 1 error and 0 warnings:
2023-06-25 01:17:08.721204 (MainThread): 
2023-06-25 01:17:08.721204 (MainThread): Database Error in model transform_data (models\transformations\transform_data.sql)
2023-06-25 01:17:08.721204 (MainThread):   syntax error at or near "TRUNCATE"
2023-06-25 01:17:08.721204 (MainThread):   LINE 5: TRUNCATE TABLE public.transactions;
2023-06-25 01:17:08.721204 (MainThread):           ^
2023-06-25 01:17:08.721204 (MainThread):   compiled SQL at target\run\transform_data\transformations\transform_data.sql
2023-06-25 01:17:08.721204 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2023-06-25 01:17:08.721704 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002491359A4E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024913542C88>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024913680CC0>]}
2023-06-25 01:17:08.721704 (MainThread): Flushing usage events
2023-06-25 01:17:27.263496 (MainThread): Running with dbt=0.16.0
2023-06-25 01:17:27.301464 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='C:\\Users\\Me\\.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target='dev', test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2023-06-25 01:17:27.301965 (MainThread): Tracking: tracking
2023-06-25 01:17:27.302965 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F75154FF98>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F75154FA20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F75154F1D0>]}
2023-06-25 01:17:27.313965 (MainThread): Partial parsing not enabled
2023-06-25 01:17:27.316465 (MainThread): Parsing macros\core.sql
2023-06-25 01:17:27.319965 (MainThread): Parsing macros\adapters\common.sql
2023-06-25 01:17:27.351465 (MainThread): Parsing macros\etc\datetime.sql
2023-06-25 01:17:27.357965 (MainThread): Parsing macros\etc\get_custom_alias.sql
2023-06-25 01:17:27.358965 (MainThread): Parsing macros\etc\get_custom_database.sql
2023-06-25 01:17:27.359965 (MainThread): Parsing macros\etc\get_custom_schema.sql
2023-06-25 01:17:27.361465 (MainThread): Parsing macros\etc\get_relation_comment.sql
2023-06-25 01:17:27.362965 (MainThread): Parsing macros\etc\is_incremental.sql
2023-06-25 01:17:27.364465 (MainThread): Parsing macros\etc\query.sql
2023-06-25 01:17:27.364965 (MainThread): Parsing macros\materializations\helpers.sql
2023-06-25 01:17:27.370965 (MainThread): Parsing macros\materializations\common\merge.sql
2023-06-25 01:17:27.380965 (MainThread): Parsing macros\materializations\incremental\helpers.sql
2023-06-25 01:17:27.382465 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2023-06-25 01:17:27.386964 (MainThread): Parsing macros\materializations\seed\seed.sql
2023-06-25 01:17:27.402965 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2023-06-25 01:17:27.427965 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2023-06-25 01:17:27.429465 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2023-06-25 01:17:27.441965 (MainThread): Parsing macros\materializations\table\table.sql
2023-06-25 01:17:27.446964 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2023-06-25 01:17:27.450464 (MainThread): Parsing macros\materializations\view\view.sql
2023-06-25 01:17:27.455465 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2023-06-25 01:17:27.456965 (MainThread): Parsing macros\schema_tests\not_null.sql
2023-06-25 01:17:27.457465 (MainThread): Parsing macros\schema_tests\relationships.sql
2023-06-25 01:17:27.458465 (MainThread): Parsing macros\schema_tests\unique.sql
2023-06-25 01:17:27.459965 (MainThread): Parsing macros\adapters.sql
2023-06-25 01:17:27.472965 (MainThread): Parsing macros\catalog.sql
2023-06-25 01:17:27.474465 (MainThread): Parsing macros\relations.sql
2023-06-25 01:17:27.475965 (MainThread): Parsing macros\materializations\snapshot_merge.sql
2023-06-25 01:17:27.488465 (MainThread): Partial parsing not enabled
2023-06-25 01:17:27.507965 (MainThread): Acquiring new postgres connection "model.transform_data.transform_data".
2023-06-25 01:17:27.507965 (MainThread): Opening a new connection, currently in state init
2023-06-25 01:17:27.728965 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:17:27.728965 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:17:27.728965 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:17:27.728965 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:17:27.728965 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:17:27.728965 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:17:27.728965 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:17:27.760465 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:17:27.760965 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:17:27.882965 (MainThread): scipy not found, skipping conversion test.
2023-06-25 01:17:27.883966 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2023-06-25 01:17:27.883966 (MainThread): Found 1 model, 0 tests, 0 snapshots, 0 analyses, 127 macros, 0 operations, 0 seed files, 0 sources
2023-06-25 01:17:27.884965 (MainThread): 
2023-06-25 01:17:27.885465 (MainThread): Acquiring new postgres connection "master".
2023-06-25 01:17:27.885465 (MainThread): Opening a new connection, currently in state init
2023-06-25 01:17:27.888965 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2023-06-25 01:17:27.889464 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2023-06-25 01:17:27.944494 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2023-06-25 01:17:27.944494 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2023-06-25 01:17:27.974965 (ThreadPoolExecutor-0_0): SQL status: SELECT 5 in 0.03 seconds
2023-06-25 01:17:27.980466 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_public".
2023-06-25 01:17:27.980466 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2023-06-25 01:17:27.981465 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_public".
2023-06-25 01:17:27.981465 (ThreadPoolExecutor-1_0): On list_postgres_public: BEGIN
2023-06-25 01:17:28.009965 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.03 seconds
2023-06-25 01:17:28.009965 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_public".
2023-06-25 01:17:28.009965 (ThreadPoolExecutor-1_0): On list_postgres_public: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "list_postgres_public"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2023-06-25 01:17:28.012965 (ThreadPoolExecutor-1_0): SQL status: SELECT 2 in 0.00 seconds
2023-06-25 01:17:28.013964 (ThreadPoolExecutor-1_0): On list_postgres_public: ROLLBACK
2023-06-25 01:17:28.019965 (MainThread): Using postgres connection "master".
2023-06-25 01:17:28.019965 (MainThread): On master: BEGIN
2023-06-25 01:17:28.047965 (MainThread): SQL status: BEGIN in 0.03 seconds
2023-06-25 01:17:28.047965 (MainThread): Using postgres connection "master".
2023-06-25 01:17:28.047965 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2023-06-25 01:17:28.051465 (MainThread): SQL status: SELECT 1 in 0.00 seconds
2023-06-25 01:17:28.052964 (MainThread): On master: ROLLBACK
2023-06-25 01:17:28.052964 (MainThread): Using postgres connection "master".
2023-06-25 01:17:28.052964 (MainThread): On master: BEGIN
2023-06-25 01:17:28.053465 (MainThread): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:17:28.053465 (MainThread): On master: COMMIT
2023-06-25 01:17:28.053465 (MainThread): Using postgres connection "master".
2023-06-25 01:17:28.053465 (MainThread): On master: COMMIT
2023-06-25 01:17:28.053465 (MainThread): SQL status: COMMIT in 0.00 seconds
2023-06-25 01:17:28.053965 (MainThread): 21:17:28 | Concurrency: 1 threads (target='dev')
2023-06-25 01:17:28.053965 (MainThread): 21:17:28 | 
2023-06-25 01:17:28.055965 (Thread-1): Began running node model.transform_data.transform_data
2023-06-25 01:17:28.055965 (Thread-1): 21:17:28 | 1 of 1 START view model public.transform_data........................ [RUN]
2023-06-25 01:17:28.055965 (Thread-1): Acquiring new postgres connection "model.transform_data.transform_data".
2023-06-25 01:17:28.056464 (Thread-1): Opening a new connection, currently in state init
2023-06-25 01:17:28.056464 (Thread-1): Compiling model.transform_data.transform_data
2023-06-25 01:17:28.065964 (Thread-1): Writing injected SQL for node "model.transform_data.transform_data"
2023-06-25 01:17:28.066465 (Thread-1): finished collecting timing info
2023-06-25 01:17:28.086464 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:17:28.086464 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */
drop view if exists "postgres"."public"."transform_data__dbt_tmp" cascade
2023-06-25 01:17:28.114966 (Thread-1): SQL status: DROP VIEW in 0.03 seconds
2023-06-25 01:17:28.116496 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:17:28.116496 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */
drop view if exists "postgres"."public"."transform_data__dbt_backup" cascade
2023-06-25 01:17:28.116965 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2023-06-25 01:17:28.117494 (Thread-1): Writing runtime SQL for node "model.transform_data.transform_data"
2023-06-25 01:17:28.118468 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:17:28.118468 (Thread-1): On model.transform_data.transform_data: BEGIN
2023-06-25 01:17:28.118468 (Thread-1): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:17:28.118468 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:17:28.118468 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */

  create view "postgres"."public"."transform_data__dbt_tmp" as (
    -- Clear the table before loading new data
TRUNCATE TABLE public.transactions;

-- Insert transformed and filtered data into the table
INSERT INTO public.transactions ("address", "amount", "timestamp")
SELECT
  address,
  amount,
  timestamp
FROM
  public.transactions -- Assuming 'public.transactions' is the source table
WHERE
  timestamp > CURRENT_TIMESTAMP - INTERVAL '2 years';
  );

2023-06-25 01:17:28.118995 (Thread-1): Postgres error: syntax error at or near "TRUNCATE"
LINE 5: TRUNCATE TABLE public.transactions;
        ^

2023-06-25 01:17:28.118995 (Thread-1): On model.transform_data.transform_data: ROLLBACK
2023-06-25 01:17:28.118995 (Thread-1): finished collecting timing info
2023-06-25 01:17:28.119466 (Thread-1): Database Error in model transform_data (models\transformations\transform_data.sql)
  syntax error at or near "TRUNCATE"
  LINE 5: TRUNCATE TABLE public.transactions;
          ^
  compiled SQL at target\run\transform_data\transformations\transform_data.sql
Traceback (most recent call last):
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\postgres\connections.py", line 46, in exception_handler
    yield
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near "TRUNCATE"
LINE 5: TRUNCATE TABLE public.transactions;
        ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 223, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 166, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 268, in run
    return self.execute(compiled_node, manifest)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 450, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 60, in macro
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\base\impl.py", line 220, in execute
    fetch=fetch
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 116, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 82, in add_query
    return connection, cursor
  File "c:\users\me\appdata\local\programs\python\python37\lib\contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\postgres\connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model transform_data (models\transformations\transform_data.sql)
  syntax error at or near "TRUNCATE"
  LINE 5: TRUNCATE TABLE public.transactions;
          ^
  compiled SQL at target\run\transform_data\transformations\transform_data.sql
2023-06-25 01:17:28.120965 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd5f180ba-b536-4328-aec1-139bfee7d175', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F77971E400>]}
2023-06-25 01:17:28.121464 (Thread-1): 21:17:28 | 1 of 1 ERROR creating view model public.transform_data............... [ERROR in 0.07s]
2023-06-25 01:17:28.121965 (Thread-1): Finished running node model.transform_data.transform_data
2023-06-25 01:17:28.167197 (MainThread): Using postgres connection "master".
2023-06-25 01:17:28.167197 (MainThread): On master: BEGIN
2023-06-25 01:17:28.167197 (MainThread): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:17:28.167197 (MainThread): On master: COMMIT
2023-06-25 01:17:28.167197 (MainThread): Using postgres connection "master".
2023-06-25 01:17:28.167696 (MainThread): On master: COMMIT
2023-06-25 01:17:28.167696 (MainThread): SQL status: COMMIT in 0.00 seconds
2023-06-25 01:17:28.167696 (MainThread): 21:17:28 | 
2023-06-25 01:17:28.168196 (MainThread): 21:17:28 | Finished running 1 view model in 0.28s.
2023-06-25 01:17:28.168196 (MainThread): Connection 'master' was left open.
2023-06-25 01:17:28.168196 (MainThread): On master: Close
2023-06-25 01:17:28.168196 (MainThread): Connection 'list_postgres' was left open.
2023-06-25 01:17:28.168696 (MainThread): On list_postgres: Close
2023-06-25 01:17:28.168696 (MainThread): Connection 'list_postgres_public' was left open.
2023-06-25 01:17:28.168696 (MainThread): On list_postgres_public: Close
2023-06-25 01:17:28.168696 (MainThread): Connection 'model.transform_data.transform_data' was left open.
2023-06-25 01:17:28.168696 (MainThread): On model.transform_data.transform_data: Close
2023-06-25 01:17:28.171197 (MainThread): 
2023-06-25 01:17:28.171197 (MainThread): Completed with 1 error and 0 warnings:
2023-06-25 01:17:28.171697 (MainThread): 
2023-06-25 01:17:28.171697 (MainThread): Database Error in model transform_data (models\transformations\transform_data.sql)
2023-06-25 01:17:28.172197 (MainThread):   syntax error at or near "TRUNCATE"
2023-06-25 01:17:28.172197 (MainThread):   LINE 5: TRUNCATE TABLE public.transactions;
2023-06-25 01:17:28.172197 (MainThread):           ^
2023-06-25 01:17:28.172696 (MainThread):   compiled SQL at target\run\transform_data\transformations\transform_data.sql
2023-06-25 01:17:28.172696 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2023-06-25 01:17:28.173196 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F779B24588>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F751780F60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F779BA3438>]}
2023-06-25 01:17:28.173196 (MainThread): Flushing usage events
2023-06-25 01:17:40.629227 (MainThread): Running with dbt=0.16.0
2023-06-25 01:17:40.666228 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='C:\\Users\\Me\\.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target='dev', test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2023-06-25 01:17:40.666727 (MainThread): Tracking: tracking
2023-06-25 01:17:40.667727 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E66F8CA710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E66F8CA390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E66F8CA9E8>]}
2023-06-25 01:17:40.678726 (MainThread): Partial parsing not enabled
2023-06-25 01:17:40.681227 (MainThread): Parsing macros\core.sql
2023-06-25 01:17:40.684727 (MainThread): Parsing macros\adapters\common.sql
2023-06-25 01:17:40.715727 (MainThread): Parsing macros\etc\datetime.sql
2023-06-25 01:17:40.722727 (MainThread): Parsing macros\etc\get_custom_alias.sql
2023-06-25 01:17:40.723227 (MainThread): Parsing macros\etc\get_custom_database.sql
2023-06-25 01:17:40.724228 (MainThread): Parsing macros\etc\get_custom_schema.sql
2023-06-25 01:17:40.725727 (MainThread): Parsing macros\etc\get_relation_comment.sql
2023-06-25 01:17:40.727727 (MainThread): Parsing macros\etc\is_incremental.sql
2023-06-25 01:17:40.728727 (MainThread): Parsing macros\etc\query.sql
2023-06-25 01:17:40.729727 (MainThread): Parsing macros\materializations\helpers.sql
2023-06-25 01:17:40.735227 (MainThread): Parsing macros\materializations\common\merge.sql
2023-06-25 01:17:40.745227 (MainThread): Parsing macros\materializations\incremental\helpers.sql
2023-06-25 01:17:40.746227 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2023-06-25 01:17:40.751227 (MainThread): Parsing macros\materializations\seed\seed.sql
2023-06-25 01:17:40.766727 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2023-06-25 01:17:40.791227 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2023-06-25 01:17:40.792727 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2023-06-25 01:17:40.805226 (MainThread): Parsing macros\materializations\table\table.sql
2023-06-25 01:17:40.810226 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2023-06-25 01:17:40.814226 (MainThread): Parsing macros\materializations\view\view.sql
2023-06-25 01:17:40.818726 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2023-06-25 01:17:40.820227 (MainThread): Parsing macros\schema_tests\not_null.sql
2023-06-25 01:17:40.820727 (MainThread): Parsing macros\schema_tests\relationships.sql
2023-06-25 01:17:40.821727 (MainThread): Parsing macros\schema_tests\unique.sql
2023-06-25 01:17:40.823228 (MainThread): Parsing macros\adapters.sql
2023-06-25 01:17:40.836227 (MainThread): Parsing macros\catalog.sql
2023-06-25 01:17:40.837727 (MainThread): Parsing macros\relations.sql
2023-06-25 01:17:40.838727 (MainThread): Parsing macros\materializations\snapshot_merge.sql
2023-06-25 01:17:40.851727 (MainThread): Partial parsing not enabled
2023-06-25 01:17:40.870227 (MainThread): Acquiring new postgres connection "model.transform_data.transform_data".
2023-06-25 01:17:40.870227 (MainThread): Opening a new connection, currently in state init
2023-06-25 01:17:41.087227 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:17:41.087227 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:17:41.087227 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:17:41.087727 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:17:41.087727 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:17:41.087727 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:17:41.087727 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:17:41.119227 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:17:41.119727 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:17:41.240227 (MainThread): scipy not found, skipping conversion test.
2023-06-25 01:17:41.241227 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2023-06-25 01:17:41.241727 (MainThread): Found 1 model, 0 tests, 0 snapshots, 0 analyses, 127 macros, 0 operations, 0 seed files, 0 sources
2023-06-25 01:17:41.242727 (MainThread): 
2023-06-25 01:17:41.242727 (MainThread): Acquiring new postgres connection "master".
2023-06-25 01:17:41.242727 (MainThread): Opening a new connection, currently in state init
2023-06-25 01:17:41.246227 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2023-06-25 01:17:41.246727 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2023-06-25 01:17:41.301727 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2023-06-25 01:17:41.301727 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2023-06-25 01:17:41.332227 (ThreadPoolExecutor-0_0): SQL status: SELECT 5 in 0.03 seconds
2023-06-25 01:17:41.337727 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_public".
2023-06-25 01:17:41.337727 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2023-06-25 01:17:41.338727 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_public".
2023-06-25 01:17:41.338727 (ThreadPoolExecutor-1_0): On list_postgres_public: BEGIN
2023-06-25 01:17:41.367727 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.03 seconds
2023-06-25 01:17:41.367727 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_public".
2023-06-25 01:17:41.367727 (ThreadPoolExecutor-1_0): On list_postgres_public: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "list_postgres_public"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2023-06-25 01:17:41.370727 (ThreadPoolExecutor-1_0): SQL status: SELECT 2 in 0.00 seconds
2023-06-25 01:17:41.372227 (ThreadPoolExecutor-1_0): On list_postgres_public: ROLLBACK
2023-06-25 01:17:41.377727 (MainThread): Using postgres connection "master".
2023-06-25 01:17:41.378227 (MainThread): On master: BEGIN
2023-06-25 01:17:41.406727 (MainThread): SQL status: BEGIN in 0.03 seconds
2023-06-25 01:17:41.406727 (MainThread): Using postgres connection "master".
2023-06-25 01:17:41.406727 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2023-06-25 01:17:41.410727 (MainThread): SQL status: SELECT 1 in 0.00 seconds
2023-06-25 01:17:41.411727 (MainThread): On master: ROLLBACK
2023-06-25 01:17:41.411727 (MainThread): Using postgres connection "master".
2023-06-25 01:17:41.412226 (MainThread): On master: BEGIN
2023-06-25 01:17:41.412226 (MainThread): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:17:41.412226 (MainThread): On master: COMMIT
2023-06-25 01:17:41.412727 (MainThread): Using postgres connection "master".
2023-06-25 01:17:41.412727 (MainThread): On master: COMMIT
2023-06-25 01:17:41.412727 (MainThread): SQL status: COMMIT in 0.00 seconds
2023-06-25 01:17:41.412727 (MainThread): 21:17:41 | Concurrency: 1 threads (target='dev')
2023-06-25 01:17:41.413227 (MainThread): 21:17:41 | 
2023-06-25 01:17:41.414727 (Thread-1): Began running node model.transform_data.transform_data
2023-06-25 01:17:41.414727 (Thread-1): 21:17:41 | 1 of 1 START view model public.transform_data........................ [RUN]
2023-06-25 01:17:41.415228 (Thread-1): Acquiring new postgres connection "model.transform_data.transform_data".
2023-06-25 01:17:41.415228 (Thread-1): Opening a new connection, currently in state init
2023-06-25 01:17:41.415228 (Thread-1): Compiling model.transform_data.transform_data
2023-06-25 01:17:41.424727 (Thread-1): Writing injected SQL for node "model.transform_data.transform_data"
2023-06-25 01:17:41.425227 (Thread-1): finished collecting timing info
2023-06-25 01:17:41.446227 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:17:41.446727 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */
drop view if exists "postgres"."public"."transform_data__dbt_tmp" cascade
2023-06-25 01:17:41.474227 (Thread-1): SQL status: DROP VIEW in 0.03 seconds
2023-06-25 01:17:41.475727 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:17:41.475727 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */
drop view if exists "postgres"."public"."transform_data__dbt_backup" cascade
2023-06-25 01:17:41.476227 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2023-06-25 01:17:41.477227 (Thread-1): Writing runtime SQL for node "model.transform_data.transform_data"
2023-06-25 01:17:41.477728 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:17:41.477728 (Thread-1): On model.transform_data.transform_data: BEGIN
2023-06-25 01:17:41.477728 (Thread-1): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:17:41.478227 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:17:41.478227 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */

  create view "postgres"."public"."transform_data__dbt_tmp" as (
    -- Insert transformed and filtered data into the table
INSERT INTO public.transactions ("address", "amount", "timestamp")
SELECT
  address,
  amount,
  timestamp
FROM
  public.transactions -- Assuming 'public.transactions' is the source table
WHERE
  timestamp > CURRENT_TIMESTAMP - INTERVAL '2 years';
  );

2023-06-25 01:17:41.478227 (Thread-1): Postgres error: syntax error at or near "INSERT"
LINE 5: INSERT INTO public.transactions ("address", "amount", "times...
        ^

2023-06-25 01:17:41.478227 (Thread-1): On model.transform_data.transform_data: ROLLBACK
2023-06-25 01:17:41.478727 (Thread-1): finished collecting timing info
2023-06-25 01:17:41.478727 (Thread-1): Database Error in model transform_data (models\transformations\transform_data.sql)
  syntax error at or near "INSERT"
  LINE 5: INSERT INTO public.transactions ("address", "amount", "times...
          ^
  compiled SQL at target\run\transform_data\transformations\transform_data.sql
Traceback (most recent call last):
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\postgres\connections.py", line 46, in exception_handler
    yield
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near "INSERT"
LINE 5: INSERT INTO public.transactions ("address", "amount", "times...
        ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 223, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 166, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 268, in run
    return self.execute(compiled_node, manifest)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 450, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 60, in macro
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\base\impl.py", line 220, in execute
    fetch=fetch
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 116, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 82, in add_query
    return connection, cursor
  File "c:\users\me\appdata\local\programs\python\python37\lib\contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\postgres\connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model transform_data (models\transformations\transform_data.sql)
  syntax error at or near "INSERT"
  LINE 5: INSERT INTO public.transactions ("address", "amount", "times...
          ^
  compiled SQL at target\run\transform_data\transformations\transform_data.sql
2023-06-25 01:17:41.480227 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '60431045-f230-48a9-8ed8-2c5751a8afe1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E67FEDC5F8>]}
2023-06-25 01:17:41.480727 (Thread-1): 21:17:41 | 1 of 1 ERROR creating view model public.transform_data............... [ERROR in 0.06s]
2023-06-25 01:17:41.480727 (Thread-1): Finished running node model.transform_data.transform_data
2023-06-25 01:17:41.529961 (MainThread): Using postgres connection "master".
2023-06-25 01:17:41.529961 (MainThread): On master: BEGIN
2023-06-25 01:17:41.530368 (MainThread): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:17:41.530368 (MainThread): On master: COMMIT
2023-06-25 01:17:41.530368 (MainThread): Using postgres connection "master".
2023-06-25 01:17:41.530368 (MainThread): On master: COMMIT
2023-06-25 01:17:41.530368 (MainThread): SQL status: COMMIT in 0.00 seconds
2023-06-25 01:17:41.530873 (MainThread): 21:17:41 | 
2023-06-25 01:17:41.530873 (MainThread): 21:17:41 | Finished running 1 view model in 0.29s.
2023-06-25 01:17:41.531373 (MainThread): Connection 'master' was left open.
2023-06-25 01:17:41.531373 (MainThread): On master: Close
2023-06-25 01:17:41.531373 (MainThread): Connection 'list_postgres' was left open.
2023-06-25 01:17:41.531373 (MainThread): On list_postgres: Close
2023-06-25 01:17:41.531872 (MainThread): Connection 'list_postgres_public' was left open.
2023-06-25 01:17:41.531872 (MainThread): On list_postgres_public: Close
2023-06-25 01:17:41.531872 (MainThread): Connection 'model.transform_data.transform_data' was left open.
2023-06-25 01:17:41.531872 (MainThread): On model.transform_data.transform_data: Close
2023-06-25 01:17:41.534372 (MainThread): 
2023-06-25 01:17:41.534372 (MainThread): Completed with 1 error and 0 warnings:
2023-06-25 01:17:41.534871 (MainThread): 
2023-06-25 01:17:41.534871 (MainThread): Database Error in model transform_data (models\transformations\transform_data.sql)
2023-06-25 01:17:41.535371 (MainThread):   syntax error at or near "INSERT"
2023-06-25 01:17:41.535371 (MainThread):   LINE 5: INSERT INTO public.transactions ("address", "amount", "times...
2023-06-25 01:17:41.535873 (MainThread):           ^
2023-06-25 01:17:41.535873 (MainThread):   compiled SQL at target\run\transform_data\transformations\transform_data.sql
2023-06-25 01:17:41.535873 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2023-06-25 01:17:41.536373 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E67FEC5470>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E66FB06978>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E67FEDCE80>]}
2023-06-25 01:17:41.536373 (MainThread): Flushing usage events
2023-06-25 01:18:26.156479 (MainThread): Running with dbt=0.16.0
2023-06-25 01:18:26.193981 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='C:\\Users\\Me\\.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target='dev', test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2023-06-25 01:18:26.194481 (MainThread): Tracking: tracking
2023-06-25 01:18:26.194981 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002875A31EE80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002875A31E978>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002875A31E208>]}
2023-06-25 01:18:26.206481 (MainThread): Partial parsing not enabled
2023-06-25 01:18:26.209982 (MainThread): Parsing macros\core.sql
2023-06-25 01:18:26.212981 (MainThread): Parsing macros\adapters\common.sql
2023-06-25 01:18:26.244981 (MainThread): Parsing macros\etc\datetime.sql
2023-06-25 01:18:26.251481 (MainThread): Parsing macros\etc\get_custom_alias.sql
2023-06-25 01:18:26.252482 (MainThread): Parsing macros\etc\get_custom_database.sql
2023-06-25 01:18:26.253482 (MainThread): Parsing macros\etc\get_custom_schema.sql
2023-06-25 01:18:26.254982 (MainThread): Parsing macros\etc\get_relation_comment.sql
2023-06-25 01:18:26.256481 (MainThread): Parsing macros\etc\is_incremental.sql
2023-06-25 01:18:26.257982 (MainThread): Parsing macros\etc\query.sql
2023-06-25 01:18:26.258482 (MainThread): Parsing macros\materializations\helpers.sql
2023-06-25 01:18:26.264481 (MainThread): Parsing macros\materializations\common\merge.sql
2023-06-25 01:18:26.273981 (MainThread): Parsing macros\materializations\incremental\helpers.sql
2023-06-25 01:18:26.275481 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2023-06-25 01:18:26.279981 (MainThread): Parsing macros\materializations\seed\seed.sql
2023-06-25 01:18:26.295981 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2023-06-25 01:18:26.321481 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2023-06-25 01:18:26.322982 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2023-06-25 01:18:26.335481 (MainThread): Parsing macros\materializations\table\table.sql
2023-06-25 01:18:26.340481 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2023-06-25 01:18:26.343981 (MainThread): Parsing macros\materializations\view\view.sql
2023-06-25 01:18:26.348981 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2023-06-25 01:18:26.350481 (MainThread): Parsing macros\schema_tests\not_null.sql
2023-06-25 01:18:26.351482 (MainThread): Parsing macros\schema_tests\relationships.sql
2023-06-25 01:18:26.351982 (MainThread): Parsing macros\schema_tests\unique.sql
2023-06-25 01:18:26.353482 (MainThread): Parsing macros\adapters.sql
2023-06-25 01:18:26.366481 (MainThread): Parsing macros\catalog.sql
2023-06-25 01:18:26.368482 (MainThread): Parsing macros\relations.sql
2023-06-25 01:18:26.369481 (MainThread): Parsing macros\materializations\snapshot_merge.sql
2023-06-25 01:18:26.382482 (MainThread): Partial parsing not enabled
2023-06-25 01:18:26.400981 (MainThread): Acquiring new postgres connection "model.transform_data.transform_data".
2023-06-25 01:18:26.400981 (MainThread): Opening a new connection, currently in state init
2023-06-25 01:18:26.622482 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:18:26.622482 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:18:26.622482 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:18:26.622482 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:18:26.622482 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:18:26.622482 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:18:26.622982 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:18:26.653982 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:18:26.654482 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:18:26.774982 (MainThread): scipy not found, skipping conversion test.
2023-06-25 01:18:26.775981 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2023-06-25 01:18:26.775981 (MainThread): Found 1 model, 0 tests, 0 snapshots, 0 analyses, 127 macros, 0 operations, 0 seed files, 0 sources
2023-06-25 01:18:26.776982 (MainThread): 
2023-06-25 01:18:26.776982 (MainThread): Acquiring new postgres connection "master".
2023-06-25 01:18:26.777482 (MainThread): Opening a new connection, currently in state init
2023-06-25 01:18:26.780980 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2023-06-25 01:18:26.780980 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2023-06-25 01:18:26.836012 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2023-06-25 01:18:26.836012 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2023-06-25 01:18:26.866982 (ThreadPoolExecutor-0_0): SQL status: SELECT 5 in 0.03 seconds
2023-06-25 01:18:26.872481 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_public".
2023-06-25 01:18:26.872481 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2023-06-25 01:18:26.873479 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_public".
2023-06-25 01:18:26.873479 (ThreadPoolExecutor-1_0): On list_postgres_public: BEGIN
2023-06-25 01:18:26.902481 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.03 seconds
2023-06-25 01:18:26.902981 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_public".
2023-06-25 01:18:26.902981 (ThreadPoolExecutor-1_0): On list_postgres_public: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "list_postgres_public"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2023-06-25 01:18:26.905981 (ThreadPoolExecutor-1_0): SQL status: SELECT 2 in 0.00 seconds
2023-06-25 01:18:26.907010 (ThreadPoolExecutor-1_0): On list_postgres_public: ROLLBACK
2023-06-25 01:18:26.912982 (MainThread): Using postgres connection "master".
2023-06-25 01:18:26.912982 (MainThread): On master: BEGIN
2023-06-25 01:18:26.941981 (MainThread): SQL status: BEGIN in 0.03 seconds
2023-06-25 01:18:26.941981 (MainThread): Using postgres connection "master".
2023-06-25 01:18:26.941981 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2023-06-25 01:18:26.945981 (MainThread): SQL status: SELECT 1 in 0.00 seconds
2023-06-25 01:18:26.946979 (MainThread): On master: ROLLBACK
2023-06-25 01:18:26.947480 (MainThread): Using postgres connection "master".
2023-06-25 01:18:26.947480 (MainThread): On master: BEGIN
2023-06-25 01:18:26.947480 (MainThread): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:18:26.947480 (MainThread): On master: COMMIT
2023-06-25 01:18:26.947980 (MainThread): Using postgres connection "master".
2023-06-25 01:18:26.947980 (MainThread): On master: COMMIT
2023-06-25 01:18:26.947980 (MainThread): SQL status: COMMIT in 0.00 seconds
2023-06-25 01:18:26.947980 (MainThread): 21:18:26 | Concurrency: 1 threads (target='dev')
2023-06-25 01:18:26.948480 (MainThread): 21:18:26 | 
2023-06-25 01:18:26.949980 (Thread-1): Began running node model.transform_data.transform_data
2023-06-25 01:18:26.949980 (Thread-1): 21:18:26 | 1 of 1 START view model public.transform_data........................ [RUN]
2023-06-25 01:18:26.950481 (Thread-1): Acquiring new postgres connection "model.transform_data.transform_data".
2023-06-25 01:18:26.950481 (Thread-1): Opening a new connection, currently in state init
2023-06-25 01:18:26.950481 (Thread-1): Compiling model.transform_data.transform_data
2023-06-25 01:18:26.959979 (Thread-1): Writing injected SQL for node "model.transform_data.transform_data"
2023-06-25 01:18:26.960479 (Thread-1): finished collecting timing info
2023-06-25 01:18:26.980509 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:18:26.980509 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */
drop view if exists "postgres"."public"."transform_data__dbt_tmp" cascade
2023-06-25 01:18:27.009482 (Thread-1): SQL status: DROP VIEW in 0.03 seconds
2023-06-25 01:18:27.011008 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:18:27.011008 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */
drop view if exists "postgres"."public"."transform_data__dbt_backup" cascade
2023-06-25 01:18:27.011482 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2023-06-25 01:18:27.012480 (Thread-1): Writing runtime SQL for node "model.transform_data.transform_data"
2023-06-25 01:18:27.013017 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:18:27.013017 (Thread-1): On model.transform_data.transform_data: BEGIN
2023-06-25 01:18:27.013017 (Thread-1): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:18:27.013017 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:18:27.013017 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */

  create view "postgres"."public"."transform_data__dbt_tmp" as (
    INSERT INTO public.transactions ("address", "amount", "timestamp")
SELECT
  "address",
  "amount",
  "timestamp"
FROM
  public.transactions
WHERE
  "timestamp" > CURRENT_TIMESTAMP - INTERVAL '2 years';
  );

2023-06-25 01:18:27.013508 (Thread-1): Postgres error: syntax error at or near "INSERT"
LINE 4:     INSERT INTO public.transactions ("address", "amount", "t...
            ^

2023-06-25 01:18:27.013508 (Thread-1): On model.transform_data.transform_data: ROLLBACK
2023-06-25 01:18:27.013982 (Thread-1): finished collecting timing info
2023-06-25 01:18:27.013982 (Thread-1): Database Error in model transform_data (models\transformations\transform_data.sql)
  syntax error at or near "INSERT"
  LINE 4:     INSERT INTO public.transactions ("address", "amount", "t...
              ^
  compiled SQL at target\run\transform_data\transformations\transform_data.sql
Traceback (most recent call last):
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\postgres\connections.py", line 46, in exception_handler
    yield
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near "INSERT"
LINE 4:     INSERT INTO public.transactions ("address", "amount", "t...
            ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 223, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 166, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 268, in run
    return self.execute(compiled_node, manifest)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 450, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 60, in macro
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\base\impl.py", line 220, in execute
    fetch=fetch
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 116, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 82, in add_query
    return connection, cursor
  File "c:\users\me\appdata\local\programs\python\python37\lib\contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\postgres\connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model transform_data (models\transformations\transform_data.sql)
  syntax error at or near "INSERT"
  LINE 4:     INSERT INTO public.transactions ("address", "amount", "t...
              ^
  compiled SQL at target\run\transform_data\transformations\transform_data.sql
2023-06-25 01:18:27.015481 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c985ca2d-57d2-4fd4-91e7-7740c398c015', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028702931BA8>]}
2023-06-25 01:18:27.015980 (Thread-1): 21:18:27 | 1 of 1 ERROR creating view model public.transform_data............... [ERROR in 0.07s]
2023-06-25 01:18:27.016481 (Thread-1): Finished running node model.transform_data.transform_data
2023-06-25 01:18:27.059693 (MainThread): Using postgres connection "master".
2023-06-25 01:18:27.060196 (MainThread): On master: BEGIN
2023-06-25 01:18:27.061193 (MainThread): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:18:27.061714 (MainThread): On master: COMMIT
2023-06-25 01:18:27.062212 (MainThread): Using postgres connection "master".
2023-06-25 01:18:27.062212 (MainThread): On master: COMMIT
2023-06-25 01:18:27.063193 (MainThread): SQL status: COMMIT in 0.00 seconds
2023-06-25 01:18:27.064214 (MainThread): 21:18:27 | 
2023-06-25 01:18:27.065658 (MainThread): 21:18:27 | Finished running 1 view model in 0.29s.
2023-06-25 01:18:27.066656 (MainThread): Connection 'master' was left open.
2023-06-25 01:18:27.066656 (MainThread): On master: Close
2023-06-25 01:18:27.067653 (MainThread): Connection 'list_postgres' was left open.
2023-06-25 01:18:27.068192 (MainThread): On list_postgres: Close
2023-06-25 01:18:27.068692 (MainThread): Connection 'list_postgres_public' was left open.
2023-06-25 01:18:27.069193 (MainThread): On list_postgres_public: Close
2023-06-25 01:18:27.069695 (MainThread): Connection 'model.transform_data.transform_data' was left open.
2023-06-25 01:18:27.070193 (MainThread): On model.transform_data.transform_data: Close
2023-06-25 01:18:27.073641 (MainThread): 
2023-06-25 01:18:27.074142 (MainThread): Completed with 1 error and 0 warnings:
2023-06-25 01:18:27.074142 (MainThread): 
2023-06-25 01:18:27.074641 (MainThread): Database Error in model transform_data (models\transformations\transform_data.sql)
2023-06-25 01:18:27.074641 (MainThread):   syntax error at or near "INSERT"
2023-06-25 01:18:27.075141 (MainThread):   LINE 4:     INSERT INTO public.transactions ("address", "amount", "t...
2023-06-25 01:18:27.075141 (MainThread):               ^
2023-06-25 01:18:27.075141 (MainThread):   compiled SQL at target\run\transform_data\transformations\transform_data.sql
2023-06-25 01:18:27.075641 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2023-06-25 01:18:27.075641 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002875A558780>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002875A5FB7F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000287029064E0>]}
2023-06-25 01:18:27.075641 (MainThread): Flushing usage events
2023-06-25 01:18:49.196620 (MainThread): Running with dbt=0.16.0
2023-06-25 01:18:49.233619 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='C:\\Users\\Me\\.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target='dev', test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2023-06-25 01:18:49.234120 (MainThread): Tracking: tracking
2023-06-25 01:18:49.235120 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015D2509F160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015D2509FF60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015D2509FBA8>]}
2023-06-25 01:18:49.246620 (MainThread): Partial parsing not enabled
2023-06-25 01:18:49.249120 (MainThread): Parsing macros\core.sql
2023-06-25 01:18:49.252620 (MainThread): Parsing macros\adapters\common.sql
2023-06-25 01:18:49.283620 (MainThread): Parsing macros\etc\datetime.sql
2023-06-25 01:18:49.290120 (MainThread): Parsing macros\etc\get_custom_alias.sql
2023-06-25 01:18:49.291120 (MainThread): Parsing macros\etc\get_custom_database.sql
2023-06-25 01:18:49.292120 (MainThread): Parsing macros\etc\get_custom_schema.sql
2023-06-25 01:18:49.293620 (MainThread): Parsing macros\etc\get_relation_comment.sql
2023-06-25 01:18:49.295120 (MainThread): Parsing macros\etc\is_incremental.sql
2023-06-25 01:18:49.296620 (MainThread): Parsing macros\etc\query.sql
2023-06-25 01:18:49.297120 (MainThread): Parsing macros\materializations\helpers.sql
2023-06-25 01:18:49.303120 (MainThread): Parsing macros\materializations\common\merge.sql
2023-06-25 01:18:49.312620 (MainThread): Parsing macros\materializations\incremental\helpers.sql
2023-06-25 01:18:49.314119 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2023-06-25 01:18:49.318619 (MainThread): Parsing macros\materializations\seed\seed.sql
2023-06-25 01:18:49.335120 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2023-06-25 01:18:49.359619 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2023-06-25 01:18:49.361120 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2023-06-25 01:18:49.373619 (MainThread): Parsing macros\materializations\table\table.sql
2023-06-25 01:18:49.378619 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2023-06-25 01:18:49.382119 (MainThread): Parsing macros\materializations\view\view.sql
2023-06-25 01:18:49.387119 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2023-06-25 01:18:49.389120 (MainThread): Parsing macros\schema_tests\not_null.sql
2023-06-25 01:18:49.389620 (MainThread): Parsing macros\schema_tests\relationships.sql
2023-06-25 01:18:49.390620 (MainThread): Parsing macros\schema_tests\unique.sql
2023-06-25 01:18:49.391620 (MainThread): Parsing macros\adapters.sql
2023-06-25 01:18:49.404620 (MainThread): Parsing macros\catalog.sql
2023-06-25 01:18:49.406620 (MainThread): Parsing macros\relations.sql
2023-06-25 01:18:49.407620 (MainThread): Parsing macros\materializations\snapshot_merge.sql
2023-06-25 01:18:49.420620 (MainThread): Partial parsing not enabled
2023-06-25 01:18:49.439120 (MainThread): Acquiring new postgres connection "model.transform_data.transform_data".
2023-06-25 01:18:49.439120 (MainThread): Opening a new connection, currently in state init
2023-06-25 01:18:49.657620 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:18:49.658120 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:18:49.658120 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:18:49.658120 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:18:49.658120 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:18:49.658120 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:18:49.658120 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:18:49.690120 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:18:49.690120 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:18:49.810620 (MainThread): scipy not found, skipping conversion test.
2023-06-25 01:18:49.811620 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2023-06-25 01:18:49.812120 (MainThread): Found 1 model, 0 tests, 0 snapshots, 0 analyses, 127 macros, 0 operations, 0 seed files, 0 sources
2023-06-25 01:18:49.812620 (MainThread): 
2023-06-25 01:18:49.813120 (MainThread): Acquiring new postgres connection "master".
2023-06-25 01:18:49.813120 (MainThread): Opening a new connection, currently in state init
2023-06-25 01:18:49.817119 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2023-06-25 01:18:49.817119 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2023-06-25 01:18:49.872120 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2023-06-25 01:18:49.872120 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2023-06-25 01:18:49.902620 (ThreadPoolExecutor-0_0): SQL status: SELECT 5 in 0.03 seconds
2023-06-25 01:18:49.908120 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_public".
2023-06-25 01:18:49.908120 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2023-06-25 01:18:49.909171 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_public".
2023-06-25 01:18:49.909171 (ThreadPoolExecutor-1_0): On list_postgres_public: BEGIN
2023-06-25 01:18:49.937620 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.03 seconds
2023-06-25 01:18:49.937620 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_public".
2023-06-25 01:18:49.937620 (ThreadPoolExecutor-1_0): On list_postgres_public: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "list_postgres_public"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2023-06-25 01:18:49.940620 (ThreadPoolExecutor-1_0): SQL status: SELECT 2 in 0.00 seconds
2023-06-25 01:18:49.942152 (ThreadPoolExecutor-1_0): On list_postgres_public: ROLLBACK
2023-06-25 01:18:49.947620 (MainThread): Using postgres connection "master".
2023-06-25 01:18:49.947620 (MainThread): On master: BEGIN
2023-06-25 01:18:49.977120 (MainThread): SQL status: BEGIN in 0.03 seconds
2023-06-25 01:18:49.977120 (MainThread): Using postgres connection "master".
2023-06-25 01:18:49.977120 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2023-06-25 01:18:49.981119 (MainThread): SQL status: SELECT 1 in 0.00 seconds
2023-06-25 01:18:49.982120 (MainThread): On master: ROLLBACK
2023-06-25 01:18:49.982120 (MainThread): Using postgres connection "master".
2023-06-25 01:18:49.982620 (MainThread): On master: BEGIN
2023-06-25 01:18:49.982620 (MainThread): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:18:49.982620 (MainThread): On master: COMMIT
2023-06-25 01:18:49.982620 (MainThread): Using postgres connection "master".
2023-06-25 01:18:49.983120 (MainThread): On master: COMMIT
2023-06-25 01:18:49.983120 (MainThread): SQL status: COMMIT in 0.00 seconds
2023-06-25 01:18:49.983120 (MainThread): 21:18:49 | Concurrency: 1 threads (target='dev')
2023-06-25 01:18:49.983620 (MainThread): 21:18:49 | 
2023-06-25 01:18:49.985120 (Thread-1): Began running node model.transform_data.transform_data
2023-06-25 01:18:49.985120 (Thread-1): 21:18:49 | 1 of 1 START view model public.transform_data........................ [RUN]
2023-06-25 01:18:49.985620 (Thread-1): Acquiring new postgres connection "model.transform_data.transform_data".
2023-06-25 01:18:49.985620 (Thread-1): Opening a new connection, currently in state init
2023-06-25 01:18:49.985620 (Thread-1): Compiling model.transform_data.transform_data
2023-06-25 01:18:49.995119 (Thread-1): Writing injected SQL for node "model.transform_data.transform_data"
2023-06-25 01:18:49.995619 (Thread-1): finished collecting timing info
2023-06-25 01:18:50.016120 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:18:50.016120 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */
drop view if exists "postgres"."public"."transform_data__dbt_tmp" cascade
2023-06-25 01:18:50.045382 (Thread-1): SQL status: DROP VIEW in 0.03 seconds
2023-06-25 01:18:50.046921 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:18:50.046921 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */
drop view if exists "postgres"."public"."transform_data__dbt_backup" cascade
2023-06-25 01:18:50.047412 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2023-06-25 01:18:50.048412 (Thread-1): Writing runtime SQL for node "model.transform_data.transform_data"
2023-06-25 01:18:50.048885 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:18:50.048885 (Thread-1): On model.transform_data.transform_data: BEGIN
2023-06-25 01:18:50.048885 (Thread-1): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:18:50.048885 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:18:50.049383 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */

  create view "postgres"."public"."transform_data__dbt_tmp" as (
    DELETE FROM public.transactions
WHERE "timestamp" > CURRENT_TIMESTAMP - INTERVAL '2 years';

INSERT INTO public.transactions ("address", "amount", "timestamp")
SELECT
  "address",
  "amount",
  "timestamp"
FROM
  public.transactions
WHERE
  "timestamp" > CURRENT_TIMESTAMP - INTERVAL '2 years';
  );

2023-06-25 01:18:50.049383 (Thread-1): Postgres error: syntax error at or near "DELETE"
LINE 4:     DELETE FROM public.transactions
            ^

2023-06-25 01:18:50.049383 (Thread-1): On model.transform_data.transform_data: ROLLBACK
2023-06-25 01:18:50.049882 (Thread-1): finished collecting timing info
2023-06-25 01:18:50.049882 (Thread-1): Database Error in model transform_data (models\transformations\transform_data.sql)
  syntax error at or near "DELETE"
  LINE 4:     DELETE FROM public.transactions
              ^
  compiled SQL at target\run\transform_data\transformations\transform_data.sql
Traceback (most recent call last):
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\postgres\connections.py", line 46, in exception_handler
    yield
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near "DELETE"
LINE 4:     DELETE FROM public.transactions
            ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 223, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 166, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 268, in run
    return self.execute(compiled_node, manifest)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 450, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 60, in macro
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\base\impl.py", line 220, in execute
    fetch=fetch
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 116, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 82, in add_query
    return connection, cursor
  File "c:\users\me\appdata\local\programs\python\python37\lib\contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\postgres\connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model transform_data (models\transformations\transform_data.sql)
  syntax error at or near "DELETE"
  LINE 4:     DELETE FROM public.transactions
              ^
  compiled SQL at target\run\transform_data\transformations\transform_data.sql
2023-06-25 01:18:50.051381 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dd0f3b21-4b03-4626-8f2b-e48026978b83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015D4D6B0208>]}
2023-06-25 01:18:50.051883 (Thread-1): 21:18:50 | 1 of 1 ERROR creating view model public.transform_data............... [ERROR in 0.07s]
2023-06-25 01:18:50.052382 (Thread-1): Finished running node model.transform_data.transform_data
2023-06-25 01:18:50.100296 (MainThread): Using postgres connection "master".
2023-06-25 01:18:50.100296 (MainThread): On master: BEGIN
2023-06-25 01:18:50.100824 (MainThread): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:18:50.100824 (MainThread): On master: COMMIT
2023-06-25 01:18:50.100824 (MainThread): Using postgres connection "master".
2023-06-25 01:18:50.100824 (MainThread): On master: COMMIT
2023-06-25 01:18:50.100824 (MainThread): SQL status: COMMIT in 0.00 seconds
2023-06-25 01:18:50.101295 (MainThread): 21:18:50 | 
2023-06-25 01:18:50.101295 (MainThread): 21:18:50 | Finished running 1 view model in 0.29s.
2023-06-25 01:18:50.101797 (MainThread): Connection 'master' was left open.
2023-06-25 01:18:50.101797 (MainThread): On master: Close
2023-06-25 01:18:50.101797 (MainThread): Connection 'list_postgres' was left open.
2023-06-25 01:18:50.101797 (MainThread): On list_postgres: Close
2023-06-25 01:18:50.101797 (MainThread): Connection 'list_postgres_public' was left open.
2023-06-25 01:18:50.102325 (MainThread): On list_postgres_public: Close
2023-06-25 01:18:50.102325 (MainThread): Connection 'model.transform_data.transform_data' was left open.
2023-06-25 01:18:50.102325 (MainThread): On model.transform_data.transform_data: Close
2023-06-25 01:18:50.104295 (MainThread): 
2023-06-25 01:18:50.104794 (MainThread): Completed with 1 error and 0 warnings:
2023-06-25 01:18:50.104794 (MainThread): 
2023-06-25 01:18:50.105294 (MainThread): Database Error in model transform_data (models\transformations\transform_data.sql)
2023-06-25 01:18:50.105294 (MainThread):   syntax error at or near "DELETE"
2023-06-25 01:18:50.105294 (MainThread):   LINE 4:     DELETE FROM public.transactions
2023-06-25 01:18:50.105794 (MainThread):               ^
2023-06-25 01:18:50.105794 (MainThread):   compiled SQL at target\run\transform_data\transformations\transform_data.sql
2023-06-25 01:18:50.105794 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2023-06-25 01:18:50.106296 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015D4D6863C8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015D252C78D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000015D4D69BFD0>]}
2023-06-25 01:18:50.106296 (MainThread): Flushing usage events
2023-06-25 01:18:56.905565 (MainThread): Running with dbt=0.16.0
2023-06-25 01:18:56.943066 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='C:\\Users\\Me\\.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target='dev', test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2023-06-25 01:18:56.943565 (MainThread): Tracking: tracking
2023-06-25 01:18:56.944065 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D1E055F208>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D1E055FE80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D1E055FE10>]}
2023-06-25 01:18:56.955565 (MainThread): Partial parsing not enabled
2023-06-25 01:18:56.958065 (MainThread): Parsing macros\core.sql
2023-06-25 01:18:56.961565 (MainThread): Parsing macros\adapters\common.sql
2023-06-25 01:18:56.993065 (MainThread): Parsing macros\etc\datetime.sql
2023-06-25 01:18:56.999566 (MainThread): Parsing macros\etc\get_custom_alias.sql
2023-06-25 01:18:57.000565 (MainThread): Parsing macros\etc\get_custom_database.sql
2023-06-25 01:18:57.001065 (MainThread): Parsing macros\etc\get_custom_schema.sql
2023-06-25 01:18:57.003065 (MainThread): Parsing macros\etc\get_relation_comment.sql
2023-06-25 01:18:57.004565 (MainThread): Parsing macros\etc\is_incremental.sql
2023-06-25 01:18:57.005565 (MainThread): Parsing macros\etc\query.sql
2023-06-25 01:18:57.006566 (MainThread): Parsing macros\materializations\helpers.sql
2023-06-25 01:18:57.012565 (MainThread): Parsing macros\materializations\common\merge.sql
2023-06-25 01:18:57.022065 (MainThread): Parsing macros\materializations\incremental\helpers.sql
2023-06-25 01:18:57.023565 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2023-06-25 01:18:57.028065 (MainThread): Parsing macros\materializations\seed\seed.sql
2023-06-25 01:18:57.044065 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2023-06-25 01:18:57.068565 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2023-06-25 01:18:57.070065 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2023-06-25 01:18:57.082566 (MainThread): Parsing macros\materializations\table\table.sql
2023-06-25 01:18:57.087565 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2023-06-25 01:18:57.091065 (MainThread): Parsing macros\materializations\view\view.sql
2023-06-25 01:18:57.096066 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2023-06-25 01:18:57.097565 (MainThread): Parsing macros\schema_tests\not_null.sql
2023-06-25 01:18:57.098067 (MainThread): Parsing macros\schema_tests\relationships.sql
2023-06-25 01:18:57.099066 (MainThread): Parsing macros\schema_tests\unique.sql
2023-06-25 01:18:57.100565 (MainThread): Parsing macros\adapters.sql
2023-06-25 01:18:57.113065 (MainThread): Parsing macros\catalog.sql
2023-06-25 01:18:57.115065 (MainThread): Parsing macros\relations.sql
2023-06-25 01:18:57.116065 (MainThread): Parsing macros\materializations\snapshot_merge.sql
2023-06-25 01:18:57.129066 (MainThread): Partial parsing not enabled
2023-06-25 01:18:57.147565 (MainThread): Acquiring new postgres connection "model.transform_data.transform_data".
2023-06-25 01:18:57.147565 (MainThread): Opening a new connection, currently in state init
2023-06-25 01:18:57.364066 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:18:57.364567 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:18:57.364567 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:18:57.364567 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:18:57.364567 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:18:57.364567 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:18:57.364567 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:18:57.396065 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:18:57.396065 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:18:57.515565 (MainThread): scipy not found, skipping conversion test.
2023-06-25 01:18:57.516566 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2023-06-25 01:18:57.517066 (MainThread): Found 1 model, 0 tests, 0 snapshots, 0 analyses, 127 macros, 0 operations, 0 seed files, 0 sources
2023-06-25 01:18:57.517565 (MainThread): 
2023-06-25 01:18:57.518065 (MainThread): Acquiring new postgres connection "master".
2023-06-25 01:18:57.518065 (MainThread): Opening a new connection, currently in state init
2023-06-25 01:18:57.521566 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2023-06-25 01:18:57.521566 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2023-06-25 01:18:57.577565 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2023-06-25 01:18:57.577565 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2023-06-25 01:18:57.608367 (ThreadPoolExecutor-0_0): SQL status: SELECT 5 in 0.03 seconds
2023-06-25 01:18:57.613867 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_public".
2023-06-25 01:18:57.613867 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2023-06-25 01:18:57.614898 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_public".
2023-06-25 01:18:57.614898 (ThreadPoolExecutor-1_0): On list_postgres_public: BEGIN
2023-06-25 01:18:57.646868 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.03 seconds
2023-06-25 01:18:57.646868 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_public".
2023-06-25 01:18:57.646868 (ThreadPoolExecutor-1_0): On list_postgres_public: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "list_postgres_public"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2023-06-25 01:18:57.649868 (ThreadPoolExecutor-1_0): SQL status: SELECT 2 in 0.00 seconds
2023-06-25 01:18:57.651367 (ThreadPoolExecutor-1_0): On list_postgres_public: ROLLBACK
2023-06-25 01:18:57.656867 (MainThread): Using postgres connection "master".
2023-06-25 01:18:57.657367 (MainThread): On master: BEGIN
2023-06-25 01:18:57.686367 (MainThread): SQL status: BEGIN in 0.03 seconds
2023-06-25 01:18:57.686367 (MainThread): Using postgres connection "master".
2023-06-25 01:18:57.686367 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2023-06-25 01:18:57.690367 (MainThread): SQL status: SELECT 1 in 0.00 seconds
2023-06-25 01:18:57.691366 (MainThread): On master: ROLLBACK
2023-06-25 01:18:57.691867 (MainThread): Using postgres connection "master".
2023-06-25 01:18:57.691867 (MainThread): On master: BEGIN
2023-06-25 01:18:57.691867 (MainThread): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:18:57.691867 (MainThread): On master: COMMIT
2023-06-25 01:18:57.692367 (MainThread): Using postgres connection "master".
2023-06-25 01:18:57.692367 (MainThread): On master: COMMIT
2023-06-25 01:18:57.692367 (MainThread): SQL status: COMMIT in 0.00 seconds
2023-06-25 01:18:57.692367 (MainThread): 21:18:57 | Concurrency: 1 threads (target='dev')
2023-06-25 01:18:57.692867 (MainThread): 21:18:57 | 
2023-06-25 01:18:57.694367 (Thread-1): Began running node model.transform_data.transform_data
2023-06-25 01:18:57.694367 (Thread-1): 21:18:57 | 1 of 1 START view model public.transform_data........................ [RUN]
2023-06-25 01:18:57.694868 (Thread-1): Acquiring new postgres connection "model.transform_data.transform_data".
2023-06-25 01:18:57.694868 (Thread-1): Opening a new connection, currently in state init
2023-06-25 01:18:57.694868 (Thread-1): Compiling model.transform_data.transform_data
2023-06-25 01:18:57.704367 (Thread-1): Writing injected SQL for node "model.transform_data.transform_data"
2023-06-25 01:18:57.704867 (Thread-1): finished collecting timing info
2023-06-25 01:18:57.724867 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:18:57.724867 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */
drop view if exists "postgres"."public"."transform_data__dbt_tmp" cascade
2023-06-25 01:18:57.755967 (Thread-1): SQL status: DROP VIEW in 0.03 seconds
2023-06-25 01:18:57.757467 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:18:57.757467 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */
drop view if exists "postgres"."public"."transform_data__dbt_backup" cascade
2023-06-25 01:18:57.757467 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2023-06-25 01:18:57.758467 (Thread-1): Writing runtime SQL for node "model.transform_data.transform_data"
2023-06-25 01:18:57.758968 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:18:57.759468 (Thread-1): On model.transform_data.transform_data: BEGIN
2023-06-25 01:18:57.759468 (Thread-1): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:18:57.759468 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:18:57.759468 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */

  create view "postgres"."public"."transform_data__dbt_tmp" as (
    DELETE FROM public.transactions
WHERE "timestamp" > CURRENT_TIMESTAMP - INTERVAL '2 years';

INSERT INTO public.transactions ("address", "amount", "timestamp")
SELECT
  "address",
  "amount",
  "timestamp"
FROM
  public.transactions
WHERE
  "timestamp" > CURRENT_TIMESTAMP - INTERVAL '2 years';
  );

2023-06-25 01:18:57.759968 (Thread-1): Postgres error: syntax error at or near "DELETE"
LINE 4:     DELETE FROM public.transactions
            ^

2023-06-25 01:18:57.759968 (Thread-1): On model.transform_data.transform_data: ROLLBACK
2023-06-25 01:18:57.760468 (Thread-1): finished collecting timing info
2023-06-25 01:18:57.760468 (Thread-1): Database Error in model transform_data (models\transformations\transform_data.sql)
  syntax error at or near "DELETE"
  LINE 4:     DELETE FROM public.transactions
              ^
  compiled SQL at target\run\transform_data\transformations\transform_data.sql
Traceback (most recent call last):
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\postgres\connections.py", line 46, in exception_handler
    yield
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near "DELETE"
LINE 4:     DELETE FROM public.transactions
            ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 223, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 166, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 268, in run
    return self.execute(compiled_node, manifest)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 450, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 60, in macro
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\base\impl.py", line 220, in execute
    fetch=fetch
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 116, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 82, in add_query
    return connection, cursor
  File "c:\users\me\appdata\local\programs\python\python37\lib\contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\postgres\connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model transform_data (models\transformations\transform_data.sql)
  syntax error at or near "DELETE"
  LINE 4:     DELETE FROM public.transactions
              ^
  compiled SQL at target\run\transform_data\transformations\transform_data.sql
2023-06-25 01:18:57.761967 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '245d9d61-b4af-4e22-9d05-1eb5218a4434', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D188B64D68>]}
2023-06-25 01:18:57.762467 (Thread-1): 21:18:57 | 1 of 1 ERROR creating view model public.transform_data............... [ERROR in 0.07s]
2023-06-25 01:18:57.762967 (Thread-1): Finished running node model.transform_data.transform_data
2023-06-25 01:18:57.794717 (MainThread): Using postgres connection "master".
2023-06-25 01:18:57.794717 (MainThread): On master: BEGIN
2023-06-25 01:18:57.795252 (MainThread): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:18:57.795252 (MainThread): On master: COMMIT
2023-06-25 01:18:57.795252 (MainThread): Using postgres connection "master".
2023-06-25 01:18:57.795252 (MainThread): On master: COMMIT
2023-06-25 01:18:57.795753 (MainThread): SQL status: COMMIT in 0.00 seconds
2023-06-25 01:18:57.795753 (MainThread): 21:18:57 | 
2023-06-25 01:18:57.796222 (MainThread): 21:18:57 | Finished running 1 view model in 0.28s.
2023-06-25 01:18:57.796222 (MainThread): Connection 'master' was left open.
2023-06-25 01:18:57.796222 (MainThread): On master: Close
2023-06-25 01:18:57.796724 (MainThread): Connection 'list_postgres' was left open.
2023-06-25 01:18:57.796724 (MainThread): On list_postgres: Close
2023-06-25 01:18:57.796724 (MainThread): Connection 'list_postgres_public' was left open.
2023-06-25 01:18:57.796724 (MainThread): On list_postgres_public: Close
2023-06-25 01:18:57.796724 (MainThread): Connection 'model.transform_data.transform_data' was left open.
2023-06-25 01:18:57.796724 (MainThread): On model.transform_data.transform_data: Close
2023-06-25 01:18:57.800253 (MainThread): 
2023-06-25 01:18:57.800757 (MainThread): Completed with 1 error and 0 warnings:
2023-06-25 01:18:57.800757 (MainThread): 
2023-06-25 01:18:57.801223 (MainThread): Database Error in model transform_data (models\transformations\transform_data.sql)
2023-06-25 01:18:57.801223 (MainThread):   syntax error at or near "DELETE"
2023-06-25 01:18:57.801722 (MainThread):   LINE 4:     DELETE FROM public.transactions
2023-06-25 01:18:57.801722 (MainThread):               ^
2023-06-25 01:18:57.802223 (MainThread):   compiled SQL at target\run\transform_data\transformations\transform_data.sql
2023-06-25 01:18:57.802223 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2023-06-25 01:18:57.802223 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D188B4E518>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D1E079E9E8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D188B64EB8>]}
2023-06-25 01:18:57.802723 (MainThread): Flushing usage events
2023-06-25 01:19:41.277296 (MainThread): Running with dbt=0.16.0
2023-06-25 01:19:41.314295 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='C:\\Users\\Me\\.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target='dev', test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2023-06-25 01:19:41.314795 (MainThread): Tracking: tracking
2023-06-25 01:19:41.315795 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014DE650FF98>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014DE650FA20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014DE650F198>]}
2023-06-25 01:19:41.326795 (MainThread): Partial parsing not enabled
2023-06-25 01:19:41.329296 (MainThread): Parsing macros\core.sql
2023-06-25 01:19:41.332796 (MainThread): Parsing macros\adapters\common.sql
2023-06-25 01:19:41.363796 (MainThread): Parsing macros\etc\datetime.sql
2023-06-25 01:19:41.370796 (MainThread): Parsing macros\etc\get_custom_alias.sql
2023-06-25 01:19:41.371796 (MainThread): Parsing macros\etc\get_custom_database.sql
2023-06-25 01:19:41.372296 (MainThread): Parsing macros\etc\get_custom_schema.sql
2023-06-25 01:19:41.373797 (MainThread): Parsing macros\etc\get_relation_comment.sql
2023-06-25 01:19:41.375795 (MainThread): Parsing macros\etc\is_incremental.sql
2023-06-25 01:19:41.376796 (MainThread): Parsing macros\etc\query.sql
2023-06-25 01:19:41.377796 (MainThread): Parsing macros\materializations\helpers.sql
2023-06-25 01:19:41.383796 (MainThread): Parsing macros\materializations\common\merge.sql
2023-06-25 01:19:41.393296 (MainThread): Parsing macros\materializations\incremental\helpers.sql
2023-06-25 01:19:41.394795 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2023-06-25 01:19:41.399297 (MainThread): Parsing macros\materializations\seed\seed.sql
2023-06-25 01:19:41.414795 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2023-06-25 01:19:41.439797 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2023-06-25 01:19:41.440796 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2023-06-25 01:19:41.453295 (MainThread): Parsing macros\materializations\table\table.sql
2023-06-25 01:19:41.458296 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2023-06-25 01:19:41.462296 (MainThread): Parsing macros\materializations\view\view.sql
2023-06-25 01:19:41.466795 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2023-06-25 01:19:41.468296 (MainThread): Parsing macros\schema_tests\not_null.sql
2023-06-25 01:19:41.469296 (MainThread): Parsing macros\schema_tests\relationships.sql
2023-06-25 01:19:41.469795 (MainThread): Parsing macros\schema_tests\unique.sql
2023-06-25 01:19:41.471296 (MainThread): Parsing macros\adapters.sql
2023-06-25 01:19:41.484295 (MainThread): Parsing macros\catalog.sql
2023-06-25 01:19:41.485796 (MainThread): Parsing macros\relations.sql
2023-06-25 01:19:41.486795 (MainThread): Parsing macros\materializations\snapshot_merge.sql
2023-06-25 01:19:41.499795 (MainThread): Partial parsing not enabled
2023-06-25 01:19:41.518296 (MainThread): Acquiring new postgres connection "model.transform_data.transform_data".
2023-06-25 01:19:41.518296 (MainThread): Opening a new connection, currently in state init
2023-06-25 01:19:41.736296 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:19:41.736296 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:19:41.736296 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:19:41.736799 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:19:41.736799 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:19:41.736799 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:19:41.736799 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:19:41.768295 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:19:41.768295 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:19:41.889795 (MainThread): scipy not found, skipping conversion test.
2023-06-25 01:19:41.890796 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2023-06-25 01:19:41.891296 (MainThread): Found 1 model, 0 tests, 0 snapshots, 0 analyses, 127 macros, 0 operations, 0 seed files, 0 sources
2023-06-25 01:19:41.892296 (MainThread): 
2023-06-25 01:19:41.892296 (MainThread): Acquiring new postgres connection "master".
2023-06-25 01:19:41.892797 (MainThread): Opening a new connection, currently in state init
2023-06-25 01:19:41.896796 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2023-06-25 01:19:41.896796 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2023-06-25 01:19:41.953796 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2023-06-25 01:19:41.953796 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2023-06-25 01:19:41.983320 (ThreadPoolExecutor-0_0): SQL status: SELECT 5 in 0.03 seconds
2023-06-25 01:19:41.988796 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_public".
2023-06-25 01:19:41.988796 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2023-06-25 01:19:41.989796 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_public".
2023-06-25 01:19:41.989796 (ThreadPoolExecutor-1_0): On list_postgres_public: BEGIN
2023-06-25 01:19:42.017380 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.03 seconds
2023-06-25 01:19:42.017380 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_public".
2023-06-25 01:19:42.017380 (ThreadPoolExecutor-1_0): On list_postgres_public: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "list_postgres_public"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2023-06-25 01:19:42.020410 (ThreadPoolExecutor-1_0): SQL status: SELECT 2 in 0.00 seconds
2023-06-25 01:19:42.021879 (ThreadPoolExecutor-1_0): On list_postgres_public: ROLLBACK
2023-06-25 01:19:42.027413 (MainThread): Using postgres connection "master".
2023-06-25 01:19:42.027413 (MainThread): On master: BEGIN
2023-06-25 01:19:42.160421 (MainThread): SQL status: BEGIN in 0.13 seconds
2023-06-25 01:19:42.160421 (MainThread): Using postgres connection "master".
2023-06-25 01:19:42.160421 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2023-06-25 01:19:42.164421 (MainThread): SQL status: SELECT 1 in 0.00 seconds
2023-06-25 01:19:42.165422 (MainThread): On master: ROLLBACK
2023-06-25 01:19:42.165921 (MainThread): Using postgres connection "master".
2023-06-25 01:19:42.165921 (MainThread): On master: BEGIN
2023-06-25 01:19:42.165921 (MainThread): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:19:42.165921 (MainThread): On master: COMMIT
2023-06-25 01:19:42.166422 (MainThread): Using postgres connection "master".
2023-06-25 01:19:42.166422 (MainThread): On master: COMMIT
2023-06-25 01:19:42.166422 (MainThread): SQL status: COMMIT in 0.00 seconds
2023-06-25 01:19:42.166422 (MainThread): 21:19:42 | Concurrency: 1 threads (target='dev')
2023-06-25 01:19:42.166922 (MainThread): 21:19:42 | 
2023-06-25 01:19:42.168422 (Thread-1): Began running node model.transform_data.transform_data
2023-06-25 01:19:42.168422 (Thread-1): 21:19:42 | 1 of 1 START view model public.transform_data........................ [RUN]
2023-06-25 01:19:42.168921 (Thread-1): Acquiring new postgres connection "model.transform_data.transform_data".
2023-06-25 01:19:42.168921 (Thread-1): Opening a new connection, currently in state init
2023-06-25 01:19:42.168921 (Thread-1): Compiling model.transform_data.transform_data
2023-06-25 01:19:42.178421 (Thread-1): Writing injected SQL for node "model.transform_data.transform_data"
2023-06-25 01:19:42.179298 (Thread-1): finished collecting timing info
2023-06-25 01:19:42.199802 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:19:42.199802 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */
drop view if exists "postgres"."public"."transform_data__dbt_tmp" cascade
2023-06-25 01:19:42.228304 (Thread-1): SQL status: DROP VIEW in 0.03 seconds
2023-06-25 01:19:42.229835 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:19:42.229835 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */
drop view if exists "postgres"."public"."transform_data__dbt_backup" cascade
2023-06-25 01:19:42.230302 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2023-06-25 01:19:42.230803 (Thread-1): Writing runtime SQL for node "model.transform_data.transform_data"
2023-06-25 01:19:42.231802 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:19:42.231802 (Thread-1): On model.transform_data.transform_data: BEGIN
2023-06-25 01:19:42.231802 (Thread-1): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:19:42.231802 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:19:42.231802 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */

  create view "postgres"."public"."transform_data__dbt_tmp" as (
    -- Create a temporary table to hold the filtered and transformed data
CREATE TEMPORARY TABLE temp_transactions AS
SELECT
  "address",
  "amount",
  "timestamp"
FROM
  public.transactions
WHERE
  "timestamp" > CURRENT_TIMESTAMP - INTERVAL '2 years';

-- Clear existing data from the target table
DELETE FROM public.transactions;

-- Insert the data from the temporary table into the target table
INSERT INTO public.transactions ("address", "amount", "timestamp")
SELECT
  "address",
  "amount",
  "timestamp"
FROM
  temp_transactions;
  );

2023-06-25 01:19:42.232303 (Thread-1): Postgres error: syntax error at or near "CREATE"
LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
        ^

2023-06-25 01:19:42.232303 (Thread-1): On model.transform_data.transform_data: ROLLBACK
2023-06-25 01:19:42.232303 (Thread-1): finished collecting timing info
2023-06-25 01:19:42.232803 (Thread-1): Database Error in model transform_data (models\transformations\transform_data.sql)
  syntax error at or near "CREATE"
  LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
          ^
  compiled SQL at target\run\transform_data\transformations\transform_data.sql
Traceback (most recent call last):
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\postgres\connections.py", line 46, in exception_handler
    yield
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near "CREATE"
LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
        ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 223, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 166, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 268, in run
    return self.execute(compiled_node, manifest)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 450, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 60, in macro
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\base\impl.py", line 220, in execute
    fetch=fetch
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 116, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 82, in add_query
    return connection, cursor
  File "c:\users\me\appdata\local\programs\python\python37\lib\contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\postgres\connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model transform_data (models\transformations\transform_data.sql)
  syntax error at or near "CREATE"
  LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
          ^
  compiled SQL at target\run\transform_data\transformations\transform_data.sql
2023-06-25 01:19:42.234302 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f6bee60-8741-4102-b005-ee5951d817f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014DE5D29390>]}
2023-06-25 01:19:42.234803 (Thread-1): 21:19:42 | 1 of 1 ERROR creating view model public.transform_data............... [ERROR in 0.07s]
2023-06-25 01:19:42.235303 (Thread-1): Finished running node model.transform_data.transform_data
2023-06-25 01:19:42.277989 (MainThread): Using postgres connection "master".
2023-06-25 01:19:42.277989 (MainThread): On master: BEGIN
2023-06-25 01:19:42.278496 (MainThread): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:19:42.278496 (MainThread): On master: COMMIT
2023-06-25 01:19:42.278496 (MainThread): Using postgres connection "master".
2023-06-25 01:19:42.278496 (MainThread): On master: COMMIT
2023-06-25 01:19:42.278496 (MainThread): SQL status: COMMIT in 0.00 seconds
2023-06-25 01:19:42.278993 (MainThread): 21:19:42 | 
2023-06-25 01:19:42.278993 (MainThread): 21:19:42 | Finished running 1 view model in 0.39s.
2023-06-25 01:19:42.278993 (MainThread): Connection 'master' was left open.
2023-06-25 01:19:42.279494 (MainThread): On master: Close
2023-06-25 01:19:42.279494 (MainThread): Connection 'list_postgres' was left open.
2023-06-25 01:19:42.279494 (MainThread): On list_postgres: Close
2023-06-25 01:19:42.279494 (MainThread): Connection 'list_postgres_public' was left open.
2023-06-25 01:19:42.279494 (MainThread): On list_postgres_public: Close
2023-06-25 01:19:42.279494 (MainThread): Connection 'model.transform_data.transform_data' was left open.
2023-06-25 01:19:42.280022 (MainThread): On model.transform_data.transform_data: Close
2023-06-25 01:19:42.281993 (MainThread): 
2023-06-25 01:19:42.282492 (MainThread): Completed with 1 error and 0 warnings:
2023-06-25 01:19:42.282492 (MainThread): 
2023-06-25 01:19:42.282492 (MainThread): Database Error in model transform_data (models\transformations\transform_data.sql)
2023-06-25 01:19:42.282993 (MainThread):   syntax error at or near "CREATE"
2023-06-25 01:19:42.282993 (MainThread):   LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
2023-06-25 01:19:42.282993 (MainThread):           ^
2023-06-25 01:19:42.283522 (MainThread):   compiled SQL at target\run\transform_data\transformations\transform_data.sql
2023-06-25 01:19:42.283522 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2023-06-25 01:19:42.283522 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014DE674F6A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014D8EB05518>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014D8EB05588>]}
2023-06-25 01:19:42.284024 (MainThread): Flushing usage events
2023-06-25 01:22:27.951899 (MainThread): Running with dbt=0.16.0
2023-06-25 01:22:27.988899 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='C:\\Users\\Me\\.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target='dev', test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2023-06-25 01:22:27.989398 (MainThread): Tracking: tracking
2023-06-25 01:22:27.990398 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028798F0EF98>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028798F0EA20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028798F0E198>]}
2023-06-25 01:22:28.001398 (MainThread): Partial parsing not enabled
2023-06-25 01:22:28.003898 (MainThread): Parsing macros\core.sql
2023-06-25 01:22:28.007398 (MainThread): Parsing macros\adapters\common.sql
2023-06-25 01:22:28.038398 (MainThread): Parsing macros\etc\datetime.sql
2023-06-25 01:22:28.045398 (MainThread): Parsing macros\etc\get_custom_alias.sql
2023-06-25 01:22:28.045899 (MainThread): Parsing macros\etc\get_custom_database.sql
2023-06-25 01:22:28.046898 (MainThread): Parsing macros\etc\get_custom_schema.sql
2023-06-25 01:22:28.048399 (MainThread): Parsing macros\etc\get_relation_comment.sql
2023-06-25 01:22:28.050399 (MainThread): Parsing macros\etc\is_incremental.sql
2023-06-25 01:22:28.051398 (MainThread): Parsing macros\etc\query.sql
2023-06-25 01:22:28.052398 (MainThread): Parsing macros\materializations\helpers.sql
2023-06-25 01:22:28.058398 (MainThread): Parsing macros\materializations\common\merge.sql
2023-06-25 01:22:28.067898 (MainThread): Parsing macros\materializations\incremental\helpers.sql
2023-06-25 01:22:28.068898 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2023-06-25 01:22:28.073899 (MainThread): Parsing macros\materializations\seed\seed.sql
2023-06-25 01:22:28.089398 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2023-06-25 01:22:28.113899 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2023-06-25 01:22:28.115398 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2023-06-25 01:22:28.127898 (MainThread): Parsing macros\materializations\table\table.sql
2023-06-25 01:22:28.132899 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2023-06-25 01:22:28.136398 (MainThread): Parsing macros\materializations\view\view.sql
2023-06-25 01:22:28.141399 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2023-06-25 01:22:28.142899 (MainThread): Parsing macros\schema_tests\not_null.sql
2023-06-25 01:22:28.143399 (MainThread): Parsing macros\schema_tests\relationships.sql
2023-06-25 01:22:28.144398 (MainThread): Parsing macros\schema_tests\unique.sql
2023-06-25 01:22:28.145899 (MainThread): Parsing macros\adapters.sql
2023-06-25 01:22:28.158398 (MainThread): Parsing macros\catalog.sql
2023-06-25 01:22:28.160398 (MainThread): Parsing macros\relations.sql
2023-06-25 01:22:28.161399 (MainThread): Parsing macros\materializations\snapshot_merge.sql
2023-06-25 01:22:28.174398 (MainThread): Partial parsing not enabled
2023-06-25 01:22:28.192899 (MainThread): Acquiring new postgres connection "model.transform_data.transform_data".
2023-06-25 01:22:28.192899 (MainThread): Opening a new connection, currently in state init
2023-06-25 01:22:28.412899 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:22:28.412899 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:22:28.412899 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:22:28.412899 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:22:28.412899 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:22:28.412899 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:22:28.413399 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:22:28.444399 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:22:28.444399 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:22:28.564399 (MainThread): scipy not found, skipping conversion test.
2023-06-25 01:22:28.565428 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2023-06-25 01:22:28.565899 (MainThread): Found 1 model, 0 tests, 0 snapshots, 0 analyses, 127 macros, 0 operations, 0 seed files, 0 sources
2023-06-25 01:22:28.566399 (MainThread): 
2023-06-25 01:22:28.566898 (MainThread): Acquiring new postgres connection "master".
2023-06-25 01:22:28.566898 (MainThread): Opening a new connection, currently in state init
2023-06-25 01:22:28.570399 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2023-06-25 01:22:28.570900 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2023-06-25 01:22:28.625899 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2023-06-25 01:22:28.626399 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2023-06-25 01:22:28.656428 (ThreadPoolExecutor-0_0): SQL status: SELECT 5 in 0.03 seconds
2023-06-25 01:22:28.661945 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_public".
2023-06-25 01:22:28.661945 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2023-06-25 01:22:28.662930 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_public".
2023-06-25 01:22:28.662930 (ThreadPoolExecutor-1_0): On list_postgres_public: BEGIN
2023-06-25 01:22:28.691898 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.03 seconds
2023-06-25 01:22:28.691898 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_public".
2023-06-25 01:22:28.691898 (ThreadPoolExecutor-1_0): On list_postgres_public: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "list_postgres_public"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2023-06-25 01:22:28.694899 (ThreadPoolExecutor-1_0): SQL status: SELECT 2 in 0.00 seconds
2023-06-25 01:22:28.696399 (ThreadPoolExecutor-1_0): On list_postgres_public: ROLLBACK
2023-06-25 01:22:28.701898 (MainThread): Using postgres connection "master".
2023-06-25 01:22:28.701898 (MainThread): On master: BEGIN
2023-06-25 01:22:28.731400 (MainThread): SQL status: BEGIN in 0.03 seconds
2023-06-25 01:22:28.731400 (MainThread): Using postgres connection "master".
2023-06-25 01:22:28.731400 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2023-06-25 01:22:28.735435 (MainThread): SQL status: SELECT 1 in 0.00 seconds
2023-06-25 01:22:28.736399 (MainThread): On master: ROLLBACK
2023-06-25 01:22:28.736399 (MainThread): Using postgres connection "master".
2023-06-25 01:22:28.736899 (MainThread): On master: BEGIN
2023-06-25 01:22:28.736899 (MainThread): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:22:28.736899 (MainThread): On master: COMMIT
2023-06-25 01:22:28.736899 (MainThread): Using postgres connection "master".
2023-06-25 01:22:28.736899 (MainThread): On master: COMMIT
2023-06-25 01:22:28.737400 (MainThread): SQL status: COMMIT in 0.00 seconds
2023-06-25 01:22:28.737400 (MainThread): 21:22:28 | Concurrency: 1 threads (target='dev')
2023-06-25 01:22:28.737900 (MainThread): 21:22:28 | 
2023-06-25 01:22:28.739434 (Thread-1): Began running node model.transform_data.transform_data
2023-06-25 01:22:28.739434 (Thread-1): 21:22:28 | 1 of 1 START view model public.transform_data........................ [RUN]
2023-06-25 01:22:28.739946 (Thread-1): Acquiring new postgres connection "model.transform_data.transform_data".
2023-06-25 01:22:28.739946 (Thread-1): Opening a new connection, currently in state init
2023-06-25 01:22:28.739946 (Thread-1): Compiling model.transform_data.transform_data
2023-06-25 01:22:28.749429 (Thread-1): Writing injected SQL for node "model.transform_data.transform_data"
2023-06-25 01:22:28.750400 (Thread-1): finished collecting timing info
2023-06-25 01:22:28.770399 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:22:28.770399 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */
drop view if exists "postgres"."public"."transform_data__dbt_tmp" cascade
2023-06-25 01:22:28.799159 (Thread-1): SQL status: DROP VIEW in 0.03 seconds
2023-06-25 01:22:28.800659 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:22:28.800659 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */
drop view if exists "postgres"."public"."transform_data__dbt_backup" cascade
2023-06-25 01:22:28.800659 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2023-06-25 01:22:28.801659 (Thread-1): Writing runtime SQL for node "model.transform_data.transform_data"
2023-06-25 01:22:28.802659 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:22:28.802659 (Thread-1): On model.transform_data.transform_data: BEGIN
2023-06-25 01:22:28.802842 (Thread-1): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:22:28.802842 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:22:28.802842 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */

  create view "postgres"."public"."transform_data__dbt_tmp" as (
    -- Create a temporary table to hold the filtered and transformed data
CREATE TEMPORARY TABLE temp_transactions AS
SELECT
  "address",
  "amount",
  "timestamp"
FROM
  public.transactions
WHERE
  "timestamp" > CURRENT_TIMESTAMP - INTERVAL '2 years';

-- Clear existing data from the target table
DELETE FROM public.transactions;

-- Insert the data from the temporary table into the target table
INSERT INTO public.transactions ("address", "amount", "timestamp")
SELECT
  "address",
  "amount",
  "timestamp"
FROM
  temp_transactions;
  );

2023-06-25 01:22:28.803346 (Thread-1): Postgres error: syntax error at or near "CREATE"
LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
        ^

2023-06-25 01:22:28.803346 (Thread-1): On model.transform_data.transform_data: ROLLBACK
2023-06-25 01:22:28.803642 (Thread-1): finished collecting timing info
2023-06-25 01:22:28.803642 (Thread-1): Database Error in model transform_data (models\transformations\transform_data.sql)
  syntax error at or near "CREATE"
  LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
          ^
  compiled SQL at target\run\transform_data\transformations\transform_data.sql
Traceback (most recent call last):
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\postgres\connections.py", line 46, in exception_handler
    yield
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near "CREATE"
LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
        ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 223, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 166, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 268, in run
    return self.execute(compiled_node, manifest)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 450, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 60, in macro
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\base\impl.py", line 220, in execute
    fetch=fetch
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 116, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 82, in add_query
    return connection, cursor
  File "c:\users\me\appdata\local\programs\python\python37\lib\contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\postgres\connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model transform_data (models\transformations\transform_data.sql)
  syntax error at or near "CREATE"
  LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
          ^
  compiled SQL at target\run\transform_data\transformations\transform_data.sql
2023-06-25 01:22:28.805146 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4f17cb8c-12f8-4cf1-bc8b-8b4f4e29a253', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000287C14FBDD8>]}
2023-06-25 01:22:28.805646 (Thread-1): 21:22:28 | 1 of 1 ERROR creating view model public.transform_data............... [ERROR in 0.07s]
2023-06-25 01:22:28.806412 (Thread-1): Finished running node model.transform_data.transform_data
2023-06-25 01:22:28.846259 (MainThread): Using postgres connection "master".
2023-06-25 01:22:28.846259 (MainThread): On master: BEGIN
2023-06-25 01:22:28.846819 (MainThread): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:22:28.846819 (MainThread): On master: COMMIT
2023-06-25 01:22:28.846819 (MainThread): Using postgres connection "master".
2023-06-25 01:22:28.846819 (MainThread): On master: COMMIT
2023-06-25 01:22:28.847307 (MainThread): SQL status: COMMIT in 0.00 seconds
2023-06-25 01:22:28.847307 (MainThread): 21:22:28 | 
2023-06-25 01:22:28.847778 (MainThread): 21:22:28 | Finished running 1 view model in 0.28s.
2023-06-25 01:22:28.847778 (MainThread): Connection 'master' was left open.
2023-06-25 01:22:28.847778 (MainThread): On master: Close
2023-06-25 01:22:28.848276 (MainThread): Connection 'list_postgres' was left open.
2023-06-25 01:22:28.848276 (MainThread): On list_postgres: Close
2023-06-25 01:22:28.848276 (MainThread): Connection 'list_postgres_public' was left open.
2023-06-25 01:22:28.848276 (MainThread): On list_postgres_public: Close
2023-06-25 01:22:28.848276 (MainThread): Connection 'model.transform_data.transform_data' was left open.
2023-06-25 01:22:28.848276 (MainThread): On model.transform_data.transform_data: Close
2023-06-25 01:22:28.850776 (MainThread): 
2023-06-25 01:22:28.850776 (MainThread): Completed with 1 error and 0 warnings:
2023-06-25 01:22:28.851275 (MainThread): 
2023-06-25 01:22:28.851776 (MainThread): Database Error in model transform_data (models\transformations\transform_data.sql)
2023-06-25 01:22:28.851776 (MainThread):   syntax error at or near "CREATE"
2023-06-25 01:22:28.852278 (MainThread):   LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
2023-06-25 01:22:28.852278 (MainThread):           ^
2023-06-25 01:22:28.852278 (MainThread):   compiled SQL at target\run\transform_data\transformations\transform_data.sql
2023-06-25 01:22:28.852778 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2023-06-25 01:22:28.852778 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000287C14F44A8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000287991369B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000287C150BD30>]}
2023-06-25 01:22:28.852778 (MainThread): Flushing usage events
2023-06-25 01:22:34.027750 (MainThread): Running with dbt=0.16.0
2023-06-25 01:22:34.064752 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='C:\\Users\\Me\\.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2023-06-25 01:22:34.065251 (MainThread): Tracking: tracking
2023-06-25 01:22:34.066250 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002560A740240>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002560A740F28>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002560A740B70>]}
2023-06-25 01:22:34.077250 (MainThread): Partial parsing not enabled
2023-06-25 01:22:34.079750 (MainThread): Parsing macros\core.sql
2023-06-25 01:22:34.083250 (MainThread): Parsing macros\adapters\common.sql
2023-06-25 01:22:34.114250 (MainThread): Parsing macros\etc\datetime.sql
2023-06-25 01:22:34.120750 (MainThread): Parsing macros\etc\get_custom_alias.sql
2023-06-25 01:22:34.121750 (MainThread): Parsing macros\etc\get_custom_database.sql
2023-06-25 01:22:34.122750 (MainThread): Parsing macros\etc\get_custom_schema.sql
2023-06-25 01:22:34.124250 (MainThread): Parsing macros\etc\get_relation_comment.sql
2023-06-25 01:22:34.125750 (MainThread): Parsing macros\etc\is_incremental.sql
2023-06-25 01:22:34.126752 (MainThread): Parsing macros\etc\query.sql
2023-06-25 01:22:34.127750 (MainThread): Parsing macros\materializations\helpers.sql
2023-06-25 01:22:34.133750 (MainThread): Parsing macros\materializations\common\merge.sql
2023-06-25 01:22:34.142750 (MainThread): Parsing macros\materializations\incremental\helpers.sql
2023-06-25 01:22:34.144250 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2023-06-25 01:22:34.148750 (MainThread): Parsing macros\materializations\seed\seed.sql
2023-06-25 01:22:34.164250 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2023-06-25 01:22:34.188751 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2023-06-25 01:22:34.190250 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2023-06-25 01:22:34.202750 (MainThread): Parsing macros\materializations\table\table.sql
2023-06-25 01:22:34.207750 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2023-06-25 01:22:34.211750 (MainThread): Parsing macros\materializations\view\view.sql
2023-06-25 01:22:34.216250 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2023-06-25 01:22:34.217751 (MainThread): Parsing macros\schema_tests\not_null.sql
2023-06-25 01:22:34.218250 (MainThread): Parsing macros\schema_tests\relationships.sql
2023-06-25 01:22:34.219251 (MainThread): Parsing macros\schema_tests\unique.sql
2023-06-25 01:22:34.220750 (MainThread): Parsing macros\adapters.sql
2023-06-25 01:22:34.233250 (MainThread): Parsing macros\catalog.sql
2023-06-25 01:22:34.235251 (MainThread): Parsing macros\relations.sql
2023-06-25 01:22:34.236250 (MainThread): Parsing macros\materializations\snapshot_merge.sql
2023-06-25 01:22:34.248750 (MainThread): Partial parsing not enabled
2023-06-25 01:22:34.267250 (MainThread): Acquiring new postgres connection "model.transform_data.transform_data".
2023-06-25 01:22:34.267250 (MainThread): Opening a new connection, currently in state init
2023-06-25 01:22:34.484751 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:22:34.484751 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:22:34.484751 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:22:34.484751 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:22:34.484751 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:22:34.485251 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:22:34.485251 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:22:34.516250 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:22:34.516250 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:22:34.635250 (MainThread): scipy not found, skipping conversion test.
2023-06-25 01:22:34.636750 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2023-06-25 01:22:34.636750 (MainThread): Found 1 model, 0 tests, 0 snapshots, 0 analyses, 127 macros, 0 operations, 0 seed files, 0 sources
2023-06-25 01:22:34.637751 (MainThread): 
2023-06-25 01:22:34.638251 (MainThread): Acquiring new postgres connection "master".
2023-06-25 01:22:34.638251 (MainThread): Opening a new connection, currently in state init
2023-06-25 01:22:34.641751 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2023-06-25 01:22:34.641751 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2023-06-25 01:22:34.696751 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2023-06-25 01:22:34.696751 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2023-06-25 01:22:34.726750 (ThreadPoolExecutor-0_0): SQL status: SELECT 5 in 0.03 seconds
2023-06-25 01:22:34.731750 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_public".
2023-06-25 01:22:34.731750 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2023-06-25 01:22:34.732751 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_public".
2023-06-25 01:22:34.732751 (ThreadPoolExecutor-1_0): On list_postgres_public: BEGIN
2023-06-25 01:22:34.761750 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.03 seconds
2023-06-25 01:22:34.761750 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_public".
2023-06-25 01:22:34.762252 (ThreadPoolExecutor-1_0): On list_postgres_public: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "list_postgres_public"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2023-06-25 01:22:34.764751 (ThreadPoolExecutor-1_0): SQL status: SELECT 2 in 0.00 seconds
2023-06-25 01:22:34.766250 (ThreadPoolExecutor-1_0): On list_postgres_public: ROLLBACK
2023-06-25 01:22:34.771750 (MainThread): Using postgres connection "master".
2023-06-25 01:22:34.772251 (MainThread): On master: BEGIN
2023-06-25 01:22:34.800750 (MainThread): SQL status: BEGIN in 0.03 seconds
2023-06-25 01:22:34.800750 (MainThread): Using postgres connection "master".
2023-06-25 01:22:34.800750 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2023-06-25 01:22:34.804250 (MainThread): SQL status: SELECT 1 in 0.00 seconds
2023-06-25 01:22:34.805750 (MainThread): On master: ROLLBACK
2023-06-25 01:22:34.805750 (MainThread): Using postgres connection "master".
2023-06-25 01:22:34.805750 (MainThread): On master: BEGIN
2023-06-25 01:22:34.806251 (MainThread): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:22:34.806251 (MainThread): On master: COMMIT
2023-06-25 01:22:34.806251 (MainThread): Using postgres connection "master".
2023-06-25 01:22:34.806251 (MainThread): On master: COMMIT
2023-06-25 01:22:34.806251 (MainThread): SQL status: COMMIT in 0.00 seconds
2023-06-25 01:22:34.806750 (MainThread): 21:22:34 | Concurrency: 1 threads (target='dev')
2023-06-25 01:22:34.806750 (MainThread): 21:22:34 | 
2023-06-25 01:22:34.808752 (Thread-1): Began running node model.transform_data.transform_data
2023-06-25 01:22:34.808752 (Thread-1): 21:22:34 | 1 of 1 START view model public.transform_data........................ [RUN]
2023-06-25 01:22:34.808752 (Thread-1): Acquiring new postgres connection "model.transform_data.transform_data".
2023-06-25 01:22:34.809250 (Thread-1): Opening a new connection, currently in state init
2023-06-25 01:22:34.809250 (Thread-1): Compiling model.transform_data.transform_data
2023-06-25 01:22:34.818250 (Thread-1): Writing injected SQL for node "model.transform_data.transform_data"
2023-06-25 01:22:34.819252 (Thread-1): finished collecting timing info
2023-06-25 01:22:34.839250 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:22:34.839250 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */
drop view if exists "postgres"."public"."transform_data__dbt_tmp" cascade
2023-06-25 01:22:34.867805 (Thread-1): SQL status: DROP VIEW in 0.03 seconds
2023-06-25 01:22:34.869304 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:22:34.869304 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */
drop view if exists "postgres"."public"."transform_data__dbt_backup" cascade
2023-06-25 01:22:34.869804 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2023-06-25 01:22:34.870805 (Thread-1): Writing runtime SQL for node "model.transform_data.transform_data"
2023-06-25 01:22:34.871304 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:22:34.871304 (Thread-1): On model.transform_data.transform_data: BEGIN
2023-06-25 01:22:34.871304 (Thread-1): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:22:34.871304 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:22:34.871804 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */

  create view "postgres"."public"."transform_data__dbt_tmp" as (
    -- Create a temporary table to hold the filtered and transformed data
CREATE TEMPORARY TABLE temp_transactions AS
SELECT
  "address",
  "amount",
  "timestamp"
FROM
  public.transactions
WHERE
  "timestamp" > CURRENT_TIMESTAMP - INTERVAL '2 years';

-- Clear existing data from the target table
DELETE FROM public.transactions;

-- Insert the data from the temporary table into the target table
INSERT INTO public.transactions ("address", "amount", "timestamp")
SELECT
  "address",
  "amount",
  "timestamp"
FROM
  temp_transactions;
  );

2023-06-25 01:22:34.871804 (Thread-1): Postgres error: syntax error at or near "CREATE"
LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
        ^

2023-06-25 01:22:34.871804 (Thread-1): On model.transform_data.transform_data: ROLLBACK
2023-06-25 01:22:34.872305 (Thread-1): finished collecting timing info
2023-06-25 01:22:34.872305 (Thread-1): Database Error in model transform_data (models\transformations\transform_data.sql)
  syntax error at or near "CREATE"
  LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
          ^
  compiled SQL at target\run\transform_data\transformations\transform_data.sql
Traceback (most recent call last):
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\postgres\connections.py", line 46, in exception_handler
    yield
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near "CREATE"
LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
        ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 223, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 166, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 268, in run
    return self.execute(compiled_node, manifest)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 450, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 60, in macro
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\base\impl.py", line 220, in execute
    fetch=fetch
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 116, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 82, in add_query
    return connection, cursor
  File "c:\users\me\appdata\local\programs\python\python37\lib\contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\postgres\connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model transform_data (models\transformations\transform_data.sql)
  syntax error at or near "CREATE"
  LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
          ^
  compiled SQL at target\run\transform_data\transformations\transform_data.sql
2023-06-25 01:22:34.873804 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '71c391ab-c9b3-469a-bb68-35a58ef7b139', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025632D431D0>]}
2023-06-25 01:22:34.874305 (Thread-1): 21:22:34 | 1 of 1 ERROR creating view model public.transform_data............... [ERROR in 0.07s]
2023-06-25 01:22:34.874805 (Thread-1): Finished running node model.transform_data.transform_data
2023-06-25 01:22:34.916933 (MainThread): Using postgres connection "master".
2023-06-25 01:22:34.916933 (MainThread): On master: BEGIN
2023-06-25 01:22:34.916933 (MainThread): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:22:34.916933 (MainThread): On master: COMMIT
2023-06-25 01:22:34.917404 (MainThread): Using postgres connection "master".
2023-06-25 01:22:34.917404 (MainThread): On master: COMMIT
2023-06-25 01:22:34.917404 (MainThread): SQL status: COMMIT in 0.00 seconds
2023-06-25 01:22:34.917404 (MainThread): 21:22:34 | 
2023-06-25 01:22:34.917934 (MainThread): 21:22:34 | Finished running 1 view model in 0.28s.
2023-06-25 01:22:34.917934 (MainThread): Connection 'master' was left open.
2023-06-25 01:22:34.917934 (MainThread): On master: Close
2023-06-25 01:22:34.918404 (MainThread): Connection 'list_postgres' was left open.
2023-06-25 01:22:34.918404 (MainThread): On list_postgres: Close
2023-06-25 01:22:34.918404 (MainThread): Connection 'list_postgres_public' was left open.
2023-06-25 01:22:34.918404 (MainThread): On list_postgres_public: Close
2023-06-25 01:22:34.918404 (MainThread): Connection 'model.transform_data.transform_data' was left open.
2023-06-25 01:22:34.918404 (MainThread): On model.transform_data.transform_data: Close
2023-06-25 01:22:34.920905 (MainThread): 
2023-06-25 01:22:34.921405 (MainThread): Completed with 1 error and 0 warnings:
2023-06-25 01:22:34.921405 (MainThread): 
2023-06-25 01:22:34.921905 (MainThread): Database Error in model transform_data (models\transformations\transform_data.sql)
2023-06-25 01:22:34.921905 (MainThread):   syntax error at or near "CREATE"
2023-06-25 01:22:34.922404 (MainThread):   LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
2023-06-25 01:22:34.922404 (MainThread):           ^
2023-06-25 01:22:34.922404 (MainThread):   compiled SQL at target\run\transform_data\transformations\transform_data.sql
2023-06-25 01:22:34.922904 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2023-06-25 01:22:34.922904 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025632D234A8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002560A966A20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025632D64FD0>]}
2023-06-25 01:22:34.923403 (MainThread): Flushing usage events
2023-06-25 01:23:04.162233 (MainThread): Running with dbt=0.16.0
2023-06-25 01:23:04.200230 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='C:\\Users\\Me\\.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2023-06-25 01:23:04.200731 (MainThread): Tracking: tracking
2023-06-25 01:23:04.201231 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000248DD67A4A8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000248DD67A048>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000248DD681EF0>]}
2023-06-25 01:23:04.213231 (MainThread): Partial parsing not enabled
2023-06-25 01:23:04.215231 (MainThread): Parsing macros\core.sql
2023-06-25 01:23:04.218730 (MainThread): Parsing macros\adapters\common.sql
2023-06-25 01:23:04.250231 (MainThread): Parsing macros\etc\datetime.sql
2023-06-25 01:23:04.257231 (MainThread): Parsing macros\etc\get_custom_alias.sql
2023-06-25 01:23:04.258231 (MainThread): Parsing macros\etc\get_custom_database.sql
2023-06-25 01:23:04.258731 (MainThread): Parsing macros\etc\get_custom_schema.sql
2023-06-25 01:23:04.260731 (MainThread): Parsing macros\etc\get_relation_comment.sql
2023-06-25 01:23:04.262231 (MainThread): Parsing macros\etc\is_incremental.sql
2023-06-25 01:23:04.263230 (MainThread): Parsing macros\etc\query.sql
2023-06-25 01:23:04.264231 (MainThread): Parsing macros\materializations\helpers.sql
2023-06-25 01:23:04.270231 (MainThread): Parsing macros\materializations\common\merge.sql
2023-06-25 01:23:04.279730 (MainThread): Parsing macros\materializations\incremental\helpers.sql
2023-06-25 01:23:04.281230 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2023-06-25 01:23:04.285730 (MainThread): Parsing macros\materializations\seed\seed.sql
2023-06-25 01:23:04.301731 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2023-06-25 01:23:04.326730 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2023-06-25 01:23:04.328231 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2023-06-25 01:23:04.340731 (MainThread): Parsing macros\materializations\table\table.sql
2023-06-25 01:23:04.345731 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2023-06-25 01:23:04.349730 (MainThread): Parsing macros\materializations\view\view.sql
2023-06-25 01:23:04.354230 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2023-06-25 01:23:04.356231 (MainThread): Parsing macros\schema_tests\not_null.sql
2023-06-25 01:23:04.356731 (MainThread): Parsing macros\schema_tests\relationships.sql
2023-06-25 01:23:04.357731 (MainThread): Parsing macros\schema_tests\unique.sql
2023-06-25 01:23:04.359231 (MainThread): Parsing macros\adapters.sql
2023-06-25 01:23:04.372231 (MainThread): Parsing macros\catalog.sql
2023-06-25 01:23:04.373730 (MainThread): Parsing macros\relations.sql
2023-06-25 01:23:04.375231 (MainThread): Parsing macros\materializations\snapshot_merge.sql
2023-06-25 01:23:04.388231 (MainThread): Partial parsing not enabled
2023-06-25 01:23:04.406730 (MainThread): Acquiring new postgres connection "model.transform_data.transform_data".
2023-06-25 01:23:04.406730 (MainThread): Opening a new connection, currently in state init
2023-06-25 01:23:04.626231 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:23:04.626231 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:23:04.626231 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:23:04.626231 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:23:04.626231 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:23:04.626231 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:23:04.626731 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:23:04.658231 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:23:04.658732 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:23:04.778731 (MainThread): scipy not found, skipping conversion test.
2023-06-25 01:23:04.779731 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2023-06-25 01:23:04.780231 (MainThread): Found 1 model, 0 tests, 0 snapshots, 0 analyses, 127 macros, 0 operations, 0 seed files, 0 sources
2023-06-25 01:23:04.781231 (MainThread): 
2023-06-25 01:23:04.781231 (MainThread): Acquiring new postgres connection "master".
2023-06-25 01:23:04.781231 (MainThread): Opening a new connection, currently in state init
2023-06-25 01:23:04.785231 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2023-06-25 01:23:04.785231 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2023-06-25 01:23:04.840262 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2023-06-25 01:23:04.840764 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2023-06-25 01:23:04.871295 (ThreadPoolExecutor-0_0): SQL status: SELECT 5 in 0.03 seconds
2023-06-25 01:23:04.876795 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_public".
2023-06-25 01:23:04.876795 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2023-06-25 01:23:04.877825 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_public".
2023-06-25 01:23:04.877825 (ThreadPoolExecutor-1_0): On list_postgres_public: BEGIN
2023-06-25 01:23:04.906982 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.03 seconds
2023-06-25 01:23:04.906982 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_public".
2023-06-25 01:23:04.906982 (ThreadPoolExecutor-1_0): On list_postgres_public: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "list_postgres_public"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2023-06-25 01:23:04.910017 (ThreadPoolExecutor-1_0): SQL status: SELECT 2 in 0.00 seconds
2023-06-25 01:23:04.911485 (ThreadPoolExecutor-1_0): On list_postgres_public: ROLLBACK
2023-06-25 01:23:04.917514 (MainThread): Using postgres connection "master".
2023-06-25 01:23:04.917514 (MainThread): On master: BEGIN
2023-06-25 01:23:04.945985 (MainThread): SQL status: BEGIN in 0.03 seconds
2023-06-25 01:23:04.945985 (MainThread): Using postgres connection "master".
2023-06-25 01:23:04.945985 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2023-06-25 01:23:04.949984 (MainThread): SQL status: SELECT 1 in 0.00 seconds
2023-06-25 01:23:04.950985 (MainThread): On master: ROLLBACK
2023-06-25 01:23:04.951485 (MainThread): Using postgres connection "master".
2023-06-25 01:23:04.951485 (MainThread): On master: BEGIN
2023-06-25 01:23:04.951485 (MainThread): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:23:04.951485 (MainThread): On master: COMMIT
2023-06-25 01:23:04.951485 (MainThread): Using postgres connection "master".
2023-06-25 01:23:04.951985 (MainThread): On master: COMMIT
2023-06-25 01:23:04.951985 (MainThread): SQL status: COMMIT in 0.00 seconds
2023-06-25 01:23:04.951985 (MainThread): 21:23:04 | Concurrency: 1 threads (target='dev')
2023-06-25 01:23:04.952486 (MainThread): 21:23:04 | 
2023-06-25 01:23:04.953985 (Thread-1): Began running node model.transform_data.transform_data
2023-06-25 01:23:04.953985 (Thread-1): 21:23:04 | 1 of 1 START view model public.transform_data........................ [RUN]
2023-06-25 01:23:04.954485 (Thread-1): Acquiring new postgres connection "model.transform_data.transform_data".
2023-06-25 01:23:04.954485 (Thread-1): Opening a new connection, currently in state init
2023-06-25 01:23:04.954485 (Thread-1): Compiling model.transform_data.transform_data
2023-06-25 01:23:04.963985 (Thread-1): Writing injected SQL for node "model.transform_data.transform_data"
2023-06-25 01:23:04.964485 (Thread-1): finished collecting timing info
2023-06-25 01:23:04.984985 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:23:04.984985 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */
drop view if exists "postgres"."public"."transform_data__dbt_tmp" cascade
2023-06-25 01:23:05.013543 (Thread-1): SQL status: DROP VIEW in 0.03 seconds
2023-06-25 01:23:05.015042 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:23:05.015042 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */
drop view if exists "postgres"."public"."transform_data__dbt_backup" cascade
2023-06-25 01:23:05.015542 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2023-06-25 01:23:05.016542 (Thread-1): Writing runtime SQL for node "model.transform_data.transform_data"
2023-06-25 01:23:05.017042 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:23:05.017042 (Thread-1): On model.transform_data.transform_data: BEGIN
2023-06-25 01:23:05.017543 (Thread-1): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:23:05.017543 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:23:05.017543 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */

  create view "postgres"."public"."transform_data__dbt_tmp" as (
    -- Create a temporary table to hold the filtered and transformed data
CREATE TEMPORARY TABLE temp_transactions AS
SELECT
  "address",
  "amount",
  "timestamp"
FROM
  public.transactions
WHERE
  "timestamp" > CURRENT_TIMESTAMP - INTERVAL '2 years';

-- Clear existing data from the target table
TRUNCATE TABLE public.transactions;

-- Insert the data from the temporary table into the target table
INSERT INTO public.transactions ("address", "amount", "timestamp")
SELECT
  "address",
  "amount",
  "timestamp"
FROM
  temp_transactions;
  );

2023-06-25 01:23:05.018042 (Thread-1): Postgres error: syntax error at or near "CREATE"
LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
        ^

2023-06-25 01:23:05.018042 (Thread-1): On model.transform_data.transform_data: ROLLBACK
2023-06-25 01:23:05.018042 (Thread-1): finished collecting timing info
2023-06-25 01:23:05.018542 (Thread-1): Database Error in model transform_data (models\transformations\transform_data.sql)
  syntax error at or near "CREATE"
  LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
          ^
  compiled SQL at target\run\transform_data\transformations\transform_data.sql
Traceback (most recent call last):
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\postgres\connections.py", line 46, in exception_handler
    yield
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near "CREATE"
LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
        ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 223, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 166, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 268, in run
    return self.execute(compiled_node, manifest)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 450, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 60, in macro
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\base\impl.py", line 220, in execute
    fetch=fetch
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 116, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 82, in add_query
    return connection, cursor
  File "c:\users\me\appdata\local\programs\python\python37\lib\contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\postgres\connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model transform_data (models\transformations\transform_data.sql)
  syntax error at or near "CREATE"
  LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
          ^
  compiled SQL at target\run\transform_data\transformations\transform_data.sql
2023-06-25 01:23:05.020042 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '83ae5909-3fb2-4217-9c05-c5d8ee954258', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000248FFC8A6D8>]}
2023-06-25 01:23:05.020042 (Thread-1): 21:23:05 | 1 of 1 ERROR creating view model public.transform_data............... [ERROR in 0.07s]
2023-06-25 01:23:05.021042 (Thread-1): Finished running node model.transform_data.transform_data
2023-06-25 01:23:05.060775 (MainThread): Using postgres connection "master".
2023-06-25 01:23:05.060775 (MainThread): On master: BEGIN
2023-06-25 01:23:05.060775 (MainThread): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:23:05.061274 (MainThread): On master: COMMIT
2023-06-25 01:23:05.061274 (MainThread): Using postgres connection "master".
2023-06-25 01:23:05.061274 (MainThread): On master: COMMIT
2023-06-25 01:23:05.061274 (MainThread): SQL status: COMMIT in 0.00 seconds
2023-06-25 01:23:05.061776 (MainThread): 21:23:05 | 
2023-06-25 01:23:05.061776 (MainThread): 21:23:05 | Finished running 1 view model in 0.28s.
2023-06-25 01:23:05.061776 (MainThread): Connection 'master' was left open.
2023-06-25 01:23:05.062274 (MainThread): On master: Close
2023-06-25 01:23:05.062274 (MainThread): Connection 'list_postgres' was left open.
2023-06-25 01:23:05.062274 (MainThread): On list_postgres: Close
2023-06-25 01:23:05.062274 (MainThread): Connection 'list_postgres_public' was left open.
2023-06-25 01:23:05.062274 (MainThread): On list_postgres_public: Close
2023-06-25 01:23:05.062274 (MainThread): Connection 'model.transform_data.transform_data' was left open.
2023-06-25 01:23:05.062821 (MainThread): On model.transform_data.transform_data: Close
2023-06-25 01:23:05.064774 (MainThread): 
2023-06-25 01:23:05.065274 (MainThread): Completed with 1 error and 0 warnings:
2023-06-25 01:23:05.065274 (MainThread): 
2023-06-25 01:23:05.065274 (MainThread): Database Error in model transform_data (models\transformations\transform_data.sql)
2023-06-25 01:23:05.065773 (MainThread):   syntax error at or near "CREATE"
2023-06-25 01:23:05.065773 (MainThread):   LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
2023-06-25 01:23:05.065773 (MainThread):           ^
2023-06-25 01:23:05.066274 (MainThread):   compiled SQL at target\run\transform_data\transformations\transform_data.sql
2023-06-25 01:23:05.066274 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2023-06-25 01:23:05.066774 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000248FFC79470>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000248FFC2E908>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000248FFCB3F98>]}
2023-06-25 01:23:05.066774 (MainThread): Flushing usage events
2023-06-25 01:23:07.933198 (MainThread): Running with dbt=0.16.0
2023-06-25 01:23:07.970698 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='C:\\Users\\Me\\.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target='dev', test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2023-06-25 01:23:07.971199 (MainThread): Tracking: tracking
2023-06-25 01:23:07.971698 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C29C94EE80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C29C94E978>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C29C94E208>]}
2023-06-25 01:23:07.983698 (MainThread): Partial parsing not enabled
2023-06-25 01:23:07.985698 (MainThread): Parsing macros\core.sql
2023-06-25 01:23:07.989198 (MainThread): Parsing macros\adapters\common.sql
2023-06-25 01:23:08.020698 (MainThread): Parsing macros\etc\datetime.sql
2023-06-25 01:23:08.027698 (MainThread): Parsing macros\etc\get_custom_alias.sql
2023-06-25 01:23:08.028198 (MainThread): Parsing macros\etc\get_custom_database.sql
2023-06-25 01:23:08.029198 (MainThread): Parsing macros\etc\get_custom_schema.sql
2023-06-25 01:23:08.030698 (MainThread): Parsing macros\etc\get_relation_comment.sql
2023-06-25 01:23:08.032698 (MainThread): Parsing macros\etc\is_incremental.sql
2023-06-25 01:23:08.033698 (MainThread): Parsing macros\etc\query.sql
2023-06-25 01:23:08.034698 (MainThread): Parsing macros\materializations\helpers.sql
2023-06-25 01:23:08.040698 (MainThread): Parsing macros\materializations\common\merge.sql
2023-06-25 01:23:08.050198 (MainThread): Parsing macros\materializations\incremental\helpers.sql
2023-06-25 01:23:08.051698 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2023-06-25 01:23:08.056197 (MainThread): Parsing macros\materializations\seed\seed.sql
2023-06-25 01:23:08.072198 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2023-06-25 01:23:08.096697 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2023-06-25 01:23:08.098198 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2023-06-25 01:23:08.110697 (MainThread): Parsing macros\materializations\table\table.sql
2023-06-25 01:23:08.115698 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2023-06-25 01:23:08.119698 (MainThread): Parsing macros\materializations\view\view.sql
2023-06-25 01:23:08.124198 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2023-06-25 01:23:08.126198 (MainThread): Parsing macros\schema_tests\not_null.sql
2023-06-25 01:23:08.126698 (MainThread): Parsing macros\schema_tests\relationships.sql
2023-06-25 01:23:08.127698 (MainThread): Parsing macros\schema_tests\unique.sql
2023-06-25 01:23:08.128698 (MainThread): Parsing macros\adapters.sql
2023-06-25 01:23:08.141698 (MainThread): Parsing macros\catalog.sql
2023-06-25 01:23:08.143698 (MainThread): Parsing macros\relations.sql
2023-06-25 01:23:08.144698 (MainThread): Parsing macros\materializations\snapshot_merge.sql
2023-06-25 01:23:08.157698 (MainThread): Partial parsing not enabled
2023-06-25 01:23:08.176198 (MainThread): Acquiring new postgres connection "model.transform_data.transform_data".
2023-06-25 01:23:08.176198 (MainThread): Opening a new connection, currently in state init
2023-06-25 01:23:08.395198 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:23:08.395198 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:23:08.395198 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:23:08.395198 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:23:08.395198 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:23:08.395198 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:23:08.395198 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:23:08.426699 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:23:08.426699 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:23:08.548199 (MainThread): scipy not found, skipping conversion test.
2023-06-25 01:23:08.549198 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2023-06-25 01:23:08.549698 (MainThread): Found 1 model, 0 tests, 0 snapshots, 0 analyses, 127 macros, 0 operations, 0 seed files, 0 sources
2023-06-25 01:23:08.550198 (MainThread): 
2023-06-25 01:23:08.550198 (MainThread): Acquiring new postgres connection "master".
2023-06-25 01:23:08.550698 (MainThread): Opening a new connection, currently in state init
2023-06-25 01:23:08.554199 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_postgres".
2023-06-25 01:23:08.554199 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2023-06-25 01:23:08.609697 (ThreadPoolExecutor-0_0): Using postgres connection "list_postgres".
2023-06-25 01:23:08.609697 (ThreadPoolExecutor-0_0): On list_postgres: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "list_postgres"} */

    select distinct nspname from pg_namespace
  
2023-06-25 01:23:08.639198 (ThreadPoolExecutor-0_0): SQL status: SELECT 5 in 0.03 seconds
2023-06-25 01:23:08.644697 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_postgres_public".
2023-06-25 01:23:08.644697 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2023-06-25 01:23:08.645697 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_public".
2023-06-25 01:23:08.645697 (ThreadPoolExecutor-1_0): On list_postgres_public: BEGIN
2023-06-25 01:23:08.673199 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.03 seconds
2023-06-25 01:23:08.673199 (ThreadPoolExecutor-1_0): Using postgres connection "list_postgres_public".
2023-06-25 01:23:08.673199 (ThreadPoolExecutor-1_0): On list_postgres_public: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "list_postgres_public"} */
select
      'postgres' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'postgres' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2023-06-25 01:23:08.675698 (ThreadPoolExecutor-1_0): SQL status: SELECT 2 in 0.00 seconds
2023-06-25 01:23:08.677197 (ThreadPoolExecutor-1_0): On list_postgres_public: ROLLBACK
2023-06-25 01:23:08.683198 (MainThread): Using postgres connection "master".
2023-06-25 01:23:08.683198 (MainThread): On master: BEGIN
2023-06-25 01:23:08.710583 (MainThread): SQL status: BEGIN in 0.03 seconds
2023-06-25 01:23:08.710583 (MainThread): Using postgres connection "master".
2023-06-25 01:23:08.710583 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2023-06-25 01:23:08.714584 (MainThread): SQL status: SELECT 1 in 0.00 seconds
2023-06-25 01:23:08.715583 (MainThread): On master: ROLLBACK
2023-06-25 01:23:08.716084 (MainThread): Using postgres connection "master".
2023-06-25 01:23:08.716084 (MainThread): On master: BEGIN
2023-06-25 01:23:08.716084 (MainThread): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:23:08.716084 (MainThread): On master: COMMIT
2023-06-25 01:23:08.716583 (MainThread): Using postgres connection "master".
2023-06-25 01:23:08.716583 (MainThread): On master: COMMIT
2023-06-25 01:23:08.716583 (MainThread): SQL status: COMMIT in 0.00 seconds
2023-06-25 01:23:08.716583 (MainThread): 21:23:08 | Concurrency: 1 threads (target='dev')
2023-06-25 01:23:08.717083 (MainThread): 21:23:08 | 
2023-06-25 01:23:08.718419 (Thread-1): Began running node model.transform_data.transform_data
2023-06-25 01:23:08.718419 (Thread-1): 21:23:08 | 1 of 1 START view model public.transform_data........................ [RUN]
2023-06-25 01:23:08.718419 (Thread-1): Acquiring new postgres connection "model.transform_data.transform_data".
2023-06-25 01:23:08.718897 (Thread-1): Opening a new connection, currently in state init
2023-06-25 01:23:08.718897 (Thread-1): Compiling model.transform_data.transform_data
2023-06-25 01:23:08.728397 (Thread-1): Writing injected SQL for node "model.transform_data.transform_data"
2023-06-25 01:23:08.728897 (Thread-1): finished collecting timing info
2023-06-25 01:23:08.749398 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:23:08.749898 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */
drop view if exists "postgres"."public"."transform_data__dbt_tmp" cascade
2023-06-25 01:23:08.776897 (Thread-1): SQL status: DROP VIEW in 0.03 seconds
2023-06-25 01:23:08.778397 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:23:08.778897 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */
drop view if exists "postgres"."public"."transform_data__dbt_backup" cascade
2023-06-25 01:23:08.778897 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2023-06-25 01:23:08.779897 (Thread-1): Writing runtime SQL for node "model.transform_data.transform_data"
2023-06-25 01:23:08.780397 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:23:08.780397 (Thread-1): On model.transform_data.transform_data: BEGIN
2023-06-25 01:23:08.780397 (Thread-1): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:23:08.780397 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:23:08.780897 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */

  create view "postgres"."public"."transform_data__dbt_tmp" as (
    -- Create a temporary table to hold the filtered and transformed data
CREATE TEMPORARY TABLE temp_transactions AS
SELECT
  "address",
  "amount",
  "timestamp"
FROM
  public.transactions
WHERE
  "timestamp" > CURRENT_TIMESTAMP - INTERVAL '2 years';

-- Clear existing data from the target table
TRUNCATE TABLE public.transactions;

-- Insert the data from the temporary table into the target table
INSERT INTO public.transactions ("address", "amount", "timestamp")
SELECT
  "address",
  "amount",
  "timestamp"
FROM
  temp_transactions;
  );

2023-06-25 01:23:08.780897 (Thread-1): Postgres error: syntax error at or near "CREATE"
LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
        ^

2023-06-25 01:23:08.780897 (Thread-1): On model.transform_data.transform_data: ROLLBACK
2023-06-25 01:23:08.781398 (Thread-1): finished collecting timing info
2023-06-25 01:23:08.781398 (Thread-1): Database Error in model transform_data (models\transformations\transform_data.sql)
  syntax error at or near "CREATE"
  LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
          ^
  compiled SQL at target\run\transform_data\transformations\transform_data.sql
Traceback (most recent call last):
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\postgres\connections.py", line 46, in exception_handler
    yield
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near "CREATE"
LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
        ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 223, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 166, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 268, in run
    return self.execute(compiled_node, manifest)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 450, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 60, in macro
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\base\impl.py", line 220, in execute
    fetch=fetch
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 116, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 82, in add_query
    return connection, cursor
  File "c:\users\me\appdata\local\programs\python\python37\lib\contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\postgres\connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model transform_data (models\transformations\transform_data.sql)
  syntax error at or near "CREATE"
  LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
          ^
  compiled SQL at target\run\transform_data\transformations\transform_data.sql
2023-06-25 01:23:08.782897 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3ffce7c8-92f3-4788-8e0f-1db54cf9825a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C2C4F60240>]}
2023-06-25 01:23:08.783398 (Thread-1): 21:23:08 | 1 of 1 ERROR creating view model public.transform_data............... [ERROR in 0.06s]
2023-06-25 01:23:08.783398 (Thread-1): Finished running node model.transform_data.transform_data
2023-06-25 01:23:08.831536 (MainThread): Using postgres connection "master".
2023-06-25 01:23:08.831536 (MainThread): On master: BEGIN
2023-06-25 01:23:08.831536 (MainThread): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:23:08.831536 (MainThread): On master: COMMIT
2023-06-25 01:23:08.831536 (MainThread): Using postgres connection "master".
2023-06-25 01:23:08.832036 (MainThread): On master: COMMIT
2023-06-25 01:23:08.832036 (MainThread): SQL status: COMMIT in 0.00 seconds
2023-06-25 01:23:08.832036 (MainThread): 21:23:08 | 
2023-06-25 01:23:08.832536 (MainThread): 21:23:08 | Finished running 1 view model in 0.28s.
2023-06-25 01:23:08.832536 (MainThread): Connection 'master' was left open.
2023-06-25 01:23:08.832536 (MainThread): On master: Close
2023-06-25 01:23:08.832536 (MainThread): Connection 'list_postgres' was left open.
2023-06-25 01:23:08.832536 (MainThread): On list_postgres: Close
2023-06-25 01:23:08.833037 (MainThread): Connection 'list_postgres_public' was left open.
2023-06-25 01:23:08.833037 (MainThread): On list_postgres_public: Close
2023-06-25 01:23:08.833037 (MainThread): Connection 'model.transform_data.transform_data' was left open.
2023-06-25 01:23:08.833037 (MainThread): On model.transform_data.transform_data: Close
2023-06-25 01:23:08.835036 (MainThread): 
2023-06-25 01:23:08.835536 (MainThread): Completed with 1 error and 0 warnings:
2023-06-25 01:23:08.835536 (MainThread): 
2023-06-25 01:23:08.836036 (MainThread): Database Error in model transform_data (models\transformations\transform_data.sql)
2023-06-25 01:23:08.836036 (MainThread):   syntax error at or near "CREATE"
2023-06-25 01:23:08.836036 (MainThread):   LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
2023-06-25 01:23:08.836537 (MainThread):           ^
2023-06-25 01:23:08.836537 (MainThread):   compiled SQL at target\run\transform_data\transformations\transform_data.sql
2023-06-25 01:23:08.836537 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2023-06-25 01:23:08.837035 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C2C4F39470>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C29CB92208>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C2C4F602B0>]}
2023-06-25 01:23:08.837035 (MainThread): Flushing usage events
2023-06-25 01:23:43.966251 (MainThread): Running with dbt=0.16.0
2023-06-25 01:23:44.003251 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='C:\\Users\\Me\\.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target='dev', test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2023-06-25 01:23:44.003751 (MainThread): Tracking: tracking
2023-06-25 01:23:44.004251 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F2CAAA0240>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F2CAAA0D30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F2CAAA0C88>]}
2023-06-25 01:23:44.015751 (MainThread): Partial parsing not enabled
2023-06-25 01:23:44.018251 (MainThread): Parsing macros\core.sql
2023-06-25 01:23:44.021251 (MainThread): Parsing macros\adapters\common.sql
2023-06-25 01:23:44.052251 (MainThread): Parsing macros\etc\datetime.sql
2023-06-25 01:23:44.059251 (MainThread): Parsing macros\etc\get_custom_alias.sql
2023-06-25 01:23:44.059751 (MainThread): Parsing macros\etc\get_custom_database.sql
2023-06-25 01:23:44.060751 (MainThread): Parsing macros\etc\get_custom_schema.sql
2023-06-25 01:23:44.062251 (MainThread): Parsing macros\etc\get_relation_comment.sql
2023-06-25 01:23:44.063751 (MainThread): Parsing macros\etc\is_incremental.sql
2023-06-25 01:23:44.065251 (MainThread): Parsing macros\etc\query.sql
2023-06-25 01:23:44.066251 (MainThread): Parsing macros\materializations\helpers.sql
2023-06-25 01:23:44.071751 (MainThread): Parsing macros\materializations\common\merge.sql
2023-06-25 01:23:44.081252 (MainThread): Parsing macros\materializations\incremental\helpers.sql
2023-06-25 01:23:44.082751 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2023-06-25 01:23:44.087251 (MainThread): Parsing macros\materializations\seed\seed.sql
2023-06-25 01:23:44.103251 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2023-06-25 01:23:44.127751 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2023-06-25 01:23:44.129251 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2023-06-25 01:23:44.141751 (MainThread): Parsing macros\materializations\table\table.sql
2023-06-25 01:23:44.146751 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2023-06-25 01:23:44.150251 (MainThread): Parsing macros\materializations\view\view.sql
2023-06-25 01:23:44.154751 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2023-06-25 01:23:44.156251 (MainThread): Parsing macros\schema_tests\not_null.sql
2023-06-25 01:23:44.157251 (MainThread): Parsing macros\schema_tests\relationships.sql
2023-06-25 01:23:44.158251 (MainThread): Parsing macros\schema_tests\unique.sql
2023-06-25 01:23:44.159251 (MainThread): Parsing macros\adapters.sql
2023-06-25 01:23:44.172251 (MainThread): Parsing macros\catalog.sql
2023-06-25 01:23:44.173751 (MainThread): Parsing macros\relations.sql
2023-06-25 01:23:44.175251 (MainThread): Parsing macros\materializations\snapshot_merge.sql
2023-06-25 01:23:44.187751 (MainThread): Partial parsing not enabled
2023-06-25 01:23:44.206252 (MainThread): Acquiring new postgres connection "model.transform_data.transform_data".
2023-06-25 01:23:44.206252 (MainThread): Opening a new connection, currently in state init
2023-06-25 01:23:44.423751 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:23:44.423751 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:23:44.423751 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:23:44.423751 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:23:44.423751 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:23:44.423751 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:23:44.424251 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:23:44.454751 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:23:44.454751 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:23:44.573751 (MainThread): scipy not found, skipping conversion test.
2023-06-25 01:23:44.574751 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2023-06-25 01:23:44.574751 (MainThread): Found 1 model, 0 tests, 0 snapshots, 0 analyses, 127 macros, 0 operations, 0 seed files, 0 sources
2023-06-25 01:23:44.575751 (MainThread): 
2023-06-25 01:23:44.575751 (MainThread): Acquiring new postgres connection "master".
2023-06-25 01:23:44.576251 (MainThread): Opening a new connection, currently in state init
2023-06-25 01:23:44.579752 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_transactions".
2023-06-25 01:23:44.579752 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2023-06-25 01:23:44.635251 (ThreadPoolExecutor-0_0): Using postgres connection "list_transactions".
2023-06-25 01:23:44.635251 (ThreadPoolExecutor-0_0): On list_transactions: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "list_transactions"} */

    select distinct nspname from pg_namespace
  
2023-06-25 01:23:44.663751 (ThreadPoolExecutor-0_0): Got an error when attempting to open a postgres connection: 'connection to server at "127.0.0.1", port 5432 failed: FATAL:  database "transactions" does not exist
'
2023-06-25 01:23:44.663751 (ThreadPoolExecutor-0_0): Error running SQL: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "list_transactions"} */

    select distinct nspname from pg_namespace
  
2023-06-25 01:23:44.663751 (ThreadPoolExecutor-0_0): Rolling back transaction.
2023-06-25 01:23:44.663751 (ThreadPoolExecutor-0_0): On list_transactions: No close available on handle
2023-06-25 01:23:44.663751 (ThreadPoolExecutor-0_0): Error running SQL: macro list_schemas
2023-06-25 01:23:44.664252 (ThreadPoolExecutor-0_0): Rolling back transaction.
2023-06-25 01:23:44.664252 (MainThread): Connection 'master' was properly closed.
2023-06-25 01:23:44.664252 (MainThread): Connection 'list_transactions' was properly closed.
2023-06-25 01:23:44.664751 (MainThread): ERROR: Database Error
  connection to server at "127.0.0.1", port 5432 failed: FATAL:  database "transactions" does not exist
  
2023-06-25 01:23:44.664751 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F2F2C7E400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F2CABEBA58>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F2F2016A20>]}
2023-06-25 01:23:44.665252 (MainThread): Flushing usage events
2023-06-25 01:24:31.330721 (MainThread): Running with dbt=0.16.0
2023-06-25 01:24:31.368721 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='C:\\Users\\Me\\.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target='dev', test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2023-06-25 01:24:31.369221 (MainThread): Tracking: tracking
2023-06-25 01:24:31.369721 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002093233EF98>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002093233EA20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002093233E198>]}
2023-06-25 01:24:31.381721 (MainThread): Partial parsing not enabled
2023-06-25 01:24:31.383720 (MainThread): Parsing macros\core.sql
2023-06-25 01:24:31.387221 (MainThread): Parsing macros\adapters\common.sql
2023-06-25 01:24:31.418721 (MainThread): Parsing macros\etc\datetime.sql
2023-06-25 01:24:31.425721 (MainThread): Parsing macros\etc\get_custom_alias.sql
2023-06-25 01:24:31.426720 (MainThread): Parsing macros\etc\get_custom_database.sql
2023-06-25 01:24:31.427221 (MainThread): Parsing macros\etc\get_custom_schema.sql
2023-06-25 01:24:31.429221 (MainThread): Parsing macros\etc\get_relation_comment.sql
2023-06-25 01:24:31.430721 (MainThread): Parsing macros\etc\is_incremental.sql
2023-06-25 01:24:31.431720 (MainThread): Parsing macros\etc\query.sql
2023-06-25 01:24:31.432721 (MainThread): Parsing macros\materializations\helpers.sql
2023-06-25 01:24:31.438720 (MainThread): Parsing macros\materializations\common\merge.sql
2023-06-25 01:24:31.448220 (MainThread): Parsing macros\materializations\incremental\helpers.sql
2023-06-25 01:24:31.449721 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2023-06-25 01:24:31.454220 (MainThread): Parsing macros\materializations\seed\seed.sql
2023-06-25 01:24:31.470220 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2023-06-25 01:24:31.495221 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2023-06-25 01:24:31.496221 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2023-06-25 01:24:31.509221 (MainThread): Parsing macros\materializations\table\table.sql
2023-06-25 01:24:31.514721 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2023-06-25 01:24:31.518220 (MainThread): Parsing macros\materializations\view\view.sql
2023-06-25 01:24:31.522721 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2023-06-25 01:24:31.524220 (MainThread): Parsing macros\schema_tests\not_null.sql
2023-06-25 01:24:31.525221 (MainThread): Parsing macros\schema_tests\relationships.sql
2023-06-25 01:24:31.526220 (MainThread): Parsing macros\schema_tests\unique.sql
2023-06-25 01:24:31.527221 (MainThread): Parsing macros\adapters.sql
2023-06-25 01:24:31.540220 (MainThread): Parsing macros\catalog.sql
2023-06-25 01:24:31.542220 (MainThread): Parsing macros\relations.sql
2023-06-25 01:24:31.543221 (MainThread): Parsing macros\materializations\snapshot_merge.sql
2023-06-25 01:24:31.556221 (MainThread): Partial parsing not enabled
2023-06-25 01:24:31.575721 (MainThread): Acquiring new postgres connection "model.transform_data.transform_data".
2023-06-25 01:24:31.575721 (MainThread): Opening a new connection, currently in state init
2023-06-25 01:24:31.795721 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:24:31.795721 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:24:31.795721 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:24:31.795721 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:24:31.795721 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:24:31.795721 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:24:31.796221 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:24:31.827221 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:24:31.827721 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:24:31.948221 (MainThread): scipy not found, skipping conversion test.
2023-06-25 01:24:31.949221 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2023-06-25 01:24:31.949721 (MainThread): Found 1 model, 0 tests, 0 snapshots, 0 analyses, 127 macros, 0 operations, 0 seed files, 0 sources
2023-06-25 01:24:31.950221 (MainThread): 
2023-06-25 01:24:31.950721 (MainThread): Acquiring new postgres connection "master".
2023-06-25 01:24:31.950721 (MainThread): Opening a new connection, currently in state init
2023-06-25 01:24:31.954221 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_main_database".
2023-06-25 01:24:31.954720 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2023-06-25 01:24:32.009753 (ThreadPoolExecutor-0_0): Using postgres connection "list_main_database".
2023-06-25 01:24:32.009753 (ThreadPoolExecutor-0_0): On list_main_database: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "list_main_database"} */

    select distinct nspname from pg_namespace
  
2023-06-25 01:24:32.040221 (ThreadPoolExecutor-0_0): SQL status: SELECT 4 in 0.03 seconds
2023-06-25 01:24:32.045220 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_main_database_public".
2023-06-25 01:24:32.045721 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2023-06-25 01:24:32.046251 (ThreadPoolExecutor-1_0): Using postgres connection "list_main_database_public".
2023-06-25 01:24:32.046752 (ThreadPoolExecutor-1_0): On list_main_database_public: BEGIN
2023-06-25 01:24:32.076721 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.03 seconds
2023-06-25 01:24:32.076721 (ThreadPoolExecutor-1_0): Using postgres connection "list_main_database_public".
2023-06-25 01:24:32.076721 (ThreadPoolExecutor-1_0): On list_main_database_public: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "list_main_database_public"} */
select
      'main_database' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'main_database' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2023-06-25 01:24:32.079721 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2023-06-25 01:24:32.080750 (ThreadPoolExecutor-1_0): On list_main_database_public: ROLLBACK
2023-06-25 01:24:32.086721 (MainThread): Using postgres connection "master".
2023-06-25 01:24:32.086721 (MainThread): On master: BEGIN
2023-06-25 01:24:32.115220 (MainThread): SQL status: BEGIN in 0.03 seconds
2023-06-25 01:24:32.115220 (MainThread): Using postgres connection "master".
2023-06-25 01:24:32.115220 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2023-06-25 01:24:32.118720 (MainThread): SQL status: SELECT 0 in 0.00 seconds
2023-06-25 01:24:32.119721 (MainThread): On master: ROLLBACK
2023-06-25 01:24:32.119721 (MainThread): Using postgres connection "master".
2023-06-25 01:24:32.119721 (MainThread): On master: BEGIN
2023-06-25 01:24:32.120220 (MainThread): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:24:32.120220 (MainThread): On master: COMMIT
2023-06-25 01:24:32.120220 (MainThread): Using postgres connection "master".
2023-06-25 01:24:32.120220 (MainThread): On master: COMMIT
2023-06-25 01:24:32.120220 (MainThread): SQL status: COMMIT in 0.00 seconds
2023-06-25 01:24:32.120720 (MainThread): 21:24:32 | Concurrency: 1 threads (target='dev')
2023-06-25 01:24:32.120720 (MainThread): 21:24:32 | 
2023-06-25 01:24:32.122721 (Thread-1): Began running node model.transform_data.transform_data
2023-06-25 01:24:32.122721 (Thread-1): 21:24:32 | 1 of 1 START view model public.transform_data........................ [RUN]
2023-06-25 01:24:32.122721 (Thread-1): Acquiring new postgres connection "model.transform_data.transform_data".
2023-06-25 01:24:32.123220 (Thread-1): Opening a new connection, currently in state init
2023-06-25 01:24:32.123220 (Thread-1): Compiling model.transform_data.transform_data
2023-06-25 01:24:32.132720 (Thread-1): Writing injected SQL for node "model.transform_data.transform_data"
2023-06-25 01:24:32.133220 (Thread-1): finished collecting timing info
2023-06-25 01:24:32.153720 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:24:32.153720 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */
drop view if exists "main_database"."public"."transform_data__dbt_tmp" cascade
2023-06-25 01:24:32.184474 (Thread-1): SQL status: DROP VIEW in 0.03 seconds
2023-06-25 01:24:32.185972 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:24:32.185972 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */
drop view if exists "main_database"."public"."transform_data__dbt_backup" cascade
2023-06-25 01:24:32.186473 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2023-06-25 01:24:32.187472 (Thread-1): Writing runtime SQL for node "model.transform_data.transform_data"
2023-06-25 01:24:32.187972 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:24:32.187972 (Thread-1): On model.transform_data.transform_data: BEGIN
2023-06-25 01:24:32.187972 (Thread-1): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:24:32.188473 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:24:32.188473 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */

  create view "main_database"."public"."transform_data__dbt_tmp" as (
    -- Create a temporary table to hold the filtered and transformed data
CREATE TEMPORARY TABLE temp_transactions AS
SELECT
  "address",
  "amount",
  "timestamp"
FROM
  public.transactions
WHERE
  "timestamp" > CURRENT_TIMESTAMP - INTERVAL '2 years';

-- Clear existing data from the target table
TRUNCATE TABLE public.transactions;

-- Insert the data from the temporary table into the target table
INSERT INTO public.transactions ("address", "amount", "timestamp")
SELECT
  "address",
  "amount",
  "timestamp"
FROM
  temp_transactions;
  );

2023-06-25 01:24:32.188473 (Thread-1): Postgres error: syntax error at or near "CREATE"
LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
        ^

2023-06-25 01:24:32.188473 (Thread-1): On model.transform_data.transform_data: ROLLBACK
2023-06-25 01:24:32.188974 (Thread-1): finished collecting timing info
2023-06-25 01:24:32.188974 (Thread-1): Database Error in model transform_data (models\transformations\transform_data.sql)
  syntax error at or near "CREATE"
  LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
          ^
  compiled SQL at target\run\transform_data\transformations\transform_data.sql
Traceback (most recent call last):
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\postgres\connections.py", line 46, in exception_handler
    yield
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near "CREATE"
LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
        ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 223, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 166, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 268, in run
    return self.execute(compiled_node, manifest)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 450, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 60, in macro
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\base\impl.py", line 220, in execute
    fetch=fetch
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 116, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 82, in add_query
    return connection, cursor
  File "c:\users\me\appdata\local\programs\python\python37\lib\contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\postgres\connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model transform_data (models\transformations\transform_data.sql)
  syntax error at or near "CREATE"
  LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
          ^
  compiled SQL at target\run\transform_data\transformations\transform_data.sql
2023-06-25 01:24:32.190472 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a7f21fab-d653-4943-bc2c-4f4c40575c75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020932338780>]}
2023-06-25 01:24:32.190972 (Thread-1): 21:24:32 | 1 of 1 ERROR creating view model public.transform_data............... [ERROR in 0.07s]
2023-06-25 01:24:32.191472 (Thread-1): Finished running node model.transform_data.transform_data
2023-06-25 01:24:32.225264 (MainThread): Using postgres connection "master".
2023-06-25 01:24:32.225773 (MainThread): On master: BEGIN
2023-06-25 01:24:32.226767 (MainThread): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:24:32.227265 (MainThread): On master: COMMIT
2023-06-25 01:24:32.227265 (MainThread): Using postgres connection "master".
2023-06-25 01:24:32.227765 (MainThread): On master: COMMIT
2023-06-25 01:24:32.228740 (MainThread): SQL status: COMMIT in 0.00 seconds
2023-06-25 01:24:32.229736 (MainThread): 21:24:32 | 
2023-06-25 01:24:32.230736 (MainThread): 21:24:32 | Finished running 1 view model in 0.28s.
2023-06-25 01:24:32.231727 (MainThread): Connection 'master' was left open.
2023-06-25 01:24:32.232271 (MainThread): On master: Close
2023-06-25 01:24:32.232772 (MainThread): Connection 'list_main_database' was left open.
2023-06-25 01:24:32.233276 (MainThread): On list_main_database: Close
2023-06-25 01:24:32.234265 (MainThread): Connection 'list_main_database_public' was left open.
2023-06-25 01:24:32.234265 (MainThread): On list_main_database_public: Close
2023-06-25 01:24:32.235232 (MainThread): Connection 'model.transform_data.transform_data' was left open.
2023-06-25 01:24:32.235232 (MainThread): On model.transform_data.transform_data: Close
2023-06-25 01:24:32.242242 (MainThread): 
2023-06-25 01:24:32.242588 (MainThread): Completed with 1 error and 0 warnings:
2023-06-25 01:24:32.242588 (MainThread): 
2023-06-25 01:24:32.243092 (MainThread): Database Error in model transform_data (models\transformations\transform_data.sql)
2023-06-25 01:24:32.243092 (MainThread):   syntax error at or near "CREATE"
2023-06-25 01:24:32.243592 (MainThread):   LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
2023-06-25 01:24:32.243592 (MainThread):           ^
2023-06-25 01:24:32.243592 (MainThread):   compiled SQL at target\run\transform_data\transformations\transform_data.sql
2023-06-25 01:24:32.244092 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2023-06-25 01:24:32.244092 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002095A8EF2E8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002093256E940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002095A8F39B0>]}
2023-06-25 01:24:32.244592 (MainThread): Flushing usage events
2023-06-25 01:25:33.369744 (MainThread): Running with dbt=0.16.0
2023-06-25 01:25:33.408244 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='C:\\Users\\Me\\.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2023-06-25 01:25:33.408744 (MainThread): Tracking: tracking
2023-06-25 01:25:33.409244 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EEBF72E358>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EEBF72ED30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EEBF720278>]}
2023-06-25 01:25:33.420744 (MainThread): Partial parsing not enabled
2023-06-25 01:25:33.423244 (MainThread): Parsing macros\core.sql
2023-06-25 01:25:33.426744 (MainThread): Parsing macros\adapters\common.sql
2023-06-25 01:25:33.458744 (MainThread): Parsing macros\etc\datetime.sql
2023-06-25 01:25:33.465244 (MainThread): Parsing macros\etc\get_custom_alias.sql
2023-06-25 01:25:33.466244 (MainThread): Parsing macros\etc\get_custom_database.sql
2023-06-25 01:25:33.467244 (MainThread): Parsing macros\etc\get_custom_schema.sql
2023-06-25 01:25:33.468744 (MainThread): Parsing macros\etc\get_relation_comment.sql
2023-06-25 01:25:33.470244 (MainThread): Parsing macros\etc\is_incremental.sql
2023-06-25 01:25:33.471744 (MainThread): Parsing macros\etc\query.sql
2023-06-25 01:25:33.472744 (MainThread): Parsing macros\materializations\helpers.sql
2023-06-25 01:25:33.478244 (MainThread): Parsing macros\materializations\common\merge.sql
2023-06-25 01:25:33.488244 (MainThread): Parsing macros\materializations\incremental\helpers.sql
2023-06-25 01:25:33.489744 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2023-06-25 01:25:33.494244 (MainThread): Parsing macros\materializations\seed\seed.sql
2023-06-25 01:25:33.509743 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2023-06-25 01:25:33.534743 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2023-06-25 01:25:33.536244 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2023-06-25 01:25:33.548743 (MainThread): Parsing macros\materializations\table\table.sql
2023-06-25 01:25:33.554244 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2023-06-25 01:25:33.557743 (MainThread): Parsing macros\materializations\view\view.sql
2023-06-25 01:25:33.562244 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2023-06-25 01:25:33.564244 (MainThread): Parsing macros\schema_tests\not_null.sql
2023-06-25 01:25:33.564744 (MainThread): Parsing macros\schema_tests\relationships.sql
2023-06-25 01:25:33.565744 (MainThread): Parsing macros\schema_tests\unique.sql
2023-06-25 01:25:33.566744 (MainThread): Parsing macros\adapters.sql
2023-06-25 01:25:33.580744 (MainThread): Parsing macros\catalog.sql
2023-06-25 01:25:33.582744 (MainThread): Parsing macros\relations.sql
2023-06-25 01:25:33.583744 (MainThread): Parsing macros\materializations\snapshot_merge.sql
2023-06-25 01:25:33.596744 (MainThread): Partial parsing not enabled
2023-06-25 01:25:33.615744 (MainThread): Acquiring new postgres connection "model.transform_data.transform_data".
2023-06-25 01:25:33.615744 (MainThread): Opening a new connection, currently in state init
2023-06-25 01:25:33.835244 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:25:33.835244 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:25:33.835244 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:25:33.835744 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:25:33.835744 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:25:33.835744 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:25:33.835744 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:25:33.867244 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:25:33.867244 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:25:33.988246 (MainThread): scipy not found, skipping conversion test.
2023-06-25 01:25:33.989246 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2023-06-25 01:25:33.989744 (MainThread): Found 1 model, 0 tests, 0 snapshots, 0 analyses, 127 macros, 0 operations, 0 seed files, 0 sources
2023-06-25 01:25:33.990244 (MainThread): 
2023-06-25 01:25:33.990745 (MainThread): Acquiring new postgres connection "master".
2023-06-25 01:25:33.990745 (MainThread): Opening a new connection, currently in state init
2023-06-25 01:25:33.994297 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_main_database".
2023-06-25 01:25:33.994801 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2023-06-25 01:25:34.050300 (ThreadPoolExecutor-0_0): Using postgres connection "list_main_database".
2023-06-25 01:25:34.050300 (ThreadPoolExecutor-0_0): On list_main_database: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "list_main_database"} */

    select distinct nspname from pg_namespace
  
2023-06-25 01:25:34.081301 (ThreadPoolExecutor-0_0): SQL status: SELECT 4 in 0.03 seconds
2023-06-25 01:25:34.086337 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_main_database_public".
2023-06-25 01:25:34.086337 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2023-06-25 01:25:34.087334 (ThreadPoolExecutor-1_0): Using postgres connection "list_main_database_public".
2023-06-25 01:25:34.087334 (ThreadPoolExecutor-1_0): On list_main_database_public: BEGIN
2023-06-25 01:25:34.116300 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.03 seconds
2023-06-25 01:25:34.116300 (ThreadPoolExecutor-1_0): Using postgres connection "list_main_database_public".
2023-06-25 01:25:34.116300 (ThreadPoolExecutor-1_0): On list_main_database_public: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "list_main_database_public"} */
select
      'main_database' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'main_database' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2023-06-25 01:25:34.119300 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2023-06-25 01:25:34.120300 (ThreadPoolExecutor-1_0): On list_main_database_public: ROLLBACK
2023-06-25 01:25:34.125800 (MainThread): Using postgres connection "master".
2023-06-25 01:25:34.125800 (MainThread): On master: BEGIN
2023-06-25 01:25:34.155342 (MainThread): SQL status: BEGIN in 0.03 seconds
2023-06-25 01:25:34.155342 (MainThread): Using postgres connection "master".
2023-06-25 01:25:34.155342 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2023-06-25 01:25:34.158832 (MainThread): SQL status: SELECT 0 in 0.00 seconds
2023-06-25 01:25:34.159330 (MainThread): On master: ROLLBACK
2023-06-25 01:25:34.159330 (MainThread): Using postgres connection "master".
2023-06-25 01:25:34.159832 (MainThread): On master: BEGIN
2023-06-25 01:25:34.159832 (MainThread): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:25:34.159832 (MainThread): On master: COMMIT
2023-06-25 01:25:34.160330 (MainThread): Using postgres connection "master".
2023-06-25 01:25:34.160330 (MainThread): On master: COMMIT
2023-06-25 01:25:34.160330 (MainThread): SQL status: COMMIT in 0.00 seconds
2023-06-25 01:25:34.160330 (MainThread): 21:25:34 | Concurrency: 1 threads (target='dev')
2023-06-25 01:25:34.160830 (MainThread): 21:25:34 | 
2023-06-25 01:25:34.162830 (Thread-1): Began running node model.transform_data.transform_data
2023-06-25 01:25:34.162830 (Thread-1): 21:25:34 | 1 of 1 START view model public.transform_data........................ [RUN]
2023-06-25 01:25:34.163330 (Thread-1): Acquiring new postgres connection "model.transform_data.transform_data".
2023-06-25 01:25:34.163330 (Thread-1): Opening a new connection, currently in state init
2023-06-25 01:25:34.163330 (Thread-1): Compiling model.transform_data.transform_data
2023-06-25 01:25:34.172830 (Thread-1): Writing injected SQL for node "model.transform_data.transform_data"
2023-06-25 01:25:34.173319 (Thread-1): finished collecting timing info
2023-06-25 01:25:34.193300 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:25:34.193300 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */
drop view if exists "main_database"."public"."transform_data__dbt_tmp" cascade
2023-06-25 01:25:34.223835 (Thread-1): SQL status: DROP VIEW in 0.03 seconds
2023-06-25 01:25:34.225330 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:25:34.225833 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */
drop view if exists "main_database"."public"."transform_data__dbt_backup" cascade
2023-06-25 01:25:34.225833 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2023-06-25 01:25:34.226830 (Thread-1): Writing runtime SQL for node "model.transform_data.transform_data"
2023-06-25 01:25:34.227303 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:25:34.227303 (Thread-1): On model.transform_data.transform_data: BEGIN
2023-06-25 01:25:34.227801 (Thread-1): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:25:34.227801 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:25:34.227801 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */

  create view "main_database"."public"."transform_data__dbt_tmp" as (
    -- Create a temporary table to hold the filtered and transformed data
CREATE TEMPORARY TABLE temp_transactions AS
SELECT
  "address",
  "amount",
  "timestamp"
FROM
  public.transactions
WHERE
  "timestamp" > CURRENT_TIMESTAMP - INTERVAL '2 years';

-- Clear existing data from the target table
TRUNCATE TABLE public.transactions;

-- Insert the data from the temporary table into the target table
INSERT INTO public.transactions ("address", "amount", "timestamp")
SELECT
  "address",
  "amount",
  "timestamp"
FROM
  temp_transactions;
  );

2023-06-25 01:25:34.227801 (Thread-1): Postgres error: syntax error at or near "CREATE"
LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
        ^

2023-06-25 01:25:34.228301 (Thread-1): On model.transform_data.transform_data: ROLLBACK
2023-06-25 01:25:34.228301 (Thread-1): finished collecting timing info
2023-06-25 01:25:34.228301 (Thread-1): Database Error in model transform_data (models\transformations\transform_data.sql)
  syntax error at or near "CREATE"
  LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
          ^
  compiled SQL at target\run\transform_data\transformations\transform_data.sql
Traceback (most recent call last):
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\postgres\connections.py", line 46, in exception_handler
    yield
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near "CREATE"
LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
        ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 223, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 166, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 268, in run
    return self.execute(compiled_node, manifest)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 450, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 60, in macro
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\base\impl.py", line 220, in execute
    fetch=fetch
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 116, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 82, in add_query
    return connection, cursor
  File "c:\users\me\appdata\local\programs\python\python37\lib\contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\postgres\connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model transform_data (models\transformations\transform_data.sql)
  syntax error at or near "CREATE"
  LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
          ^
  compiled SQL at target\run\transform_data\transformations\transform_data.sql
2023-06-25 01:25:34.230300 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6ded4d82-dab6-4d24-b778-3cd50552b056', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EEE7D98438>]}
2023-06-25 01:25:34.230300 (Thread-1): 21:25:34 | 1 of 1 ERROR creating view model public.transform_data............... [ERROR in 0.07s]
2023-06-25 01:25:34.230800 (Thread-1): Finished running node model.transform_data.transform_data
2023-06-25 01:25:34.263143 (MainThread): Using postgres connection "master".
2023-06-25 01:25:34.263143 (MainThread): On master: BEGIN
2023-06-25 01:25:34.263143 (MainThread): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:25:34.263533 (MainThread): On master: COMMIT
2023-06-25 01:25:34.263533 (MainThread): Using postgres connection "master".
2023-06-25 01:25:34.263533 (MainThread): On master: COMMIT
2023-06-25 01:25:34.263533 (MainThread): SQL status: COMMIT in 0.00 seconds
2023-06-25 01:25:34.264032 (MainThread): 21:25:34 | 
2023-06-25 01:25:34.264032 (MainThread): 21:25:34 | Finished running 1 view model in 0.27s.
2023-06-25 01:25:34.264533 (MainThread): Connection 'master' was left open.
2023-06-25 01:25:34.264533 (MainThread): On master: Close
2023-06-25 01:25:34.264533 (MainThread): Connection 'list_main_database' was left open.
2023-06-25 01:25:34.264533 (MainThread): On list_main_database: Close
2023-06-25 01:25:34.264533 (MainThread): Connection 'list_main_database_public' was left open.
2023-06-25 01:25:34.264533 (MainThread): On list_main_database_public: Close
2023-06-25 01:25:34.265032 (MainThread): Connection 'model.transform_data.transform_data' was left open.
2023-06-25 01:25:34.265032 (MainThread): On model.transform_data.transform_data: Close
2023-06-25 01:25:34.267033 (MainThread): 
2023-06-25 01:25:34.267534 (MainThread): Completed with 1 error and 0 warnings:
2023-06-25 01:25:34.268033 (MainThread): 
2023-06-25 01:25:34.268033 (MainThread): Database Error in model transform_data (models\transformations\transform_data.sql)
2023-06-25 01:25:34.268533 (MainThread):   syntax error at or near "CREATE"
2023-06-25 01:25:34.268533 (MainThread):   LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
2023-06-25 01:25:34.268533 (MainThread):           ^
2023-06-25 01:25:34.269033 (MainThread):   compiled SQL at target\run\transform_data\transformations\transform_data.sql
2023-06-25 01:25:34.269033 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2023-06-25 01:25:34.269033 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EEE7D4A780>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EEBF86ED68>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EEE7D98438>]}
2023-06-25 01:25:34.269532 (MainThread): Flushing usage events
2023-06-25 01:25:36.663182 (MainThread): Running with dbt=0.16.0
2023-06-25 01:25:36.700181 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='C:\\Users\\Me\\.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target='dev', test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2023-06-25 01:25:36.700682 (MainThread): Tracking: tracking
2023-06-25 01:25:36.701682 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A2742F9198>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A2742F97B8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A274309C18>]}
2023-06-25 01:25:36.713182 (MainThread): Partial parsing not enabled
2023-06-25 01:25:36.715682 (MainThread): Parsing macros\core.sql
2023-06-25 01:25:36.719182 (MainThread): Parsing macros\adapters\common.sql
2023-06-25 01:25:36.750682 (MainThread): Parsing macros\etc\datetime.sql
2023-06-25 01:25:36.757682 (MainThread): Parsing macros\etc\get_custom_alias.sql
2023-06-25 01:25:36.758182 (MainThread): Parsing macros\etc\get_custom_database.sql
2023-06-25 01:25:36.759182 (MainThread): Parsing macros\etc\get_custom_schema.sql
2023-06-25 01:25:36.760682 (MainThread): Parsing macros\etc\get_relation_comment.sql
2023-06-25 01:25:36.762682 (MainThread): Parsing macros\etc\is_incremental.sql
2023-06-25 01:25:36.763682 (MainThread): Parsing macros\etc\query.sql
2023-06-25 01:25:36.764682 (MainThread): Parsing macros\materializations\helpers.sql
2023-06-25 01:25:36.770682 (MainThread): Parsing macros\materializations\common\merge.sql
2023-06-25 01:25:36.780181 (MainThread): Parsing macros\materializations\incremental\helpers.sql
2023-06-25 01:25:36.781681 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2023-06-25 01:25:36.786182 (MainThread): Parsing macros\materializations\seed\seed.sql
2023-06-25 01:25:36.802182 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2023-06-25 01:25:36.827181 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2023-06-25 01:25:36.828682 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2023-06-25 01:25:36.841181 (MainThread): Parsing macros\materializations\table\table.sql
2023-06-25 01:25:36.846181 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2023-06-25 01:25:36.849681 (MainThread): Parsing macros\materializations\view\view.sql
2023-06-25 01:25:36.854681 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2023-06-25 01:25:36.856181 (MainThread): Parsing macros\schema_tests\not_null.sql
2023-06-25 01:25:36.857182 (MainThread): Parsing macros\schema_tests\relationships.sql
2023-06-25 01:25:36.857682 (MainThread): Parsing macros\schema_tests\unique.sql
2023-06-25 01:25:36.859182 (MainThread): Parsing macros\adapters.sql
2023-06-25 01:25:36.872182 (MainThread): Parsing macros\catalog.sql
2023-06-25 01:25:36.873682 (MainThread): Parsing macros\relations.sql
2023-06-25 01:25:36.875182 (MainThread): Parsing macros\materializations\snapshot_merge.sql
2023-06-25 01:25:36.887682 (MainThread): Partial parsing not enabled
2023-06-25 01:25:36.906682 (MainThread): Acquiring new postgres connection "model.transform_data.transform_data".
2023-06-25 01:25:36.906682 (MainThread): Opening a new connection, currently in state init
2023-06-25 01:25:37.124682 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:25:37.124682 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:25:37.124682 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:25:37.124682 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:25:37.125182 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:25:37.125182 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:25:37.125182 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:25:37.156182 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:25:37.156182 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:25:37.275682 (MainThread): scipy not found, skipping conversion test.
2023-06-25 01:25:37.276682 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2023-06-25 01:25:37.277182 (MainThread): Found 1 model, 0 tests, 0 snapshots, 0 analyses, 127 macros, 0 operations, 0 seed files, 0 sources
2023-06-25 01:25:37.277682 (MainThread): 
2023-06-25 01:25:37.278182 (MainThread): Acquiring new postgres connection "master".
2023-06-25 01:25:37.278182 (MainThread): Opening a new connection, currently in state init
2023-06-25 01:25:37.281682 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_main_database".
2023-06-25 01:25:37.282182 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2023-06-25 01:25:37.337214 (ThreadPoolExecutor-0_0): Using postgres connection "list_main_database".
2023-06-25 01:25:37.337214 (ThreadPoolExecutor-0_0): On list_main_database: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "list_main_database"} */

    select distinct nspname from pg_namespace
  
2023-06-25 01:25:37.367731 (ThreadPoolExecutor-0_0): SQL status: SELECT 4 in 0.03 seconds
2023-06-25 01:25:37.373302 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_main_database_public".
2023-06-25 01:25:37.373302 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2023-06-25 01:25:37.374305 (ThreadPoolExecutor-1_0): Using postgres connection "list_main_database_public".
2023-06-25 01:25:37.374305 (ThreadPoolExecutor-1_0): On list_main_database_public: BEGIN
2023-06-25 01:25:37.403306 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.03 seconds
2023-06-25 01:25:37.403306 (ThreadPoolExecutor-1_0): Using postgres connection "list_main_database_public".
2023-06-25 01:25:37.403806 (ThreadPoolExecutor-1_0): On list_main_database_public: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "list_main_database_public"} */
select
      'main_database' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'main_database' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2023-06-25 01:25:37.406340 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2023-06-25 01:25:37.407305 (ThreadPoolExecutor-1_0): On list_main_database_public: ROLLBACK
2023-06-25 01:25:37.412855 (MainThread): Using postgres connection "master".
2023-06-25 01:25:37.413335 (MainThread): On master: BEGIN
2023-06-25 01:25:37.441836 (MainThread): SQL status: BEGIN in 0.03 seconds
2023-06-25 01:25:37.442306 (MainThread): Using postgres connection "master".
2023-06-25 01:25:37.442306 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2023-06-25 01:25:37.445836 (MainThread): SQL status: SELECT 0 in 0.00 seconds
2023-06-25 01:25:37.446335 (MainThread): On master: ROLLBACK
2023-06-25 01:25:37.446335 (MainThread): Using postgres connection "master".
2023-06-25 01:25:37.446806 (MainThread): On master: BEGIN
2023-06-25 01:25:37.446806 (MainThread): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:25:37.446806 (MainThread): On master: COMMIT
2023-06-25 01:25:37.447306 (MainThread): Using postgres connection "master".
2023-06-25 01:25:37.447306 (MainThread): On master: COMMIT
2023-06-25 01:25:37.447306 (MainThread): SQL status: COMMIT in 0.00 seconds
2023-06-25 01:25:37.447306 (MainThread): 21:25:37 | Concurrency: 1 threads (target='dev')
2023-06-25 01:25:37.447837 (MainThread): 21:25:37 | 
2023-06-25 01:25:37.449304 (Thread-1): Began running node model.transform_data.transform_data
2023-06-25 01:25:37.449804 (Thread-1): 21:25:37 | 1 of 1 START view model public.transform_data........................ [RUN]
2023-06-25 01:25:37.449804 (Thread-1): Acquiring new postgres connection "model.transform_data.transform_data".
2023-06-25 01:25:37.449804 (Thread-1): Opening a new connection, currently in state init
2023-06-25 01:25:37.450305 (Thread-1): Compiling model.transform_data.transform_data
2023-06-25 01:25:37.459305 (Thread-1): Writing injected SQL for node "model.transform_data.transform_data"
2023-06-25 01:25:37.459805 (Thread-1): finished collecting timing info
2023-06-25 01:25:37.480305 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:25:37.480305 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */
drop view if exists "main_database"."public"."transform_data__dbt_tmp" cascade
2023-06-25 01:25:37.509830 (Thread-1): SQL status: DROP VIEW in 0.03 seconds
2023-06-25 01:25:37.511365 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:25:37.511862 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */
drop view if exists "main_database"."public"."transform_data__dbt_backup" cascade
2023-06-25 01:25:37.511862 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2023-06-25 01:25:37.512865 (Thread-1): Writing runtime SQL for node "model.transform_data.transform_data"
2023-06-25 01:25:37.513359 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:25:37.513359 (Thread-1): On model.transform_data.transform_data: BEGIN
2023-06-25 01:25:37.513833 (Thread-1): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:25:37.513833 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:25:37.513833 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */

  create view "main_database"."public"."transform_data__dbt_tmp" as (
    -- Create a temporary table to hold the filtered and transformed data
CREATE TEMPORARY TABLE temp_transactions AS
SELECT
  "address",
  "amount",
  "timestamp"
FROM
  public.transactions
WHERE
  "timestamp" > CURRENT_TIMESTAMP - INTERVAL '2 years';

-- Clear existing data from the target table
TRUNCATE TABLE public.transactions;

-- Insert the data from the temporary table into the target table
INSERT INTO public.transactions ("address", "amount", "timestamp")
SELECT
  "address",
  "amount",
  "timestamp"
FROM
  temp_transactions;
  );

2023-06-25 01:25:37.514335 (Thread-1): Postgres error: syntax error at or near "CREATE"
LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
        ^

2023-06-25 01:25:37.514335 (Thread-1): On model.transform_data.transform_data: ROLLBACK
2023-06-25 01:25:37.514335 (Thread-1): finished collecting timing info
2023-06-25 01:25:37.514834 (Thread-1): Database Error in model transform_data (models\transformations\transform_data.sql)
  syntax error at or near "CREATE"
  LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
          ^
  compiled SQL at target\run\transform_data\transformations\transform_data.sql
Traceback (most recent call last):
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\postgres\connections.py", line 46, in exception_handler
    yield
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near "CREATE"
LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
        ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 223, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 166, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 268, in run
    return self.execute(compiled_node, manifest)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 450, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 60, in macro
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\base\impl.py", line 220, in execute
    fetch=fetch
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 116, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 82, in add_query
    return connection, cursor
  File "c:\users\me\appdata\local\programs\python\python37\lib\contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\postgres\connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model transform_data (models\transformations\transform_data.sql)
  syntax error at or near "CREATE"
  LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
          ^
  compiled SQL at target\run\transform_data\transformations\transform_data.sql
2023-06-25 01:25:37.516333 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a9aa8b8-f8a7-402b-b1fd-90b4deeb4e3c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A21C9297F0>]}
2023-06-25 01:25:37.516333 (Thread-1): 21:25:37 | 1 of 1 ERROR creating view model public.transform_data............... [ERROR in 0.07s]
2023-06-25 01:25:37.517333 (Thread-1): Finished running node model.transform_data.transform_data
2023-06-25 01:25:37.564837 (MainThread): Using postgres connection "master".
2023-06-25 01:25:37.564837 (MainThread): On master: BEGIN
2023-06-25 01:25:37.564837 (MainThread): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:25:37.565339 (MainThread): On master: COMMIT
2023-06-25 01:25:37.565339 (MainThread): Using postgres connection "master".
2023-06-25 01:25:37.565339 (MainThread): On master: COMMIT
2023-06-25 01:25:37.565339 (MainThread): SQL status: COMMIT in 0.00 seconds
2023-06-25 01:25:37.565836 (MainThread): 21:25:37 | 
2023-06-25 01:25:37.565836 (MainThread): 21:25:37 | Finished running 1 view model in 0.29s.
2023-06-25 01:25:37.566336 (MainThread): Connection 'master' was left open.
2023-06-25 01:25:37.566336 (MainThread): On master: Close
2023-06-25 01:25:37.566336 (MainThread): Connection 'list_main_database' was left open.
2023-06-25 01:25:37.566336 (MainThread): On list_main_database: Close
2023-06-25 01:25:37.566336 (MainThread): Connection 'list_main_database_public' was left open.
2023-06-25 01:25:37.566835 (MainThread): On list_main_database_public: Close
2023-06-25 01:25:37.566835 (MainThread): Connection 'model.transform_data.transform_data' was left open.
2023-06-25 01:25:37.566835 (MainThread): On model.transform_data.transform_data: Close
2023-06-25 01:25:37.569337 (MainThread): 
2023-06-25 01:25:37.569337 (MainThread): Completed with 1 error and 0 warnings:
2023-06-25 01:25:37.569836 (MainThread): 
2023-06-25 01:25:37.569836 (MainThread): Database Error in model transform_data (models\transformations\transform_data.sql)
2023-06-25 01:25:37.570336 (MainThread):   syntax error at or near "CREATE"
2023-06-25 01:25:37.570336 (MainThread):   LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
2023-06-25 01:25:37.570336 (MainThread):           ^
2023-06-25 01:25:37.570336 (MainThread):   compiled SQL at target\run\transform_data\transformations\transform_data.sql
2023-06-25 01:25:37.570836 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2023-06-25 01:25:37.570836 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A27F885B00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A21C89E0F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002A21C8ECD30>]}
2023-06-25 01:25:37.571337 (MainThread): Flushing usage events
2023-06-25 01:25:54.705445 (MainThread): Running with dbt=0.16.0
2023-06-25 01:25:54.742445 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='C:\\Users\\Me\\.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target='dev', test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2023-06-25 01:25:54.742945 (MainThread): Tracking: tracking
2023-06-25 01:25:54.743445 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002788031FF60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002788031F860>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002788031F240>]}
2023-06-25 01:25:54.754945 (MainThread): Partial parsing not enabled
2023-06-25 01:25:54.757445 (MainThread): Parsing macros\core.sql
2023-06-25 01:25:54.760945 (MainThread): Parsing macros\adapters\common.sql
2023-06-25 01:25:54.791945 (MainThread): Parsing macros\etc\datetime.sql
2023-06-25 01:25:54.798445 (MainThread): Parsing macros\etc\get_custom_alias.sql
2023-06-25 01:25:54.799445 (MainThread): Parsing macros\etc\get_custom_database.sql
2023-06-25 01:25:54.799945 (MainThread): Parsing macros\etc\get_custom_schema.sql
2023-06-25 01:25:54.801445 (MainThread): Parsing macros\etc\get_relation_comment.sql
2023-06-25 01:25:54.803445 (MainThread): Parsing macros\etc\is_incremental.sql
2023-06-25 01:25:54.804445 (MainThread): Parsing macros\etc\query.sql
2023-06-25 01:25:54.805445 (MainThread): Parsing macros\materializations\helpers.sql
2023-06-25 01:25:54.811445 (MainThread): Parsing macros\materializations\common\merge.sql
2023-06-25 01:25:54.820945 (MainThread): Parsing macros\materializations\incremental\helpers.sql
2023-06-25 01:25:54.821945 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2023-06-25 01:25:54.826945 (MainThread): Parsing macros\materializations\seed\seed.sql
2023-06-25 01:25:54.842445 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2023-06-25 01:25:54.866945 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2023-06-25 01:25:54.867946 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2023-06-25 01:25:54.880445 (MainThread): Parsing macros\materializations\table\table.sql
2023-06-25 01:25:54.885445 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2023-06-25 01:25:54.889445 (MainThread): Parsing macros\materializations\view\view.sql
2023-06-25 01:25:54.893945 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2023-06-25 01:25:54.895445 (MainThread): Parsing macros\schema_tests\not_null.sql
2023-06-25 01:25:54.895945 (MainThread): Parsing macros\schema_tests\relationships.sql
2023-06-25 01:25:54.896945 (MainThread): Parsing macros\schema_tests\unique.sql
2023-06-25 01:25:54.898445 (MainThread): Parsing macros\adapters.sql
2023-06-25 01:25:54.910945 (MainThread): Parsing macros\catalog.sql
2023-06-25 01:25:54.912945 (MainThread): Parsing macros\relations.sql
2023-06-25 01:25:54.913945 (MainThread): Parsing macros\materializations\snapshot_merge.sql
2023-06-25 01:25:54.926445 (MainThread): Partial parsing not enabled
2023-06-25 01:25:54.944945 (MainThread): Acquiring new postgres connection "model.transform_data.transform_data".
2023-06-25 01:25:54.944945 (MainThread): Opening a new connection, currently in state init
2023-06-25 01:25:55.159945 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:25:55.159945 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:25:55.159945 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:25:55.159945 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:25:55.160445 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:25:55.160445 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:25:55.160445 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:25:55.190945 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:25:55.190945 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:25:55.309445 (MainThread): scipy not found, skipping conversion test.
2023-06-25 01:25:55.310445 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2023-06-25 01:25:55.310946 (MainThread): Found 1 model, 0 tests, 0 snapshots, 0 analyses, 127 macros, 0 operations, 0 seed files, 0 sources
2023-06-25 01:25:55.311445 (MainThread): 
2023-06-25 01:25:55.311945 (MainThread): Acquiring new postgres connection "master".
2023-06-25 01:25:55.311945 (MainThread): Opening a new connection, currently in state init
2023-06-25 01:25:55.315448 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_main_database".
2023-06-25 01:25:55.315448 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2023-06-25 01:25:55.370948 (ThreadPoolExecutor-0_0): Using postgres connection "list_main_database".
2023-06-25 01:25:55.370948 (ThreadPoolExecutor-0_0): On list_main_database: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "list_main_database"} */

    select distinct nspname from pg_namespace
  
2023-06-25 01:25:55.401640 (ThreadPoolExecutor-0_0): SQL status: SELECT 4 in 0.03 seconds
2023-06-25 01:25:55.407140 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_main_database_public".
2023-06-25 01:25:55.407140 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2023-06-25 01:25:55.408139 (ThreadPoolExecutor-1_0): Using postgres connection "list_main_database_public".
2023-06-25 01:25:55.408139 (ThreadPoolExecutor-1_0): On list_main_database_public: BEGIN
2023-06-25 01:25:55.436448 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.03 seconds
2023-06-25 01:25:55.436448 (ThreadPoolExecutor-1_0): Using postgres connection "list_main_database_public".
2023-06-25 01:25:55.436448 (ThreadPoolExecutor-1_0): On list_main_database_public: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "list_main_database_public"} */
select
      'main_database' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'main_database' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2023-06-25 01:25:55.439476 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2023-06-25 01:25:55.440447 (ThreadPoolExecutor-1_0): On list_main_database_public: ROLLBACK
2023-06-25 01:25:55.446348 (MainThread): Using postgres connection "master".
2023-06-25 01:25:55.446348 (MainThread): On master: BEGIN
2023-06-25 01:25:55.478347 (MainThread): SQL status: BEGIN in 0.03 seconds
2023-06-25 01:25:55.478347 (MainThread): Using postgres connection "master".
2023-06-25 01:25:55.478347 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2023-06-25 01:25:55.481848 (MainThread): SQL status: SELECT 0 in 0.00 seconds
2023-06-25 01:25:55.482847 (MainThread): On master: ROLLBACK
2023-06-25 01:25:55.482847 (MainThread): Using postgres connection "master".
2023-06-25 01:25:55.482847 (MainThread): On master: BEGIN
2023-06-25 01:25:55.483347 (MainThread): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:25:55.483347 (MainThread): On master: COMMIT
2023-06-25 01:25:55.483347 (MainThread): Using postgres connection "master".
2023-06-25 01:25:55.483347 (MainThread): On master: COMMIT
2023-06-25 01:25:55.483347 (MainThread): SQL status: COMMIT in 0.00 seconds
2023-06-25 01:25:55.483848 (MainThread): 21:25:55 | Concurrency: 1 threads (target='dev')
2023-06-25 01:25:55.483848 (MainThread): 21:25:55 | 
2023-06-25 01:25:55.485847 (Thread-1): Began running node model.transform_data.transform_data
2023-06-25 01:25:55.485847 (Thread-1): 21:25:55 | 1 of 1 START view model public.transform_data........................ [RUN]
2023-06-25 01:25:55.485847 (Thread-1): Acquiring new postgres connection "model.transform_data.transform_data".
2023-06-25 01:25:55.486346 (Thread-1): Opening a new connection, currently in state init
2023-06-25 01:25:55.486346 (Thread-1): Compiling model.transform_data.transform_data
2023-06-25 01:25:55.495846 (Thread-1): Writing injected SQL for node "model.transform_data.transform_data"
2023-06-25 01:25:55.496347 (Thread-1): finished collecting timing info
2023-06-25 01:25:55.516346 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:25:55.516847 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */
drop view if exists "main_database"."public"."transform_data__dbt_tmp" cascade
2023-06-25 01:25:55.545156 (Thread-1): SQL status: DROP VIEW in 0.03 seconds
2023-06-25 01:25:55.546656 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:25:55.546656 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */
drop view if exists "main_database"."public"."transform_data__dbt_backup" cascade
2023-06-25 01:25:55.546656 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2023-06-25 01:25:55.547656 (Thread-1): Writing runtime SQL for node "model.transform_data.transform_data"
2023-06-25 01:25:55.548156 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:25:55.548156 (Thread-1): On model.transform_data.transform_data: BEGIN
2023-06-25 01:25:55.548656 (Thread-1): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:25:55.548656 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:25:55.548656 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */

  create view "main_database"."public"."transform_data__dbt_tmp" as (
    -- Create a temporary table to hold the filtered and transformed data
CREATE TEMPORARY TABLE temp_transactions AS
SELECT
  "address",
  "amount",
  "timestamp"
FROM
  public.transactions
WHERE
  "timestamp" > CURRENT_TIMESTAMP - INTERVAL '2 years';

-- Clear existing data from the target table
TRUNCATE TABLE public.transactions;

-- Insert the data from the temporary table into the target table
INSERT INTO public.transactions ("address", "amount", "timestamp")
SELECT
  "address",
  "amount",
  "timestamp"
FROM
  temp_transactions;
  );

2023-06-25 01:25:55.549197 (Thread-1): Postgres error: syntax error at or near "CREATE"
LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
        ^

2023-06-25 01:25:55.549197 (Thread-1): On model.transform_data.transform_data: ROLLBACK
2023-06-25 01:25:55.549197 (Thread-1): finished collecting timing info
2023-06-25 01:25:55.549657 (Thread-1): Database Error in model transform_data (models\transformations\transform_data.sql)
  syntax error at or near "CREATE"
  LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
          ^
  compiled SQL at target\run\transform_data\transformations\transform_data.sql
Traceback (most recent call last):
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\postgres\connections.py", line 46, in exception_handler
    yield
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near "CREATE"
LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
        ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 223, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 166, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 268, in run
    return self.execute(compiled_node, manifest)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 450, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 60, in macro
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\base\impl.py", line 220, in execute
    fetch=fetch
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 116, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 82, in add_query
    return connection, cursor
  File "c:\users\me\appdata\local\programs\python\python37\lib\contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\postgres\connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model transform_data (models\transformations\transform_data.sql)
  syntax error at or near "CREATE"
  LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
          ^
  compiled SQL at target\run\transform_data\transformations\transform_data.sql
2023-06-25 01:25:55.551156 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9fe36a1c-9d78-4192-9800-42da0abeb925', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000278A8A60198>]}
2023-06-25 01:25:55.551156 (Thread-1): 21:25:55 | 1 of 1 ERROR creating view model public.transform_data............... [ERROR in 0.07s]
2023-06-25 01:25:55.552156 (Thread-1): Finished running node model.transform_data.transform_data
2023-06-25 01:25:55.595080 (MainThread): Using postgres connection "master".
2023-06-25 01:25:55.595080 (MainThread): On master: BEGIN
2023-06-25 01:25:55.595591 (MainThread): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:25:55.595591 (MainThread): On master: COMMIT
2023-06-25 01:25:55.595591 (MainThread): Using postgres connection "master".
2023-06-25 01:25:55.595591 (MainThread): On master: COMMIT
2023-06-25 01:25:55.595591 (MainThread): SQL status: COMMIT in 0.00 seconds
2023-06-25 01:25:55.596079 (MainThread): 21:25:55 | 
2023-06-25 01:25:55.596079 (MainThread): 21:25:55 | Finished running 1 view model in 0.28s.
2023-06-25 01:25:55.596578 (MainThread): Connection 'master' was left open.
2023-06-25 01:25:55.596578 (MainThread): On master: Close
2023-06-25 01:25:55.596578 (MainThread): Connection 'list_main_database' was left open.
2023-06-25 01:25:55.596578 (MainThread): On list_main_database: Close
2023-06-25 01:25:55.596578 (MainThread): Connection 'list_main_database_public' was left open.
2023-06-25 01:25:55.597082 (MainThread): On list_main_database_public: Close
2023-06-25 01:25:55.597082 (MainThread): Connection 'model.transform_data.transform_data' was left open.
2023-06-25 01:25:55.597082 (MainThread): On model.transform_data.transform_data: Close
2023-06-25 01:25:55.599579 (MainThread): 
2023-06-25 01:25:55.599579 (MainThread): Completed with 1 error and 0 warnings:
2023-06-25 01:25:55.600078 (MainThread): 
2023-06-25 01:25:55.600078 (MainThread): Database Error in model transform_data (models\transformations\transform_data.sql)
2023-06-25 01:25:55.600579 (MainThread):   syntax error at or near "CREATE"
2023-06-25 01:25:55.600579 (MainThread):   LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
2023-06-25 01:25:55.601078 (MainThread):           ^
2023-06-25 01:25:55.601078 (MainThread):   compiled SQL at target\run\transform_data\transformations\transform_data.sql
2023-06-25 01:25:55.601078 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2023-06-25 01:25:55.601578 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000278A8A66710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002788054EE10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000278A8AD7CF8>]}
2023-06-25 01:25:55.601578 (MainThread): Flushing usage events
2023-06-25 01:26:05.797340 (MainThread): Running with dbt=0.16.0
2023-06-25 01:26:05.834840 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='C:\\Users\\Me\\.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target='dev', test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2023-06-25 01:26:05.835340 (MainThread): Tracking: tracking
2023-06-25 01:26:05.835840 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC57A6FF60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC57A6F860>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC57A6F240>]}
2023-06-25 01:26:05.847340 (MainThread): Partial parsing not enabled
2023-06-25 01:26:05.849840 (MainThread): Parsing macros\core.sql
2023-06-25 01:26:05.853340 (MainThread): Parsing macros\adapters\common.sql
2023-06-25 01:26:05.884340 (MainThread): Parsing macros\etc\datetime.sql
2023-06-25 01:26:05.890840 (MainThread): Parsing macros\etc\get_custom_alias.sql
2023-06-25 01:26:05.891841 (MainThread): Parsing macros\etc\get_custom_database.sql
2023-06-25 01:26:05.892840 (MainThread): Parsing macros\etc\get_custom_schema.sql
2023-06-25 01:26:05.894340 (MainThread): Parsing macros\etc\get_relation_comment.sql
2023-06-25 01:26:05.895840 (MainThread): Parsing macros\etc\is_incremental.sql
2023-06-25 01:26:05.897340 (MainThread): Parsing macros\etc\query.sql
2023-06-25 01:26:05.897840 (MainThread): Parsing macros\materializations\helpers.sql
2023-06-25 01:26:05.903840 (MainThread): Parsing macros\materializations\common\merge.sql
2023-06-25 01:26:05.913340 (MainThread): Parsing macros\materializations\incremental\helpers.sql
2023-06-25 01:26:05.914840 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2023-06-25 01:26:05.919340 (MainThread): Parsing macros\materializations\seed\seed.sql
2023-06-25 01:26:05.934840 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2023-06-25 01:26:05.959840 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2023-06-25 01:26:05.961340 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2023-06-25 01:26:05.973340 (MainThread): Parsing macros\materializations\table\table.sql
2023-06-25 01:26:05.978840 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2023-06-25 01:26:05.982340 (MainThread): Parsing macros\materializations\view\view.sql
2023-06-25 01:26:05.986840 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2023-06-25 01:26:05.988340 (MainThread): Parsing macros\schema_tests\not_null.sql
2023-06-25 01:26:05.989340 (MainThread): Parsing macros\schema_tests\relationships.sql
2023-06-25 01:26:05.990340 (MainThread): Parsing macros\schema_tests\unique.sql
2023-06-25 01:26:05.991340 (MainThread): Parsing macros\adapters.sql
2023-06-25 01:26:06.004340 (MainThread): Parsing macros\catalog.sql
2023-06-25 01:26:06.005840 (MainThread): Parsing macros\relations.sql
2023-06-25 01:26:06.006840 (MainThread): Parsing macros\materializations\snapshot_merge.sql
2023-06-25 01:26:06.019840 (MainThread): Partial parsing not enabled
2023-06-25 01:26:06.038340 (MainThread): Acquiring new postgres connection "model.transform_data.transform_data".
2023-06-25 01:26:06.038340 (MainThread): Opening a new connection, currently in state init
2023-06-25 01:26:06.248341 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:26:06.248341 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:26:06.248341 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:26:06.248341 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:26:06.248341 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:26:06.248341 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:26:06.248840 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:26:06.279341 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:26:06.279840 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:26:06.399840 (MainThread): scipy not found, skipping conversion test.
2023-06-25 01:26:06.400840 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2023-06-25 01:26:06.401340 (MainThread): Found 1 model, 0 tests, 0 snapshots, 0 analyses, 127 macros, 0 operations, 0 seed files, 0 sources
2023-06-25 01:26:06.401840 (MainThread): 
2023-06-25 01:26:06.402340 (MainThread): Acquiring new postgres connection "master".
2023-06-25 01:26:06.402340 (MainThread): Opening a new connection, currently in state init
2023-06-25 01:26:06.405841 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_main_database".
2023-06-25 01:26:06.405841 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2023-06-25 01:26:06.461341 (ThreadPoolExecutor-0_0): Using postgres connection "list_main_database".
2023-06-25 01:26:06.461341 (ThreadPoolExecutor-0_0): On list_main_database: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "list_main_database"} */

    select distinct nspname from pg_namespace
  
2023-06-25 01:26:06.490871 (ThreadPoolExecutor-0_0): SQL status: SELECT 4 in 0.03 seconds
2023-06-25 01:26:06.496373 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_main_database_public".
2023-06-25 01:26:06.496373 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2023-06-25 01:26:06.497371 (ThreadPoolExecutor-1_0): Using postgres connection "list_main_database_public".
2023-06-25 01:26:06.497371 (ThreadPoolExecutor-1_0): On list_main_database_public: BEGIN
2023-06-25 01:26:06.525841 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.03 seconds
2023-06-25 01:26:06.525841 (ThreadPoolExecutor-1_0): Using postgres connection "list_main_database_public".
2023-06-25 01:26:06.526340 (ThreadPoolExecutor-1_0): On list_main_database_public: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "list_main_database_public"} */
select
      'main_database' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'main_database' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2023-06-25 01:26:06.528840 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2023-06-25 01:26:06.529840 (ThreadPoolExecutor-1_0): On list_main_database_public: ROLLBACK
2023-06-25 01:26:06.535340 (MainThread): Using postgres connection "master".
2023-06-25 01:26:06.535840 (MainThread): On master: BEGIN
2023-06-25 01:26:06.564341 (MainThread): SQL status: BEGIN in 0.03 seconds
2023-06-25 01:26:06.564842 (MainThread): Using postgres connection "master".
2023-06-25 01:26:06.564842 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2023-06-25 01:26:06.568341 (MainThread): SQL status: SELECT 0 in 0.00 seconds
2023-06-25 01:26:06.568870 (MainThread): On master: ROLLBACK
2023-06-25 01:26:06.568870 (MainThread): Using postgres connection "master".
2023-06-25 01:26:06.568870 (MainThread): On master: BEGIN
2023-06-25 01:26:06.569342 (MainThread): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:26:06.569342 (MainThread): On master: COMMIT
2023-06-25 01:26:06.569342 (MainThread): Using postgres connection "master".
2023-06-25 01:26:06.569342 (MainThread): On master: COMMIT
2023-06-25 01:26:06.569843 (MainThread): SQL status: COMMIT in 0.00 seconds
2023-06-25 01:26:06.569843 (MainThread): 21:26:06 | Concurrency: 1 threads (target='dev')
2023-06-25 01:26:06.569843 (MainThread): 21:26:06 | 
2023-06-25 01:26:06.571871 (Thread-1): Began running node model.transform_data.transform_data
2023-06-25 01:26:06.571871 (Thread-1): 21:26:06 | 1 of 1 START view model public.transform_data........................ [RUN]
2023-06-25 01:26:06.572378 (Thread-1): Acquiring new postgres connection "model.transform_data.transform_data".
2023-06-25 01:26:06.572378 (Thread-1): Opening a new connection, currently in state init
2023-06-25 01:26:06.572378 (Thread-1): Compiling model.transform_data.transform_data
2023-06-25 01:26:06.580372 (Thread-1): Writing injected SQL for node "model.transform_data.transform_data"
2023-06-25 01:26:06.580870 (Thread-1): finished collecting timing info
2023-06-25 01:26:06.600840 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:26:06.600840 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */
drop view if exists "main_database"."public"."transform_data__dbt_tmp" cascade
2023-06-25 01:26:06.629370 (Thread-1): SQL status: DROP VIEW in 0.03 seconds
2023-06-25 01:26:06.630870 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:26:06.631371 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */
drop view if exists "main_database"."public"."transform_data__dbt_backup" cascade
2023-06-25 01:26:06.631371 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2023-06-25 01:26:06.632370 (Thread-1): Writing runtime SQL for node "model.transform_data.transform_data"
2023-06-25 01:26:06.632875 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:26:06.632875 (Thread-1): On model.transform_data.transform_data: BEGIN
2023-06-25 01:26:06.633328 (Thread-1): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:26:06.633328 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:26:06.633328 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */

  create view "main_database"."public"."transform_data__dbt_tmp" as (
    -- Create a temporary table to hold the filtered and transformed data
CREATE TEMPORARY TABLE temp_transactions AS
SELECT
  "address",
  "amount",
  "timestamp"
FROM
  public.transactions
WHERE
  "timestamp" > CURRENT_TIMESTAMP - INTERVAL '2 years';

-- Clear existing data from the target table
TRUNCATE TABLE public.transactions;

-- Insert the data from the temporary table into the target table
INSERT INTO public.transactions ("address", "amount", "timestamp")
SELECT
  "address",
  "amount",
  "timestamp"
FROM
  temp_transactions;
  );

2023-06-25 01:26:06.633832 (Thread-1): Postgres error: syntax error at or near "CREATE"
LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
        ^

2023-06-25 01:26:06.633832 (Thread-1): On model.transform_data.transform_data: ROLLBACK
2023-06-25 01:26:06.633832 (Thread-1): finished collecting timing info
2023-06-25 01:26:06.634362 (Thread-1): Database Error in model transform_data (models\transformations\transform_data.sql)
  syntax error at or near "CREATE"
  LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
          ^
  compiled SQL at target\run\transform_data\transformations\transform_data.sql
Traceback (most recent call last):
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\postgres\connections.py", line 46, in exception_handler
    yield
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near "CREATE"
LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
        ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 223, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 166, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 268, in run
    return self.execute(compiled_node, manifest)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 450, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 60, in macro
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\base\impl.py", line 220, in execute
    fetch=fetch
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 116, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 82, in add_query
    return connection, cursor
  File "c:\users\me\appdata\local\programs\python\python37\lib\contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\postgres\connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model transform_data (models\transformations\transform_data.sql)
  syntax error at or near "CREATE"
  LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
          ^
  compiled SQL at target\run\transform_data\transformations\transform_data.sql
2023-06-25 01:26:06.635833 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '943e3c9e-6f3e-4ef0-b80a-3b0d7d6f09c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC000AC940>]}
2023-06-25 01:26:06.635833 (Thread-1): 21:26:06 | 1 of 1 ERROR creating view model public.transform_data............... [ERROR in 0.06s]
2023-06-25 01:26:06.636756 (Thread-1): Finished running node model.transform_data.transform_data
2023-06-25 01:26:06.681693 (MainThread): Using postgres connection "master".
2023-06-25 01:26:06.681693 (MainThread): On master: BEGIN
2023-06-25 01:26:06.682191 (MainThread): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:26:06.682191 (MainThread): On master: COMMIT
2023-06-25 01:26:06.682191 (MainThread): Using postgres connection "master".
2023-06-25 01:26:06.682191 (MainThread): On master: COMMIT
2023-06-25 01:26:06.682191 (MainThread): SQL status: COMMIT in 0.00 seconds
2023-06-25 01:26:06.682691 (MainThread): 21:26:06 | 
2023-06-25 01:26:06.682691 (MainThread): 21:26:06 | Finished running 1 view model in 0.28s.
2023-06-25 01:26:06.682691 (MainThread): Connection 'master' was left open.
2023-06-25 01:26:06.683191 (MainThread): On master: Close
2023-06-25 01:26:06.683191 (MainThread): Connection 'list_main_database' was left open.
2023-06-25 01:26:06.683191 (MainThread): On list_main_database: Close
2023-06-25 01:26:06.683191 (MainThread): Connection 'list_main_database_public' was left open.
2023-06-25 01:26:06.683191 (MainThread): On list_main_database_public: Close
2023-06-25 01:26:06.683722 (MainThread): Connection 'model.transform_data.transform_data' was left open.
2023-06-25 01:26:06.683722 (MainThread): On model.transform_data.transform_data: Close
2023-06-25 01:26:06.686191 (MainThread): 
2023-06-25 01:26:06.686191 (MainThread): Completed with 1 error and 0 warnings:
2023-06-25 01:26:06.686691 (MainThread): 
2023-06-25 01:26:06.686691 (MainThread): Database Error in model transform_data (models\transformations\transform_data.sql)
2023-06-25 01:26:06.687190 (MainThread):   syntax error at or near "CREATE"
2023-06-25 01:26:06.687190 (MainThread):   LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
2023-06-25 01:26:06.687190 (MainThread):           ^
2023-06-25 01:26:06.687690 (MainThread):   compiled SQL at target\run\transform_data\transformations\transform_data.sql
2023-06-25 01:26:06.687690 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2023-06-25 01:26:06.688191 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC57C97908>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC0004DB00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC0004DD68>]}
2023-06-25 01:26:06.688191 (MainThread): Flushing usage events
2023-06-25 01:26:09.059260 (MainThread): Running with dbt=0.16.0
2023-06-25 01:26:09.097259 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='C:\\Users\\Me\\.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2023-06-25 01:26:09.097760 (MainThread): Tracking: tracking
2023-06-25 01:26:09.098260 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025CFE7DEEF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025CFE7DE1D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025CFE7DEC50>]}
2023-06-25 01:26:09.109760 (MainThread): Partial parsing not enabled
2023-06-25 01:26:09.112259 (MainThread): Parsing macros\core.sql
2023-06-25 01:26:09.115259 (MainThread): Parsing macros\adapters\common.sql
2023-06-25 01:26:09.146759 (MainThread): Parsing macros\etc\datetime.sql
2023-06-25 01:26:09.153759 (MainThread): Parsing macros\etc\get_custom_alias.sql
2023-06-25 01:26:09.154760 (MainThread): Parsing macros\etc\get_custom_database.sql
2023-06-25 01:26:09.155260 (MainThread): Parsing macros\etc\get_custom_schema.sql
2023-06-25 01:26:09.156759 (MainThread): Parsing macros\etc\get_relation_comment.sql
2023-06-25 01:26:09.158759 (MainThread): Parsing macros\etc\is_incremental.sql
2023-06-25 01:26:09.159760 (MainThread): Parsing macros\etc\query.sql
2023-06-25 01:26:09.160760 (MainThread): Parsing macros\materializations\helpers.sql
2023-06-25 01:26:09.166759 (MainThread): Parsing macros\materializations\common\merge.sql
2023-06-25 01:26:09.176259 (MainThread): Parsing macros\materializations\incremental\helpers.sql
2023-06-25 01:26:09.177760 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2023-06-25 01:26:09.182259 (MainThread): Parsing macros\materializations\seed\seed.sql
2023-06-25 01:26:09.198260 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2023-06-25 01:26:09.222759 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2023-06-25 01:26:09.224259 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2023-06-25 01:26:09.236759 (MainThread): Parsing macros\materializations\table\table.sql
2023-06-25 01:26:09.241759 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2023-06-25 01:26:09.245759 (MainThread): Parsing macros\materializations\view\view.sql
2023-06-25 01:26:09.250259 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2023-06-25 01:26:09.251759 (MainThread): Parsing macros\schema_tests\not_null.sql
2023-06-25 01:26:09.252760 (MainThread): Parsing macros\schema_tests\relationships.sql
2023-06-25 01:26:09.253759 (MainThread): Parsing macros\schema_tests\unique.sql
2023-06-25 01:26:09.254760 (MainThread): Parsing macros\adapters.sql
2023-06-25 01:26:09.267760 (MainThread): Parsing macros\catalog.sql
2023-06-25 01:26:09.269759 (MainThread): Parsing macros\relations.sql
2023-06-25 01:26:09.270759 (MainThread): Parsing macros\materializations\snapshot_merge.sql
2023-06-25 01:26:09.283760 (MainThread): Partial parsing not enabled
2023-06-25 01:26:09.301759 (MainThread): Acquiring new postgres connection "model.transform_data.transform_data".
2023-06-25 01:26:09.301759 (MainThread): Opening a new connection, currently in state init
2023-06-25 01:26:09.513760 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:26:09.513760 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:26:09.513760 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:26:09.513760 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:26:09.513760 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:26:09.514260 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:26:09.514260 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:26:09.544760 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:26:09.544760 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:26:09.664760 (MainThread): scipy not found, skipping conversion test.
2023-06-25 01:26:09.665760 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2023-06-25 01:26:09.666260 (MainThread): Found 1 model, 0 tests, 0 snapshots, 0 analyses, 127 macros, 0 operations, 0 seed files, 0 sources
2023-06-25 01:26:09.666760 (MainThread): 
2023-06-25 01:26:09.667259 (MainThread): Acquiring new postgres connection "master".
2023-06-25 01:26:09.667259 (MainThread): Opening a new connection, currently in state init
2023-06-25 01:26:09.670760 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_main_database".
2023-06-25 01:26:09.670760 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2023-06-25 01:26:09.725758 (ThreadPoolExecutor-0_0): Using postgres connection "list_main_database".
2023-06-25 01:26:09.725758 (ThreadPoolExecutor-0_0): On list_main_database: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "list_main_database"} */

    select distinct nspname from pg_namespace
  
2023-06-25 01:26:09.756260 (ThreadPoolExecutor-0_0): SQL status: SELECT 4 in 0.03 seconds
2023-06-25 01:26:09.761760 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_main_database_public".
2023-06-25 01:26:09.761760 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2023-06-25 01:26:09.762759 (ThreadPoolExecutor-1_0): Using postgres connection "list_main_database_public".
2023-06-25 01:26:09.762759 (ThreadPoolExecutor-1_0): On list_main_database_public: BEGIN
2023-06-25 01:26:09.790761 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.03 seconds
2023-06-25 01:26:09.791261 (ThreadPoolExecutor-1_0): Using postgres connection "list_main_database_public".
2023-06-25 01:26:09.791261 (ThreadPoolExecutor-1_0): On list_main_database_public: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "list_main_database_public"} */
select
      'main_database' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'main_database' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2023-06-25 01:26:09.794261 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2023-06-25 01:26:09.794788 (ThreadPoolExecutor-1_0): On list_main_database_public: ROLLBACK
2023-06-25 01:26:09.800760 (MainThread): Using postgres connection "master".
2023-06-25 01:26:09.800760 (MainThread): On master: BEGIN
2023-06-25 01:26:09.829851 (MainThread): SQL status: BEGIN in 0.03 seconds
2023-06-25 01:26:09.830386 (MainThread): Using postgres connection "master".
2023-06-25 01:26:09.830386 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2023-06-25 01:26:09.833898 (MainThread): SQL status: SELECT 0 in 0.00 seconds
2023-06-25 01:26:09.834389 (MainThread): On master: ROLLBACK
2023-06-25 01:26:09.834389 (MainThread): Using postgres connection "master".
2023-06-25 01:26:09.834389 (MainThread): On master: BEGIN
2023-06-25 01:26:09.835033 (MainThread): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:26:09.835033 (MainThread): On master: COMMIT
2023-06-25 01:26:09.835033 (MainThread): Using postgres connection "master".
2023-06-25 01:26:09.835033 (MainThread): On master: COMMIT
2023-06-25 01:26:09.835506 (MainThread): SQL status: COMMIT in 0.00 seconds
2023-06-25 01:26:09.835506 (MainThread): 21:26:09 | Concurrency: 1 threads (target='dev')
2023-06-25 01:26:09.835835 (MainThread): 21:26:09 | 
2023-06-25 01:26:09.837340 (Thread-1): Began running node model.transform_data.transform_data
2023-06-25 01:26:09.837340 (Thread-1): 21:26:09 | 1 of 1 START view model public.transform_data........................ [RUN]
2023-06-25 01:26:09.837864 (Thread-1): Acquiring new postgres connection "model.transform_data.transform_data".
2023-06-25 01:26:09.837864 (Thread-1): Opening a new connection, currently in state init
2023-06-25 01:26:09.837864 (Thread-1): Compiling model.transform_data.transform_data
2023-06-25 01:26:09.845841 (Thread-1): Writing injected SQL for node "model.transform_data.transform_data"
2023-06-25 01:26:09.846340 (Thread-1): finished collecting timing info
2023-06-25 01:26:09.866338 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:26:09.866338 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */
drop view if exists "main_database"."public"."transform_data__dbt_tmp" cascade
2023-06-25 01:26:09.895433 (Thread-1): SQL status: DROP VIEW in 0.03 seconds
2023-06-25 01:26:09.896937 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:26:09.897437 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */
drop view if exists "main_database"."public"."transform_data__dbt_backup" cascade
2023-06-25 01:26:09.897437 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2023-06-25 01:26:09.898437 (Thread-1): Writing runtime SQL for node "model.transform_data.transform_data"
2023-06-25 01:26:09.898937 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:26:09.898937 (Thread-1): On model.transform_data.transform_data: BEGIN
2023-06-25 01:26:09.899438 (Thread-1): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:26:09.899438 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:26:09.899438 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */

  create view "main_database"."public"."transform_data__dbt_tmp" as (
    -- Create a temporary table to hold the filtered and transformed data
CREATE TEMPORARY TABLE temp_transactions AS
SELECT
  "address",
  "amount",
  "timestamp"
FROM
  public.transactions
WHERE
  "timestamp" > CURRENT_TIMESTAMP - INTERVAL '2 years';

-- Clear existing data from the target table
TRUNCATE TABLE public.transactions;

-- Insert the data from the temporary table into the target table
INSERT INTO public.transactions ("address", "amount", "timestamp")
SELECT
  "address",
  "amount",
  "timestamp"
FROM
  temp_transactions;
  );

2023-06-25 01:26:09.899937 (Thread-1): Postgres error: syntax error at or near "CREATE"
LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
        ^

2023-06-25 01:26:09.899937 (Thread-1): On model.transform_data.transform_data: ROLLBACK
2023-06-25 01:26:09.899937 (Thread-1): finished collecting timing info
2023-06-25 01:26:09.900438 (Thread-1): Database Error in model transform_data (models\transformations\transform_data.sql)
  syntax error at or near "CREATE"
  LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
          ^
  compiled SQL at target\run\transform_data\transformations\transform_data.sql
Traceback (most recent call last):
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\postgres\connections.py", line 46, in exception_handler
    yield
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near "CREATE"
LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
        ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 223, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 166, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 268, in run
    return self.execute(compiled_node, manifest)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 450, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 60, in macro
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\base\impl.py", line 220, in execute
    fetch=fetch
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 116, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 82, in add_query
    return connection, cursor
  File "c:\users\me\appdata\local\programs\python\python37\lib\contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\postgres\connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model transform_data (models\transformations\transform_data.sql)
  syntax error at or near "CREATE"
  LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
          ^
  compiled SQL at target\run\transform_data\transformations\transform_data.sql
2023-06-25 01:26:09.901937 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a7fffac-7e4a-49cf-bbcb-9773aad772f5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025CA6F3E438>]}
2023-06-25 01:26:09.901937 (Thread-1): 21:26:09 | 1 of 1 ERROR creating view model public.transform_data............... [ERROR in 0.06s]
2023-06-25 01:26:09.902937 (Thread-1): Finished running node model.transform_data.transform_data
2023-06-25 01:26:09.938259 (MainThread): Using postgres connection "master".
2023-06-25 01:26:09.938259 (MainThread): On master: BEGIN
2023-06-25 01:26:09.938259 (MainThread): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:26:09.938259 (MainThread): On master: COMMIT
2023-06-25 01:26:09.938259 (MainThread): Using postgres connection "master".
2023-06-25 01:26:09.938758 (MainThread): On master: COMMIT
2023-06-25 01:26:09.938758 (MainThread): SQL status: COMMIT in 0.00 seconds
2023-06-25 01:26:09.938758 (MainThread): 21:26:09 | 
2023-06-25 01:26:09.939259 (MainThread): 21:26:09 | Finished running 1 view model in 0.27s.
2023-06-25 01:26:09.939259 (MainThread): Connection 'master' was left open.
2023-06-25 01:26:09.939259 (MainThread): On master: Close
2023-06-25 01:26:09.939793 (MainThread): Connection 'list_main_database' was left open.
2023-06-25 01:26:09.939793 (MainThread): On list_main_database: Close
2023-06-25 01:26:09.939793 (MainThread): Connection 'list_main_database_public' was left open.
2023-06-25 01:26:09.939793 (MainThread): On list_main_database_public: Close
2023-06-25 01:26:09.939793 (MainThread): Connection 'model.transform_data.transform_data' was left open.
2023-06-25 01:26:09.939793 (MainThread): On model.transform_data.transform_data: Close
2023-06-25 01:26:09.942264 (MainThread): 
2023-06-25 01:26:09.942264 (MainThread): Completed with 1 error and 0 warnings:
2023-06-25 01:26:09.942762 (MainThread): 
2023-06-25 01:26:09.943262 (MainThread): Database Error in model transform_data (models\transformations\transform_data.sql)
2023-06-25 01:26:09.943763 (MainThread):   syntax error at or near "CREATE"
2023-06-25 01:26:09.943763 (MainThread):   LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
2023-06-25 01:26:09.943763 (MainThread):           ^
2023-06-25 01:26:09.944263 (MainThread):   compiled SQL at target\run\transform_data\transformations\transform_data.sql
2023-06-25 01:26:09.944263 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2023-06-25 01:26:09.944778 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025CA6EF39B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025CA6EF3CC0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025CA6EF3320>]}
2023-06-25 01:26:09.944778 (MainThread): Flushing usage events
2023-06-25 01:26:43.195763 (MainThread): Running with dbt=0.16.0
2023-06-25 01:26:43.233762 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=['+transformations.transform_data'], partial_parse=None, profile=None, profiles_dir='C:\\Users\\Me\\.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2023-06-25 01:26:43.234262 (MainThread): Tracking: tracking
2023-06-25 01:26:43.234762 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020C462BDFD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020C462BD710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020C462BD358>]}
2023-06-25 01:26:43.246762 (MainThread): Partial parsing not enabled
2023-06-25 01:26:43.249302 (MainThread): Parsing macros\core.sql
2023-06-25 01:26:43.252763 (MainThread): Parsing macros\adapters\common.sql
2023-06-25 01:26:43.284762 (MainThread): Parsing macros\etc\datetime.sql
2023-06-25 01:26:43.291763 (MainThread): Parsing macros\etc\get_custom_alias.sql
2023-06-25 01:26:43.292762 (MainThread): Parsing macros\etc\get_custom_database.sql
2023-06-25 01:26:43.293762 (MainThread): Parsing macros\etc\get_custom_schema.sql
2023-06-25 01:26:43.295263 (MainThread): Parsing macros\etc\get_relation_comment.sql
2023-06-25 01:26:43.296762 (MainThread): Parsing macros\etc\is_incremental.sql
2023-06-25 01:26:43.298262 (MainThread): Parsing macros\etc\query.sql
2023-06-25 01:26:43.299262 (MainThread): Parsing macros\materializations\helpers.sql
2023-06-25 01:26:43.304762 (MainThread): Parsing macros\materializations\common\merge.sql
2023-06-25 01:26:43.314762 (MainThread): Parsing macros\materializations\incremental\helpers.sql
2023-06-25 01:26:43.316263 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2023-06-25 01:26:43.320762 (MainThread): Parsing macros\materializations\seed\seed.sql
2023-06-25 01:26:43.336262 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2023-06-25 01:26:43.361264 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2023-06-25 01:26:43.362763 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2023-06-25 01:26:43.376263 (MainThread): Parsing macros\materializations\table\table.sql
2023-06-25 01:26:43.381762 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2023-06-25 01:26:43.385762 (MainThread): Parsing macros\materializations\view\view.sql
2023-06-25 01:26:43.390262 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2023-06-25 01:26:43.392262 (MainThread): Parsing macros\schema_tests\not_null.sql
2023-06-25 01:26:43.392762 (MainThread): Parsing macros\schema_tests\relationships.sql
2023-06-25 01:26:43.393763 (MainThread): Parsing macros\schema_tests\unique.sql
2023-06-25 01:26:43.394762 (MainThread): Parsing macros\adapters.sql
2023-06-25 01:26:43.408262 (MainThread): Parsing macros\catalog.sql
2023-06-25 01:26:43.410262 (MainThread): Parsing macros\relations.sql
2023-06-25 01:26:43.411262 (MainThread): Parsing macros\materializations\snapshot_merge.sql
2023-06-25 01:26:43.424262 (MainThread): Partial parsing not enabled
2023-06-25 01:26:43.443763 (MainThread): Acquiring new postgres connection "model.transform_data.transform_data".
2023-06-25 01:26:43.443763 (MainThread): Opening a new connection, currently in state init
2023-06-25 01:26:43.588262 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:26:43.588762 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:26:43.588762 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:26:43.588762 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:26:43.588762 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:26:43.588762 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:26:43.588762 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:26:43.590263 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:26:43.590762 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:26:43.591762 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:26:43.593263 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:26:43.594762 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:26:43.595262 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:26:43.595762 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:26:43.596762 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:26:43.597262 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:26:43.597763 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:26:43.598763 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:26:43.599263 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:26:43.600262 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:26:43.601262 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:26:43.603763 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:26:43.607262 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:26:43.608262 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:26:43.609263 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:26:43.610262 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:26:43.610762 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:26:43.618262 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:26:43.621762 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:26:43.621762 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:26:43.623763 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:26:43.638762 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:26:43.639262 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:26:43.641262 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:26:43.674795 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:26:43.679292 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:26:43.679805 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:26:43.693265 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:26:43.696265 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:26:43.712297 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:26:43.713299 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:26:43.726266 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:26:43.743263 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:26:43.743797 (MainThread): scipy not found, skipping conversion test.
2023-06-25 01:26:43.744796 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2023-06-25 01:26:43.745264 (MainThread): Found 1 model, 0 tests, 0 snapshots, 0 analyses, 127 macros, 0 operations, 0 seed files, 0 sources
2023-06-25 01:26:43.745795 (MainThread): 
2023-06-25 01:26:43.746294 (MainThread): Acquiring new postgres connection "master".
2023-06-25 01:26:43.746294 (MainThread): Opening a new connection, currently in state init
2023-06-25 01:26:43.749786 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_main_database".
2023-06-25 01:26:43.750292 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2023-06-25 01:26:43.805762 (ThreadPoolExecutor-0_0): Using postgres connection "list_main_database".
2023-06-25 01:26:43.805762 (ThreadPoolExecutor-0_0): On list_main_database: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "list_main_database"} */

    select distinct nspname from pg_namespace
  
2023-06-25 01:26:43.836297 (ThreadPoolExecutor-0_0): SQL status: SELECT 4 in 0.03 seconds
2023-06-25 01:26:43.841795 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_main_database_public".
2023-06-25 01:26:43.841795 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2023-06-25 01:26:43.842792 (ThreadPoolExecutor-1_0): Using postgres connection "list_main_database_public".
2023-06-25 01:26:43.842792 (ThreadPoolExecutor-1_0): On list_main_database_public: BEGIN
2023-06-25 01:26:43.875299 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.03 seconds
2023-06-25 01:26:43.875794 (ThreadPoolExecutor-1_0): Using postgres connection "list_main_database_public".
2023-06-25 01:26:43.875794 (ThreadPoolExecutor-1_0): On list_main_database_public: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "list_main_database_public"} */
select
      'main_database' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'main_database' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2023-06-25 01:26:43.878793 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2023-06-25 01:26:43.879300 (ThreadPoolExecutor-1_0): On list_main_database_public: ROLLBACK
2023-06-25 01:26:43.885262 (MainThread): Using postgres connection "master".
2023-06-25 01:26:43.885262 (MainThread): On master: BEGIN
2023-06-25 01:26:43.913762 (MainThread): SQL status: BEGIN in 0.03 seconds
2023-06-25 01:26:43.913762 (MainThread): Using postgres connection "master".
2023-06-25 01:26:43.914262 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2023-06-25 01:26:43.917762 (MainThread): SQL status: SELECT 0 in 0.00 seconds
2023-06-25 01:26:43.918262 (MainThread): On master: ROLLBACK
2023-06-25 01:26:43.918262 (MainThread): Using postgres connection "master".
2023-06-25 01:26:43.918262 (MainThread): On master: BEGIN
2023-06-25 01:26:43.918762 (MainThread): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:26:43.918762 (MainThread): On master: COMMIT
2023-06-25 01:26:43.918762 (MainThread): Using postgres connection "master".
2023-06-25 01:26:43.918762 (MainThread): On master: COMMIT
2023-06-25 01:26:43.919263 (MainThread): SQL status: COMMIT in 0.00 seconds
2023-06-25 01:26:43.919263 (MainThread): 21:26:43 | Concurrency: 1 threads (target='dev')
2023-06-25 01:26:43.919263 (MainThread): 21:26:43 | 
2023-06-25 01:26:43.921262 (Thread-1): Began running node model.transform_data.transform_data
2023-06-25 01:26:43.921262 (Thread-1): 21:26:43 | 1 of 1 START view model public.transform_data........................ [RUN]
2023-06-25 01:26:43.921262 (Thread-1): Acquiring new postgres connection "model.transform_data.transform_data".
2023-06-25 01:26:43.921262 (Thread-1): Opening a new connection, currently in state init
2023-06-25 01:26:43.921262 (Thread-1): Compiling model.transform_data.transform_data
2023-06-25 01:26:43.929762 (Thread-1): Writing injected SQL for node "model.transform_data.transform_data"
2023-06-25 01:26:43.930263 (Thread-1): finished collecting timing info
2023-06-25 01:26:43.950262 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:26:43.950262 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */
drop view if exists "main_database"."public"."transform_data__dbt_tmp" cascade
2023-06-25 01:26:43.979763 (Thread-1): SQL status: DROP VIEW in 0.03 seconds
2023-06-25 01:26:43.981764 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:26:43.981764 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */
drop view if exists "main_database"."public"."transform_data__dbt_backup" cascade
2023-06-25 01:26:43.982263 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2023-06-25 01:26:43.983262 (Thread-1): Writing runtime SQL for node "model.transform_data.transform_data"
2023-06-25 01:26:43.983763 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:26:43.983763 (Thread-1): On model.transform_data.transform_data: BEGIN
2023-06-25 01:26:43.984262 (Thread-1): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:26:43.984262 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:26:43.984262 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */

  create view "main_database"."public"."transform_data__dbt_tmp" as (
    -- Create a temporary table to hold the filtered and transformed data
CREATE TEMPORARY TABLE temp_transactions AS
SELECT
  "address",
  "amount",
  "timestamp"
FROM
  public.transactions
WHERE
  "timestamp" > CURRENT_TIMESTAMP - INTERVAL '2 years';

-- Clear existing data from the target table
TRUNCATE TABLE public.transactions;

-- Insert the data from the temporary table into the target table
INSERT INTO public.transactions ("address", "amount", "timestamp")
SELECT
  "address",
  "amount",
  "timestamp"
FROM
  temp_transactions;
  );

2023-06-25 01:26:43.984262 (Thread-1): Postgres error: syntax error at or near "CREATE"
LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
        ^

2023-06-25 01:26:43.984762 (Thread-1): On model.transform_data.transform_data: ROLLBACK
2023-06-25 01:26:43.984762 (Thread-1): finished collecting timing info
2023-06-25 01:26:43.985262 (Thread-1): Database Error in model transform_data (models\transformations\transform_data.sql)
  syntax error at or near "CREATE"
  LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
          ^
  compiled SQL at target\run\transform_data\transformations\transform_data.sql
Traceback (most recent call last):
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\postgres\connections.py", line 46, in exception_handler
    yield
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near "CREATE"
LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
        ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 223, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 166, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 268, in run
    return self.execute(compiled_node, manifest)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 450, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 60, in macro
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\base\impl.py", line 220, in execute
    fetch=fetch
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 116, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 82, in add_query
    return connection, cursor
  File "c:\users\me\appdata\local\programs\python\python37\lib\contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\postgres\connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model transform_data (models\transformations\transform_data.sql)
  syntax error at or near "CREATE"
  LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
          ^
  compiled SQL at target\run\transform_data\transformations\transform_data.sql
2023-06-25 01:26:43.987265 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4c3fdfb6-9d33-4276-bd9d-4c2221712a38', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020C4A22A0B8>]}
2023-06-25 01:26:43.987265 (Thread-1): 21:26:43 | 1 of 1 ERROR creating view model public.transform_data............... [ERROR in 0.07s]
2023-06-25 01:26:43.987766 (Thread-1): Finished running node model.transform_data.transform_data
2023-06-25 01:26:44.023766 (MainThread): Using postgres connection "master".
2023-06-25 01:26:44.023766 (MainThread): On master: BEGIN
2023-06-25 01:26:44.023766 (MainThread): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:26:44.024263 (MainThread): On master: COMMIT
2023-06-25 01:26:44.024263 (MainThread): Using postgres connection "master".
2023-06-25 01:26:44.024263 (MainThread): On master: COMMIT
2023-06-25 01:26:44.024263 (MainThread): SQL status: COMMIT in 0.00 seconds
2023-06-25 01:26:44.024263 (MainThread): 21:26:44 | 
2023-06-25 01:26:44.024764 (MainThread): 21:26:44 | Finished running 1 view model in 0.28s.
2023-06-25 01:26:44.024764 (MainThread): Connection 'master' was left open.
2023-06-25 01:26:44.024764 (MainThread): On master: Close
2023-06-25 01:26:44.024764 (MainThread): Connection 'list_main_database' was left open.
2023-06-25 01:26:44.024764 (MainThread): On list_main_database: Close
2023-06-25 01:26:44.024764 (MainThread): Connection 'list_main_database_public' was left open.
2023-06-25 01:26:44.025263 (MainThread): On list_main_database_public: Close
2023-06-25 01:26:44.025263 (MainThread): Connection 'model.transform_data.transform_data' was left open.
2023-06-25 01:26:44.025263 (MainThread): On model.transform_data.transform_data: Close
2023-06-25 01:26:44.030764 (MainThread): 
2023-06-25 01:26:44.030764 (MainThread): Completed with 1 error and 0 warnings:
2023-06-25 01:26:44.030764 (MainThread): 
2023-06-25 01:26:44.031264 (MainThread): Database Error in model transform_data (models\transformations\transform_data.sql)
2023-06-25 01:26:44.031264 (MainThread):   syntax error at or near "CREATE"
2023-06-25 01:26:44.031264 (MainThread):   LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
2023-06-25 01:26:44.031264 (MainThread):           ^
2023-06-25 01:26:44.031264 (MainThread):   compiled SQL at target\run\transform_data\transformations\transform_data.sql
2023-06-25 01:26:44.031264 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2023-06-25 01:26:44.031764 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020C49117BE0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020C49F22A20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020C49F227F0>]}
2023-06-25 01:26:44.031764 (MainThread): Flushing usage events
2023-06-25 01:26:48.975782 (MainThread): Running with dbt=0.16.0
2023-06-25 01:26:49.013782 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='C:\\Users\\Me\\.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2023-06-25 01:26:49.013782 (MainThread): Tracking: tracking
2023-06-25 01:26:49.014782 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029F473002B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029F47300EB8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029F47300C50>]}
2023-06-25 01:26:49.026282 (MainThread): Partial parsing not enabled
2023-06-25 01:26:49.028282 (MainThread): Parsing macros\core.sql
2023-06-25 01:26:49.031782 (MainThread): Parsing macros\adapters\common.sql
2023-06-25 01:26:49.062783 (MainThread): Parsing macros\etc\datetime.sql
2023-06-25 01:26:49.069282 (MainThread): Parsing macros\etc\get_custom_alias.sql
2023-06-25 01:26:49.070282 (MainThread): Parsing macros\etc\get_custom_database.sql
2023-06-25 01:26:49.071283 (MainThread): Parsing macros\etc\get_custom_schema.sql
2023-06-25 01:26:49.072782 (MainThread): Parsing macros\etc\get_relation_comment.sql
2023-06-25 01:26:49.074282 (MainThread): Parsing macros\etc\is_incremental.sql
2023-06-25 01:26:49.075782 (MainThread): Parsing macros\etc\query.sql
2023-06-25 01:26:49.076282 (MainThread): Parsing macros\materializations\helpers.sql
2023-06-25 01:26:49.082282 (MainThread): Parsing macros\materializations\common\merge.sql
2023-06-25 01:26:49.091782 (MainThread): Parsing macros\materializations\incremental\helpers.sql
2023-06-25 01:26:49.093282 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2023-06-25 01:26:49.097782 (MainThread): Parsing macros\materializations\seed\seed.sql
2023-06-25 01:26:49.113283 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2023-06-25 01:26:49.137782 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2023-06-25 01:26:49.139282 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2023-06-25 01:26:49.151812 (MainThread): Parsing macros\materializations\table\table.sql
2023-06-25 01:26:49.156812 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2023-06-25 01:26:49.160282 (MainThread): Parsing macros\materializations\view\view.sql
2023-06-25 01:26:49.164782 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2023-06-25 01:26:49.166282 (MainThread): Parsing macros\schema_tests\not_null.sql
2023-06-25 01:26:49.167282 (MainThread): Parsing macros\schema_tests\relationships.sql
2023-06-25 01:26:49.168282 (MainThread): Parsing macros\schema_tests\unique.sql
2023-06-25 01:26:49.169282 (MainThread): Parsing macros\adapters.sql
2023-06-25 01:26:49.182282 (MainThread): Parsing macros\catalog.sql
2023-06-25 01:26:49.183784 (MainThread): Parsing macros\relations.sql
2023-06-25 01:26:49.184782 (MainThread): Parsing macros\materializations\snapshot_merge.sql
2023-06-25 01:26:49.197782 (MainThread): Partial parsing not enabled
2023-06-25 01:26:49.216282 (MainThread): Acquiring new postgres connection "model.transform_data.transform_data".
2023-06-25 01:26:49.216282 (MainThread): Opening a new connection, currently in state init
2023-06-25 01:26:49.425282 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:26:49.425782 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:26:49.425782 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:26:49.425782 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:26:49.425782 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:26:49.425782 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:26:49.425782 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:26:49.456782 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:26:49.456782 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:26:49.575282 (MainThread): scipy not found, skipping conversion test.
2023-06-25 01:26:49.576283 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2023-06-25 01:26:49.576283 (MainThread): Found 1 model, 0 tests, 0 snapshots, 0 analyses, 127 macros, 0 operations, 0 seed files, 0 sources
2023-06-25 01:26:49.577283 (MainThread): 
2023-06-25 01:26:49.577283 (MainThread): Acquiring new postgres connection "master".
2023-06-25 01:26:49.577283 (MainThread): Opening a new connection, currently in state init
2023-06-25 01:26:49.580783 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_main_database".
2023-06-25 01:26:49.581284 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2023-06-25 01:26:49.636783 (ThreadPoolExecutor-0_0): Using postgres connection "list_main_database".
2023-06-25 01:26:49.636783 (ThreadPoolExecutor-0_0): On list_main_database: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "list_main_database"} */

    select distinct nspname from pg_namespace
  
2023-06-25 01:26:49.667813 (ThreadPoolExecutor-0_0): SQL status: SELECT 4 in 0.03 seconds
2023-06-25 01:26:49.672812 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_main_database_public".
2023-06-25 01:26:49.672812 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2023-06-25 01:26:49.673812 (ThreadPoolExecutor-1_0): Using postgres connection "list_main_database_public".
2023-06-25 01:26:49.673812 (ThreadPoolExecutor-1_0): On list_main_database_public: BEGIN
2023-06-25 01:26:49.703282 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.03 seconds
2023-06-25 01:26:49.703282 (ThreadPoolExecutor-1_0): Using postgres connection "list_main_database_public".
2023-06-25 01:26:49.703282 (ThreadPoolExecutor-1_0): On list_main_database_public: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "list_main_database_public"} */
select
      'main_database' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'main_database' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2023-06-25 01:26:49.706282 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2023-06-25 01:26:49.707282 (ThreadPoolExecutor-1_0): On list_main_database_public: ROLLBACK
2023-06-25 01:26:49.712782 (MainThread): Using postgres connection "master".
2023-06-25 01:26:49.712782 (MainThread): On master: BEGIN
2023-06-25 01:26:49.744324 (MainThread): SQL status: BEGIN in 0.03 seconds
2023-06-25 01:26:49.744324 (MainThread): Using postgres connection "master".
2023-06-25 01:26:49.744324 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2023-06-25 01:26:49.747815 (MainThread): SQL status: SELECT 0 in 0.00 seconds
2023-06-25 01:26:49.748812 (MainThread): On master: ROLLBACK
2023-06-25 01:26:49.748812 (MainThread): Using postgres connection "master".
2023-06-25 01:26:49.748812 (MainThread): On master: BEGIN
2023-06-25 01:26:49.749322 (MainThread): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:26:49.749322 (MainThread): On master: COMMIT
2023-06-25 01:26:49.749322 (MainThread): Using postgres connection "master".
2023-06-25 01:26:49.749322 (MainThread): On master: COMMIT
2023-06-25 01:26:49.749322 (MainThread): SQL status: COMMIT in 0.00 seconds
2023-06-25 01:26:49.749813 (MainThread): 21:26:49 | Concurrency: 1 threads (target='dev')
2023-06-25 01:26:49.749813 (MainThread): 21:26:49 | 
2023-06-25 01:26:49.751284 (Thread-1): Began running node model.transform_data.transform_data
2023-06-25 01:26:49.751812 (Thread-1): 21:26:49 | 1 of 1 START view model public.transform_data........................ [RUN]
2023-06-25 01:26:49.751812 (Thread-1): Acquiring new postgres connection "model.transform_data.transform_data".
2023-06-25 01:26:49.751812 (Thread-1): Opening a new connection, currently in state init
2023-06-25 01:26:49.752282 (Thread-1): Compiling model.transform_data.transform_data
2023-06-25 01:26:49.760282 (Thread-1): Writing injected SQL for node "model.transform_data.transform_data"
2023-06-25 01:26:49.760784 (Thread-1): finished collecting timing info
2023-06-25 01:26:49.780782 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:26:49.780782 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */
drop view if exists "main_database"."public"."transform_data__dbt_tmp" cascade
2023-06-25 01:26:49.809138 (Thread-1): SQL status: DROP VIEW in 0.03 seconds
2023-06-25 01:26:49.810667 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:26:49.811165 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */
drop view if exists "main_database"."public"."transform_data__dbt_backup" cascade
2023-06-25 01:26:49.811165 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2023-06-25 01:26:49.812166 (Thread-1): Writing runtime SQL for node "model.transform_data.transform_data"
2023-06-25 01:26:49.812637 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:26:49.812637 (Thread-1): On model.transform_data.transform_data: BEGIN
2023-06-25 01:26:49.813137 (Thread-1): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:26:49.813137 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:26:49.813137 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */

  create view "main_database"."public"."transform_data__dbt_tmp" as (
    -- Create a temporary table to hold the filtered and transformed data
CREATE TEMPORARY TABLE temp_transactions AS
SELECT
  "address",
  "amount",
  "timestamp"
FROM
  public.transactions
WHERE
  "timestamp" > CURRENT_TIMESTAMP - INTERVAL '2 years';

-- Clear existing data from the target table
TRUNCATE TABLE public.transactions;

-- Insert the data from the temporary table into the target table
INSERT INTO public.transactions ("address", "amount", "timestamp")
SELECT
  "address",
  "amount",
  "timestamp"
FROM
  temp_transactions;
  );

2023-06-25 01:26:49.813137 (Thread-1): Postgres error: syntax error at or near "CREATE"
LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
        ^

2023-06-25 01:26:49.813637 (Thread-1): On model.transform_data.transform_data: ROLLBACK
2023-06-25 01:26:49.813637 (Thread-1): finished collecting timing info
2023-06-25 01:26:49.813637 (Thread-1): Database Error in model transform_data (models\transformations\transform_data.sql)
  syntax error at or near "CREATE"
  LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
          ^
  compiled SQL at target\run\transform_data\transformations\transform_data.sql
Traceback (most recent call last):
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\postgres\connections.py", line 46, in exception_handler
    yield
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near "CREATE"
LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
        ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 223, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 166, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 268, in run
    return self.execute(compiled_node, manifest)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 450, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 60, in macro
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\base\impl.py", line 220, in execute
    fetch=fetch
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 116, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 82, in add_query
    return connection, cursor
  File "c:\users\me\appdata\local\programs\python\python37\lib\contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\postgres\connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model transform_data (models\transformations\transform_data.sql)
  syntax error at or near "CREATE"
  LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
          ^
  compiled SQL at target\run\transform_data\transformations\transform_data.sql
2023-06-25 01:26:49.815666 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4810d021-c618-446f-96c1-22ac47de508f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029F6F8F9D68>]}
2023-06-25 01:26:49.815666 (Thread-1): 21:26:49 | 1 of 1 ERROR creating view model public.transform_data............... [ERROR in 0.06s]
2023-06-25 01:26:49.816135 (Thread-1): Finished running node model.transform_data.transform_data
2023-06-25 01:26:49.861884 (MainThread): Using postgres connection "master".
2023-06-25 01:26:49.862384 (MainThread): On master: BEGIN
2023-06-25 01:26:49.863386 (MainThread): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:26:49.863884 (MainThread): On master: COMMIT
2023-06-25 01:26:49.863884 (MainThread): Using postgres connection "master".
2023-06-25 01:26:49.864384 (MainThread): On master: COMMIT
2023-06-25 01:26:49.865402 (MainThread): SQL status: COMMIT in 0.00 seconds
2023-06-25 01:26:49.866384 (MainThread): 21:26:49 | 
2023-06-25 01:26:49.867339 (MainThread): 21:26:49 | Finished running 1 view model in 0.29s.
2023-06-25 01:26:49.867339 (MainThread): Connection 'master' was left open.
2023-06-25 01:26:49.867826 (MainThread): On master: Close
2023-06-25 01:26:49.867826 (MainThread): Connection 'list_main_database' was left open.
2023-06-25 01:26:49.867826 (MainThread): On list_main_database: Close
2023-06-25 01:26:49.867826 (MainThread): Connection 'list_main_database_public' was left open.
2023-06-25 01:26:49.867826 (MainThread): On list_main_database_public: Close
2023-06-25 01:26:49.867826 (MainThread): Connection 'model.transform_data.transform_data' was left open.
2023-06-25 01:26:49.868326 (MainThread): On model.transform_data.transform_data: Close
2023-06-25 01:26:49.870326 (MainThread): 
2023-06-25 01:26:49.870827 (MainThread): Completed with 1 error and 0 warnings:
2023-06-25 01:26:49.871327 (MainThread): 
2023-06-25 01:26:49.871327 (MainThread): Database Error in model transform_data (models\transformations\transform_data.sql)
2023-06-25 01:26:49.871826 (MainThread):   syntax error at or near "CREATE"
2023-06-25 01:26:49.871826 (MainThread):   LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
2023-06-25 01:26:49.871826 (MainThread):           ^
2023-06-25 01:26:49.872327 (MainThread):   compiled SQL at target\run\transform_data\transformations\transform_data.sql
2023-06-25 01:26:49.872327 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2023-06-25 01:26:49.872327 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029F6F918E10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029F6F8A5940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000029F6F8A5978>]}
2023-06-25 01:26:49.872826 (MainThread): Flushing usage events
2023-06-25 01:26:52.361321 (MainThread): Running with dbt=0.16.0
2023-06-25 01:26:52.397821 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='C:\\Users\\Me\\.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target='dev', test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2023-06-25 01:26:52.398321 (MainThread): Tracking: tracking
2023-06-25 01:26:52.399321 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002686F05F198>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002686F05FEB8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002686F05FC50>]}
2023-06-25 01:26:52.410821 (MainThread): Partial parsing not enabled
2023-06-25 01:26:52.412821 (MainThread): Parsing macros\core.sql
2023-06-25 01:26:52.416321 (MainThread): Parsing macros\adapters\common.sql
2023-06-25 01:26:52.447321 (MainThread): Parsing macros\etc\datetime.sql
2023-06-25 01:26:52.453821 (MainThread): Parsing macros\etc\get_custom_alias.sql
2023-06-25 01:26:52.454821 (MainThread): Parsing macros\etc\get_custom_database.sql
2023-06-25 01:26:52.455821 (MainThread): Parsing macros\etc\get_custom_schema.sql
2023-06-25 01:26:52.457321 (MainThread): Parsing macros\etc\get_relation_comment.sql
2023-06-25 01:26:52.458822 (MainThread): Parsing macros\etc\is_incremental.sql
2023-06-25 01:26:52.460321 (MainThread): Parsing macros\etc\query.sql
2023-06-25 01:26:52.460821 (MainThread): Parsing macros\materializations\helpers.sql
2023-06-25 01:26:52.466821 (MainThread): Parsing macros\materializations\common\merge.sql
2023-06-25 01:26:52.476321 (MainThread): Parsing macros\materializations\incremental\helpers.sql
2023-06-25 01:26:52.477821 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2023-06-25 01:26:52.482321 (MainThread): Parsing macros\materializations\seed\seed.sql
2023-06-25 01:26:52.497321 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2023-06-25 01:26:52.522321 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2023-06-25 01:26:52.523321 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2023-06-25 01:26:52.535821 (MainThread): Parsing macros\materializations\table\table.sql
2023-06-25 01:26:52.540821 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2023-06-25 01:26:52.544321 (MainThread): Parsing macros\materializations\view\view.sql
2023-06-25 01:26:52.549321 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2023-06-25 01:26:52.550821 (MainThread): Parsing macros\schema_tests\not_null.sql
2023-06-25 01:26:52.551321 (MainThread): Parsing macros\schema_tests\relationships.sql
2023-06-25 01:26:52.552321 (MainThread): Parsing macros\schema_tests\unique.sql
2023-06-25 01:26:52.553321 (MainThread): Parsing macros\adapters.sql
2023-06-25 01:26:52.566321 (MainThread): Parsing macros\catalog.sql
2023-06-25 01:26:52.567821 (MainThread): Parsing macros\relations.sql
2023-06-25 01:26:52.568821 (MainThread): Parsing macros\materializations\snapshot_merge.sql
2023-06-25 01:26:52.581821 (MainThread): Partial parsing not enabled
2023-06-25 01:26:52.599821 (MainThread): Acquiring new postgres connection "model.transform_data.transform_data".
2023-06-25 01:26:52.600321 (MainThread): Opening a new connection, currently in state init
2023-06-25 01:26:52.810321 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:26:52.810321 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:26:52.810821 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:26:52.810821 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:26:52.810821 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:26:52.810821 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:26:52.810821 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:26:52.841321 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:26:52.841821 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:26:52.960821 (MainThread): scipy not found, skipping conversion test.
2023-06-25 01:26:52.961821 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2023-06-25 01:26:52.962321 (MainThread): Found 1 model, 0 tests, 0 snapshots, 0 analyses, 127 macros, 0 operations, 0 seed files, 0 sources
2023-06-25 01:26:52.962821 (MainThread): 
2023-06-25 01:26:52.963321 (MainThread): Acquiring new postgres connection "master".
2023-06-25 01:26:52.963321 (MainThread): Opening a new connection, currently in state init
2023-06-25 01:26:52.966821 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_main_database".
2023-06-25 01:26:52.966821 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2023-06-25 01:26:53.021321 (ThreadPoolExecutor-0_0): Using postgres connection "list_main_database".
2023-06-25 01:26:53.021821 (ThreadPoolExecutor-0_0): On list_main_database: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "list_main_database"} */

    select distinct nspname from pg_namespace
  
2023-06-25 01:26:53.051821 (ThreadPoolExecutor-0_0): SQL status: SELECT 4 in 0.03 seconds
2023-06-25 01:26:53.056822 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_main_database_public".
2023-06-25 01:26:53.056822 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2023-06-25 01:26:53.057822 (ThreadPoolExecutor-1_0): Using postgres connection "list_main_database_public".
2023-06-25 01:26:53.057822 (ThreadPoolExecutor-1_0): On list_main_database_public: BEGIN
2023-06-25 01:26:53.084821 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.03 seconds
2023-06-25 01:26:53.084821 (ThreadPoolExecutor-1_0): Using postgres connection "list_main_database_public".
2023-06-25 01:26:53.084821 (ThreadPoolExecutor-1_0): On list_main_database_public: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "list_main_database_public"} */
select
      'main_database' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'main_database' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2023-06-25 01:26:53.087822 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2023-06-25 01:26:53.088821 (ThreadPoolExecutor-1_0): On list_main_database_public: ROLLBACK
2023-06-25 01:26:53.094321 (MainThread): Using postgres connection "master".
2023-06-25 01:26:53.094321 (MainThread): On master: BEGIN
2023-06-25 01:26:53.123140 (MainThread): SQL status: BEGIN in 0.03 seconds
2023-06-25 01:26:53.123140 (MainThread): Using postgres connection "master".
2023-06-25 01:26:53.123140 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2023-06-25 01:26:53.126644 (MainThread): SQL status: SELECT 0 in 0.00 seconds
2023-06-25 01:26:53.127677 (MainThread): On master: ROLLBACK
2023-06-25 01:26:53.127677 (MainThread): Using postgres connection "master".
2023-06-25 01:26:53.127677 (MainThread): On master: BEGIN
2023-06-25 01:26:53.128144 (MainThread): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:26:53.128144 (MainThread): On master: COMMIT
2023-06-25 01:26:53.128144 (MainThread): Using postgres connection "master".
2023-06-25 01:26:53.128144 (MainThread): On master: COMMIT
2023-06-25 01:26:53.128662 (MainThread): SQL status: COMMIT in 0.00 seconds
2023-06-25 01:26:53.128662 (MainThread): 21:26:53 | Concurrency: 1 threads (target='dev')
2023-06-25 01:26:53.129144 (MainThread): 21:26:53 | 
2023-06-25 01:26:53.130645 (Thread-1): Began running node model.transform_data.transform_data
2023-06-25 01:26:53.131143 (Thread-1): 21:26:53 | 1 of 1 START view model public.transform_data........................ [RUN]
2023-06-25 01:26:53.131143 (Thread-1): Acquiring new postgres connection "model.transform_data.transform_data".
2023-06-25 01:26:53.131143 (Thread-1): Opening a new connection, currently in state init
2023-06-25 01:26:53.131143 (Thread-1): Compiling model.transform_data.transform_data
2023-06-25 01:26:53.139143 (Thread-1): Writing injected SQL for node "model.transform_data.transform_data"
2023-06-25 01:26:53.140077 (Thread-1): finished collecting timing info
2023-06-25 01:26:53.160081 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:26:53.160081 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */
drop view if exists "main_database"."public"."transform_data__dbt_tmp" cascade
2023-06-25 01:26:53.189260 (Thread-1): SQL status: DROP VIEW in 0.03 seconds
2023-06-25 01:26:53.191265 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:26:53.191265 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */
drop view if exists "main_database"."public"."transform_data__dbt_backup" cascade
2023-06-25 01:26:53.191265 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2023-06-25 01:26:53.192294 (Thread-1): Writing runtime SQL for node "model.transform_data.transform_data"
2023-06-25 01:26:53.192765 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:26:53.192765 (Thread-1): On model.transform_data.transform_data: BEGIN
2023-06-25 01:26:53.193266 (Thread-1): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:26:53.193266 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:26:53.193266 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */

  create view "main_database"."public"."transform_data__dbt_tmp" as (
    -- Create a temporary table to hold the filtered and transformed data
CREATE TEMPORARY TABLE temp_transactions AS
SELECT
  "address",
  "amount",
  "timestamp"
FROM
  public.transactions
WHERE
  "timestamp" > CURRENT_TIMESTAMP - INTERVAL '2 years';

-- Clear existing data from the target table
TRUNCATE TABLE public.transactions;

-- Insert the data from the temporary table into the target table
INSERT INTO public.transactions ("address", "amount", "timestamp")
SELECT
  "address",
  "amount",
  "timestamp"
FROM
  temp_transactions;
  );

2023-06-25 01:26:53.193764 (Thread-1): Postgres error: syntax error at or near "CREATE"
LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
        ^

2023-06-25 01:26:53.193764 (Thread-1): On model.transform_data.transform_data: ROLLBACK
2023-06-25 01:26:53.193764 (Thread-1): finished collecting timing info
2023-06-25 01:26:53.194264 (Thread-1): Database Error in model transform_data (models\transformations\transform_data.sql)
  syntax error at or near "CREATE"
  LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
          ^
  compiled SQL at target\run\transform_data\transformations\transform_data.sql
Traceback (most recent call last):
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\postgres\connections.py", line 46, in exception_handler
    yield
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near "CREATE"
LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
        ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 223, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 166, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 268, in run
    return self.execute(compiled_node, manifest)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 450, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 60, in macro
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\base\impl.py", line 220, in execute
    fetch=fetch
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 116, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 82, in add_query
    return connection, cursor
  File "c:\users\me\appdata\local\programs\python\python37\lib\contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\postgres\connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model transform_data (models\transformations\transform_data.sql)
  syntax error at or near "CREATE"
  LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
          ^
  compiled SQL at target\run\transform_data\transformations\transform_data.sql
2023-06-25 01:26:53.195765 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b4032436-9be2-411b-873f-3c11100cffc2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002687F65AF60>]}
2023-06-25 01:26:53.195765 (Thread-1): 21:26:53 | 1 of 1 ERROR creating view model public.transform_data............... [ERROR in 0.06s]
2023-06-25 01:26:53.196764 (Thread-1): Finished running node model.transform_data.transform_data
2023-06-25 01:26:53.241587 (MainThread): Using postgres connection "master".
2023-06-25 01:26:53.241587 (MainThread): On master: BEGIN
2023-06-25 01:26:53.241587 (MainThread): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:26:53.242086 (MainThread): On master: COMMIT
2023-06-25 01:26:53.242086 (MainThread): Using postgres connection "master".
2023-06-25 01:26:53.242086 (MainThread): On master: COMMIT
2023-06-25 01:26:53.242086 (MainThread): SQL status: COMMIT in 0.00 seconds
2023-06-25 01:26:53.242586 (MainThread): 21:26:53 | 
2023-06-25 01:26:53.242586 (MainThread): 21:26:53 | Finished running 1 view model in 0.28s.
2023-06-25 01:26:53.243086 (MainThread): Connection 'master' was left open.
2023-06-25 01:26:53.243086 (MainThread): On master: Close
2023-06-25 01:26:53.243086 (MainThread): Connection 'list_main_database' was left open.
2023-06-25 01:26:53.243086 (MainThread): On list_main_database: Close
2023-06-25 01:26:53.243086 (MainThread): Connection 'list_main_database_public' was left open.
2023-06-25 01:26:53.243086 (MainThread): On list_main_database_public: Close
2023-06-25 01:26:53.243586 (MainThread): Connection 'model.transform_data.transform_data' was left open.
2023-06-25 01:26:53.243586 (MainThread): On model.transform_data.transform_data: Close
2023-06-25 01:26:53.246087 (MainThread): 
2023-06-25 01:26:53.246087 (MainThread): Completed with 1 error and 0 warnings:
2023-06-25 01:26:53.246588 (MainThread): 
2023-06-25 01:26:53.246588 (MainThread): Database Error in model transform_data (models\transformations\transform_data.sql)
2023-06-25 01:26:53.247087 (MainThread):   syntax error at or near "CREATE"
2023-06-25 01:26:53.247087 (MainThread):   LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
2023-06-25 01:26:53.247087 (MainThread):           ^
2023-06-25 01:26:53.247587 (MainThread):   compiled SQL at target\run\transform_data\transformations\transform_data.sql
2023-06-25 01:26:53.247587 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2023-06-25 01:26:53.247587 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002687F60F4A8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002686F285908>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002687F67E278>]}
2023-06-25 01:26:53.248087 (MainThread): Flushing usage events
2023-06-25 01:27:04.489578 (MainThread): Running with dbt=0.16.0
2023-06-25 01:27:04.526577 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='C:\\Users\\Me\\.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target='dev', test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2023-06-25 01:27:04.527077 (MainThread): Tracking: tracking
2023-06-25 01:27:04.527577 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000290CEC2FFD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000290CEC2F8D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000290CEC2F2B0>]}
2023-06-25 01:27:04.539077 (MainThread): Partial parsing not enabled
2023-06-25 01:27:04.541577 (MainThread): Parsing macros\core.sql
2023-06-25 01:27:04.545077 (MainThread): Parsing macros\adapters\common.sql
2023-06-25 01:27:04.576077 (MainThread): Parsing macros\etc\datetime.sql
2023-06-25 01:27:04.583112 (MainThread): Parsing macros\etc\get_custom_alias.sql
2023-06-25 01:27:04.584109 (MainThread): Parsing macros\etc\get_custom_database.sql
2023-06-25 01:27:04.584607 (MainThread): Parsing macros\etc\get_custom_schema.sql
2023-06-25 01:27:04.586106 (MainThread): Parsing macros\etc\get_relation_comment.sql
2023-06-25 01:27:04.588106 (MainThread): Parsing macros\etc\is_incremental.sql
2023-06-25 01:27:04.589106 (MainThread): Parsing macros\etc\query.sql
2023-06-25 01:27:04.590106 (MainThread): Parsing macros\materializations\helpers.sql
2023-06-25 01:27:04.595608 (MainThread): Parsing macros\materializations\common\merge.sql
2023-06-25 01:27:04.605105 (MainThread): Parsing macros\materializations\incremental\helpers.sql
2023-06-25 01:27:04.606606 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2023-06-25 01:27:04.611113 (MainThread): Parsing macros\materializations\seed\seed.sql
2023-06-25 01:27:04.626576 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2023-06-25 01:27:04.651076 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2023-06-25 01:27:04.652076 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2023-06-25 01:27:04.664576 (MainThread): Parsing macros\materializations\table\table.sql
2023-06-25 01:27:04.669576 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2023-06-25 01:27:04.673076 (MainThread): Parsing macros\materializations\view\view.sql
2023-06-25 01:27:04.677576 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2023-06-25 01:27:04.679076 (MainThread): Parsing macros\schema_tests\not_null.sql
2023-06-25 01:27:04.680076 (MainThread): Parsing macros\schema_tests\relationships.sql
2023-06-25 01:27:04.680576 (MainThread): Parsing macros\schema_tests\unique.sql
2023-06-25 01:27:04.682076 (MainThread): Parsing macros\adapters.sql
2023-06-25 01:27:04.694576 (MainThread): Parsing macros\catalog.sql
2023-06-25 01:27:04.696576 (MainThread): Parsing macros\relations.sql
2023-06-25 01:27:04.697576 (MainThread): Parsing macros\materializations\snapshot_merge.sql
2023-06-25 01:27:04.710076 (MainThread): Partial parsing not enabled
2023-06-25 01:27:04.728577 (MainThread): Acquiring new postgres connection "model.transform_data.transform_data".
2023-06-25 01:27:04.728577 (MainThread): Opening a new connection, currently in state init
2023-06-25 01:27:04.943577 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:27:04.943577 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:27:04.943577 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:27:04.944077 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:27:04.944077 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:27:04.944077 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:27:04.944077 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:27:04.975577 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:27:04.975577 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:27:05.098577 (MainThread): scipy not found, skipping conversion test.
2023-06-25 01:27:05.099577 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2023-06-25 01:27:05.099577 (MainThread): Found 1 model, 0 tests, 0 snapshots, 0 analyses, 127 macros, 0 operations, 0 seed files, 0 sources
2023-06-25 01:27:05.100577 (MainThread): 
2023-06-25 01:27:05.100577 (MainThread): Acquiring new postgres connection "master".
2023-06-25 01:27:05.100577 (MainThread): Opening a new connection, currently in state init
2023-06-25 01:27:05.104577 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_main_database".
2023-06-25 01:27:05.104577 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2023-06-25 01:27:05.159610 (ThreadPoolExecutor-0_0): Using postgres connection "list_main_database".
2023-06-25 01:27:05.159610 (ThreadPoolExecutor-0_0): On list_main_database: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "list_main_database"} */

    select distinct nspname from pg_namespace
  
2023-06-25 01:27:05.191078 (ThreadPoolExecutor-0_0): SQL status: SELECT 4 in 0.03 seconds
2023-06-25 01:27:05.196077 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_main_database_public".
2023-06-25 01:27:05.196577 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2023-06-25 01:27:05.197107 (ThreadPoolExecutor-1_0): Using postgres connection "list_main_database_public".
2023-06-25 01:27:05.197614 (ThreadPoolExecutor-1_0): On list_main_database_public: BEGIN
2023-06-25 01:27:05.228077 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.03 seconds
2023-06-25 01:27:05.228077 (ThreadPoolExecutor-1_0): Using postgres connection "list_main_database_public".
2023-06-25 01:27:05.228077 (ThreadPoolExecutor-1_0): On list_main_database_public: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "list_main_database_public"} */
select
      'main_database' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'main_database' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2023-06-25 01:27:05.231077 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2023-06-25 01:27:05.232106 (ThreadPoolExecutor-1_0): On list_main_database_public: ROLLBACK
2023-06-25 01:27:05.237577 (MainThread): Using postgres connection "master".
2023-06-25 01:27:05.238078 (MainThread): On master: BEGIN
2023-06-25 01:27:05.267077 (MainThread): SQL status: BEGIN in 0.03 seconds
2023-06-25 01:27:05.267077 (MainThread): Using postgres connection "master".
2023-06-25 01:27:05.267077 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2023-06-25 01:27:05.270577 (MainThread): SQL status: SELECT 0 in 0.00 seconds
2023-06-25 01:27:05.271077 (MainThread): On master: ROLLBACK
2023-06-25 01:27:05.271576 (MainThread): Using postgres connection "master".
2023-06-25 01:27:05.271576 (MainThread): On master: BEGIN
2023-06-25 01:27:05.272077 (MainThread): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:27:05.272077 (MainThread): On master: COMMIT
2023-06-25 01:27:05.272077 (MainThread): Using postgres connection "master".
2023-06-25 01:27:05.272077 (MainThread): On master: COMMIT
2023-06-25 01:27:05.272077 (MainThread): SQL status: COMMIT in 0.00 seconds
2023-06-25 01:27:05.272577 (MainThread): 21:27:05 | Concurrency: 1 threads (target='dev')
2023-06-25 01:27:05.272577 (MainThread): 21:27:05 | 
2023-06-25 01:27:05.274077 (Thread-1): Began running node model.transform_data.transform_data
2023-06-25 01:27:05.274077 (Thread-1): 21:27:05 | 1 of 1 START view model public.transform_data........................ [RUN]
2023-06-25 01:27:05.274577 (Thread-1): Acquiring new postgres connection "model.transform_data.transform_data".
2023-06-25 01:27:05.274577 (Thread-1): Opening a new connection, currently in state init
2023-06-25 01:27:05.274577 (Thread-1): Compiling model.transform_data.transform_data
2023-06-25 01:27:05.282576 (Thread-1): Writing injected SQL for node "model.transform_data.transform_data"
2023-06-25 01:27:05.283076 (Thread-1): finished collecting timing info
2023-06-25 01:27:05.303106 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:27:05.303106 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */
drop view if exists "main_database"."public"."transform_data__dbt_tmp" cascade
2023-06-25 01:27:05.333302 (Thread-1): SQL status: DROP VIEW in 0.03 seconds
2023-06-25 01:27:05.334801 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:27:05.335301 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */
drop view if exists "main_database"."public"."transform_data__dbt_backup" cascade
2023-06-25 01:27:05.335435 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2023-06-25 01:27:05.336470 (Thread-1): Writing runtime SQL for node "model.transform_data.transform_data"
2023-06-25 01:27:05.337002 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:27:05.337002 (Thread-1): On model.transform_data.transform_data: BEGIN
2023-06-25 01:27:05.337002 (Thread-1): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:27:05.337002 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:27:05.337507 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */

  create view "main_database"."public"."transform_data__dbt_tmp" as (
    -- Create a temporary table to hold the filtered and transformed data
CREATE TEMPORARY TABLE temp_transactions AS
SELECT
  "address",
  "amount",
  "timestamp"
FROM
  public.transactions
WHERE
  "timestamp" > CURRENT_TIMESTAMP - INTERVAL '2 years';

-- Clear existing data from the target table
TRUNCATE TABLE public.transactions;

-- Insert the data from the temporary table into the target table
INSERT INTO public.transactions ("address", "amount", "timestamp")
SELECT
  "address",
  "amount",
  "timestamp"
FROM
  temp_transactions;
  );

2023-06-25 01:27:05.337507 (Thread-1): Postgres error: syntax error at or near "CREATE"
LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
        ^

2023-06-25 01:27:05.337507 (Thread-1): On model.transform_data.transform_data: ROLLBACK
2023-06-25 01:27:05.338051 (Thread-1): finished collecting timing info
2023-06-25 01:27:05.338051 (Thread-1): Database Error in model transform_data (models\transformations\transform_data.sql)
  syntax error at or near "CREATE"
  LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
          ^
  compiled SQL at target\run\transform_data\transformations\transform_data.sql
Traceback (most recent call last):
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\postgres\connections.py", line 46, in exception_handler
    yield
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near "CREATE"
LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
        ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 223, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 166, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 268, in run
    return self.execute(compiled_node, manifest)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 450, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 60, in macro
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\base\impl.py", line 220, in execute
    fetch=fetch
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 116, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 82, in add_query
    return connection, cursor
  File "c:\users\me\appdata\local\programs\python\python37\lib\contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\postgres\connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model transform_data (models\transformations\transform_data.sql)
  syntax error at or near "CREATE"
  LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
          ^
  compiled SQL at target\run\transform_data\transformations\transform_data.sql
2023-06-25 01:27:05.340087 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd220daa9-046c-454e-8e03-2ea552c07ec5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000290F722EEF0>]}
2023-06-25 01:27:05.340087 (Thread-1): 21:27:05 | 1 of 1 ERROR creating view model public.transform_data............... [ERROR in 0.07s]
2023-06-25 01:27:05.340556 (Thread-1): Finished running node model.transform_data.transform_data
2023-06-25 01:27:05.387755 (MainThread): Using postgres connection "master".
2023-06-25 01:27:05.388256 (MainThread): On master: BEGIN
2023-06-25 01:27:05.388256 (MainThread): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:27:05.388256 (MainThread): On master: COMMIT
2023-06-25 01:27:05.388256 (MainThread): Using postgres connection "master".
2023-06-25 01:27:05.388256 (MainThread): On master: COMMIT
2023-06-25 01:27:05.388756 (MainThread): SQL status: COMMIT in 0.00 seconds
2023-06-25 01:27:05.388756 (MainThread): 21:27:05 | 
2023-06-25 01:27:05.389256 (MainThread): 21:27:05 | Finished running 1 view model in 0.29s.
2023-06-25 01:27:05.389256 (MainThread): Connection 'master' was left open.
2023-06-25 01:27:05.389256 (MainThread): On master: Close
2023-06-25 01:27:05.389256 (MainThread): Connection 'list_main_database' was left open.
2023-06-25 01:27:05.389756 (MainThread): On list_main_database: Close
2023-06-25 01:27:05.389756 (MainThread): Connection 'list_main_database_public' was left open.
2023-06-25 01:27:05.389756 (MainThread): On list_main_database_public: Close
2023-06-25 01:27:05.389756 (MainThread): Connection 'model.transform_data.transform_data' was left open.
2023-06-25 01:27:05.389756 (MainThread): On model.transform_data.transform_data: Close
2023-06-25 01:27:05.392255 (MainThread): 
2023-06-25 01:27:05.392255 (MainThread): Completed with 1 error and 0 warnings:
2023-06-25 01:27:05.392756 (MainThread): 
2023-06-25 01:27:05.392756 (MainThread): Database Error in model transform_data (models\transformations\transform_data.sql)
2023-06-25 01:27:05.393255 (MainThread):   syntax error at or near "CREATE"
2023-06-25 01:27:05.393255 (MainThread):   LINE 5: CREATE TEMPORARY TABLE temp_transactions AS
2023-06-25 01:27:05.393255 (MainThread):           ^
2023-06-25 01:27:05.393255 (MainThread):   compiled SQL at target\run\transform_data\transformations\transform_data.sql
2023-06-25 01:27:05.393755 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2023-06-25 01:27:05.393755 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000290CEE56940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000290F71E2AC8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000290F71E29B0>]}
2023-06-25 01:27:05.393755 (MainThread): Flushing usage events
2023-06-25 01:28:33.627731 (MainThread): Running with dbt=0.16.0
2023-06-25 01:28:33.670231 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=['+transformations.transform_data'], partial_parse=None, profile=None, profiles_dir='C:\\Users\\Me\\.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2023-06-25 01:28:33.670732 (MainThread): Tracking: tracking
2023-06-25 01:28:33.671239 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000260AD7E22B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000260AD7EDFD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000260AD7ED6A0>]}
2023-06-25 01:28:33.682731 (MainThread): Partial parsing not enabled
2023-06-25 01:28:33.685232 (MainThread): Parsing macros\core.sql
2023-06-25 01:28:33.688732 (MainThread): Parsing macros\adapters\common.sql
2023-06-25 01:28:33.721735 (MainThread): Parsing macros\etc\datetime.sql
2023-06-25 01:28:33.729762 (MainThread): Parsing macros\etc\get_custom_alias.sql
2023-06-25 01:28:33.730761 (MainThread): Parsing macros\etc\get_custom_database.sql
2023-06-25 01:28:33.731263 (MainThread): Parsing macros\etc\get_custom_schema.sql
2023-06-25 01:28:33.733263 (MainThread): Parsing macros\etc\get_relation_comment.sql
2023-06-25 01:28:33.734762 (MainThread): Parsing macros\etc\is_incremental.sql
2023-06-25 01:28:33.736234 (MainThread): Parsing macros\etc\query.sql
2023-06-25 01:28:33.737234 (MainThread): Parsing macros\materializations\helpers.sql
2023-06-25 01:28:33.743232 (MainThread): Parsing macros\materializations\common\merge.sql
2023-06-25 01:28:33.753232 (MainThread): Parsing macros\materializations\incremental\helpers.sql
2023-06-25 01:28:33.754732 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2023-06-25 01:28:33.759232 (MainThread): Parsing macros\materializations\seed\seed.sql
2023-06-25 01:28:33.776732 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2023-06-25 01:28:33.802232 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2023-06-25 01:28:33.803732 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2023-06-25 01:28:33.820732 (MainThread): Parsing macros\materializations\table\table.sql
2023-06-25 01:28:33.829733 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2023-06-25 01:28:33.833233 (MainThread): Parsing macros\materializations\view\view.sql
2023-06-25 01:28:33.838734 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2023-06-25 01:28:33.840234 (MainThread): Parsing macros\schema_tests\not_null.sql
2023-06-25 01:28:33.841234 (MainThread): Parsing macros\schema_tests\relationships.sql
2023-06-25 01:28:33.842233 (MainThread): Parsing macros\schema_tests\unique.sql
2023-06-25 01:28:33.843262 (MainThread): Parsing macros\adapters.sql
2023-06-25 01:28:33.856262 (MainThread): Parsing macros\catalog.sql
2023-06-25 01:28:33.858261 (MainThread): Parsing macros\relations.sql
2023-06-25 01:28:33.859269 (MainThread): Parsing macros\materializations\snapshot_merge.sql
2023-06-25 01:28:33.872233 (MainThread): Partial parsing not enabled
2023-06-25 01:28:33.890761 (MainThread): Acquiring new postgres connection "model.transform_data.transform_data".
2023-06-25 01:28:33.890761 (MainThread): Opening a new connection, currently in state init
2023-06-25 01:28:34.036732 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:28:34.037231 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:28:34.037231 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:28:34.037231 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:28:34.037231 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:28:34.037231 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:28:34.037231 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:28:34.038735 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:28:34.039233 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:28:34.040232 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:28:34.041732 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:28:34.043232 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:28:34.043733 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:28:34.044733 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:28:34.045232 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:28:34.045732 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:28:34.046732 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:28:34.047732 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:28:34.048233 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:28:34.049233 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:28:34.050231 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:28:34.052731 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:28:34.056733 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:28:34.057232 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:28:34.058733 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:28:34.059732 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:28:34.060232 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:28:34.067732 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:28:34.071231 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:28:34.071231 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:28:34.073233 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:28:34.088733 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:28:34.089732 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:28:34.091732 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:28:34.127732 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:28:34.131732 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:28:34.132231 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:28:34.144732 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:28:34.147732 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:28:34.163232 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:28:34.164232 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:28:34.177231 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:28:34.194231 (MainThread): numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject
2023-06-25 01:28:34.195231 (MainThread): scipy not found, skipping conversion test.
2023-06-25 01:28:34.196232 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2023-06-25 01:28:34.196232 (MainThread): Found 1 model, 0 tests, 0 snapshots, 0 analyses, 127 macros, 0 operations, 0 seed files, 0 sources
2023-06-25 01:28:34.197232 (MainThread): 
2023-06-25 01:28:34.197232 (MainThread): Acquiring new postgres connection "master".
2023-06-25 01:28:34.197232 (MainThread): Opening a new connection, currently in state init
2023-06-25 01:28:34.201232 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_main_database".
2023-06-25 01:28:34.201232 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2023-06-25 01:28:34.257732 (ThreadPoolExecutor-0_0): Using postgres connection "list_main_database".
2023-06-25 01:28:34.257732 (ThreadPoolExecutor-0_0): On list_main_database: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "list_main_database"} */

    select distinct nspname from pg_namespace
  
2023-06-25 01:28:34.291734 (ThreadPoolExecutor-0_0): SQL status: SELECT 4 in 0.03 seconds
2023-06-25 01:28:34.297233 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_main_database_public".
2023-06-25 01:28:34.297233 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2023-06-25 01:28:34.298231 (ThreadPoolExecutor-1_0): Using postgres connection "list_main_database_public".
2023-06-25 01:28:34.298231 (ThreadPoolExecutor-1_0): On list_main_database_public: BEGIN
2023-06-25 01:28:34.328232 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.03 seconds
2023-06-25 01:28:34.328232 (ThreadPoolExecutor-1_0): Using postgres connection "list_main_database_public".
2023-06-25 01:28:34.328732 (ThreadPoolExecutor-1_0): On list_main_database_public: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "list_main_database_public"} */
select
      'main_database' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'main_database' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2023-06-25 01:28:34.331399 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2023-06-25 01:28:34.332428 (ThreadPoolExecutor-1_0): On list_main_database_public: ROLLBACK
2023-06-25 01:28:34.337898 (MainThread): Using postgres connection "master".
2023-06-25 01:28:34.338399 (MainThread): On master: BEGIN
2023-06-25 01:28:34.369399 (MainThread): SQL status: BEGIN in 0.03 seconds
2023-06-25 01:28:34.369399 (MainThread): Using postgres connection "master".
2023-06-25 01:28:34.369399 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2023-06-25 01:28:34.372899 (MainThread): SQL status: SELECT 0 in 0.00 seconds
2023-06-25 01:28:34.373399 (MainThread): On master: ROLLBACK
2023-06-25 01:28:34.373898 (MainThread): Using postgres connection "master".
2023-06-25 01:28:34.373898 (MainThread): On master: BEGIN
2023-06-25 01:28:34.373898 (MainThread): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:28:34.374399 (MainThread): On master: COMMIT
2023-06-25 01:28:34.374399 (MainThread): Using postgres connection "master".
2023-06-25 01:28:34.374399 (MainThread): On master: COMMIT
2023-06-25 01:28:34.374399 (MainThread): SQL status: COMMIT in 0.00 seconds
2023-06-25 01:28:34.374399 (MainThread): 21:28:34 | Concurrency: 1 threads (target='dev')
2023-06-25 01:28:34.374899 (MainThread): 21:28:34 | 
2023-06-25 01:28:34.376398 (Thread-1): Began running node model.transform_data.transform_data
2023-06-25 01:28:34.376398 (Thread-1): 21:28:34 | 1 of 1 START view model public.transform_data........................ [RUN]
2023-06-25 01:28:34.376398 (Thread-1): Acquiring new postgres connection "model.transform_data.transform_data".
2023-06-25 01:28:34.376398 (Thread-1): Opening a new connection, currently in state init
2023-06-25 01:28:34.376898 (Thread-1): Compiling model.transform_data.transform_data
2023-06-25 01:28:34.384398 (Thread-1): Writing injected SQL for node "model.transform_data.transform_data"
2023-06-25 01:28:34.385399 (Thread-1): finished collecting timing info
2023-06-25 01:28:34.405898 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:28:34.405898 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */
drop view if exists "main_database"."public"."transform_data__dbt_tmp" cascade
2023-06-25 01:28:34.440400 (Thread-1): SQL status: DROP VIEW in 0.03 seconds
2023-06-25 01:28:34.441928 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:28:34.441928 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */
drop view if exists "main_database"."public"."transform_data__dbt_backup" cascade
2023-06-25 01:28:34.441928 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2023-06-25 01:28:34.442928 (Thread-1): Writing runtime SQL for node "model.transform_data.transform_data"
2023-06-25 01:28:34.443399 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:28:34.443399 (Thread-1): On model.transform_data.transform_data: BEGIN
2023-06-25 01:28:34.443900 (Thread-1): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:28:34.443900 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:28:34.443900 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */

  create view "main_database"."public"."transform_data__dbt_tmp" as (
    INSERT INTO public.transactions ("address", "amount", "timestamp")
SELECT
  "address",
  "amount",
  "timestamp"
FROM
  public.transactions
WHERE
  "timestamp" > CURRENT_TIMESTAMP - INTERVAL '2 years';
  );

2023-06-25 01:28:34.444399 (Thread-1): Postgres error: syntax error at or near "INSERT"
LINE 4:     INSERT INTO public.transactions ("address", "amount", "t...
            ^

2023-06-25 01:28:34.444399 (Thread-1): On model.transform_data.transform_data: ROLLBACK
2023-06-25 01:28:34.444399 (Thread-1): finished collecting timing info
2023-06-25 01:28:34.444899 (Thread-1): Database Error in model transform_data (models\transformations\transform_data.sql)
  syntax error at or near "INSERT"
  LINE 4:     INSERT INTO public.transactions ("address", "amount", "t...
              ^
  compiled SQL at target\run\transform_data\transformations\transform_data.sql
Traceback (most recent call last):
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\postgres\connections.py", line 46, in exception_handler
    yield
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near "INSERT"
LINE 4:     INSERT INTO public.transactions ("address", "amount", "t...
            ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 223, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 166, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 268, in run
    return self.execute(compiled_node, manifest)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 450, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 60, in macro
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\base\impl.py", line 220, in execute
    fetch=fetch
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 116, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 82, in add_query
    return connection, cursor
  File "c:\users\me\appdata\local\programs\python\python37\lib\contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\postgres\connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model transform_data (models\transformations\transform_data.sql)
  syntax error at or near "INSERT"
  LINE 4:     INSERT INTO public.transactions ("address", "amount", "t...
              ^
  compiled SQL at target\run\transform_data\transformations\transform_data.sql
2023-06-25 01:28:34.446399 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6700d266-97c5-4427-af16-d974366fea32', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000260B1443E48>]}
2023-06-25 01:28:34.446399 (Thread-1): 21:28:34 | 1 of 1 ERROR creating view model public.transform_data............... [ERROR in 0.07s]
2023-06-25 01:28:34.446898 (Thread-1): Finished running node model.transform_data.transform_data
2023-06-25 01:28:34.491399 (MainThread): Using postgres connection "master".
2023-06-25 01:28:34.491399 (MainThread): On master: BEGIN
2023-06-25 01:28:34.491898 (MainThread): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:28:34.491898 (MainThread): On master: COMMIT
2023-06-25 01:28:34.491898 (MainThread): Using postgres connection "master".
2023-06-25 01:28:34.491898 (MainThread): On master: COMMIT
2023-06-25 01:28:34.491898 (MainThread): SQL status: COMMIT in 0.00 seconds
2023-06-25 01:28:34.492399 (MainThread): 21:28:34 | 
2023-06-25 01:28:34.492399 (MainThread): 21:28:34 | Finished running 1 view model in 0.30s.
2023-06-25 01:28:34.492399 (MainThread): Connection 'master' was left open.
2023-06-25 01:28:34.492399 (MainThread): On master: Close
2023-06-25 01:28:34.492399 (MainThread): Connection 'list_main_database' was left open.
2023-06-25 01:28:34.492399 (MainThread): On list_main_database: Close
2023-06-25 01:28:34.492899 (MainThread): Connection 'list_main_database_public' was left open.
2023-06-25 01:28:34.492899 (MainThread): On list_main_database_public: Close
2023-06-25 01:28:34.492899 (MainThread): Connection 'model.transform_data.transform_data' was left open.
2023-06-25 01:28:34.492899 (MainThread): On model.transform_data.transform_data: Close
2023-06-25 01:28:34.494899 (MainThread): 
2023-06-25 01:28:34.495399 (MainThread): Completed with 1 error and 0 warnings:
2023-06-25 01:28:34.495399 (MainThread): 
2023-06-25 01:28:34.495399 (MainThread): Database Error in model transform_data (models\transformations\transform_data.sql)
2023-06-25 01:28:34.495399 (MainThread):   syntax error at or near "INSERT"
2023-06-25 01:28:34.495399 (MainThread):   LINE 4:     INSERT INTO public.transactions ("address", "amount", "t...
2023-06-25 01:28:34.495399 (MainThread):               ^
2023-06-25 01:28:34.495399 (MainThread):   compiled SQL at target\run\transform_data\transformations\transform_data.sql
2023-06-25 01:28:34.495399 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2023-06-25 01:28:34.495898 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000260B1451438>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000260B140AEB8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000260B1748BA8>]}
2023-06-25 01:28:34.495898 (MainThread): Flushing usage events
2023-06-25 01:29:34.319647 (MainThread): Running with dbt=0.16.0
2023-06-25 01:29:34.353147 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='C:\\Users\\Me\\.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target='dev', test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2023-06-25 01:29:34.353647 (MainThread): Tracking: tracking
2023-06-25 01:29:34.354147 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000215EFAA0358>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000215EDDA8278>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000215EFA91DD8>]}
2023-06-25 01:29:34.365647 (MainThread): Partial parsing not enabled
2023-06-25 01:29:34.368148 (MainThread): Parsing macros\core.sql
2023-06-25 01:29:34.371147 (MainThread): Parsing macros\adapters\common.sql
2023-06-25 01:29:34.402647 (MainThread): Parsing macros\etc\datetime.sql
2023-06-25 01:29:34.409147 (MainThread): Parsing macros\etc\get_custom_alias.sql
2023-06-25 01:29:34.409647 (MainThread): Parsing macros\etc\get_custom_database.sql
2023-06-25 01:29:34.410647 (MainThread): Parsing macros\etc\get_custom_schema.sql
2023-06-25 01:29:34.412147 (MainThread): Parsing macros\etc\get_relation_comment.sql
2023-06-25 01:29:34.413647 (MainThread): Parsing macros\etc\is_incremental.sql
2023-06-25 01:29:34.415148 (MainThread): Parsing macros\etc\query.sql
2023-06-25 01:29:34.416148 (MainThread): Parsing macros\materializations\helpers.sql
2023-06-25 01:29:34.421647 (MainThread): Parsing macros\materializations\common\merge.sql
2023-06-25 01:29:34.431650 (MainThread): Parsing macros\materializations\incremental\helpers.sql
2023-06-25 01:29:34.432649 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2023-06-25 01:29:34.437651 (MainThread): Parsing macros\materializations\seed\seed.sql
2023-06-25 01:29:34.453150 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2023-06-25 01:29:34.477650 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2023-06-25 01:29:34.479150 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2023-06-25 01:29:34.491650 (MainThread): Parsing macros\materializations\table\table.sql
2023-06-25 01:29:34.496651 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2023-06-25 01:29:34.500150 (MainThread): Parsing macros\materializations\view\view.sql
2023-06-25 01:29:34.504650 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2023-06-25 01:29:34.506150 (MainThread): Parsing macros\schema_tests\not_null.sql
2023-06-25 01:29:34.507150 (MainThread): Parsing macros\schema_tests\relationships.sql
2023-06-25 01:29:34.508150 (MainThread): Parsing macros\schema_tests\unique.sql
2023-06-25 01:29:34.509150 (MainThread): Parsing macros\adapters.sql
2023-06-25 01:29:34.522150 (MainThread): Parsing macros\catalog.sql
2023-06-25 01:29:34.523650 (MainThread): Parsing macros\relations.sql
2023-06-25 01:29:34.525150 (MainThread): Parsing macros\materializations\snapshot_merge.sql
2023-06-25 01:29:34.537650 (MainThread): Partial parsing not enabled
2023-06-25 01:29:34.556150 (MainThread): Acquiring new postgres connection "model.transform_data.transform_data".
2023-06-25 01:29:34.556150 (MainThread): Opening a new connection, currently in state init
2023-06-25 01:29:34.766147 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:29:34.766647 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:29:34.766647 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:29:34.766647 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:29:34.766647 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:29:34.766647 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:29:34.766647 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:29:34.798147 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:29:34.798147 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:29:34.917147 (MainThread): scipy not found, skipping conversion test.
2023-06-25 01:29:34.918147 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2023-06-25 01:29:34.918648 (MainThread): Found 1 model, 0 tests, 0 snapshots, 0 analyses, 127 macros, 0 operations, 0 seed files, 0 sources
2023-06-25 01:29:34.919149 (MainThread): 
2023-06-25 01:29:34.919647 (MainThread): Acquiring new postgres connection "master".
2023-06-25 01:29:34.919647 (MainThread): Opening a new connection, currently in state init
2023-06-25 01:29:34.923147 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_main_database".
2023-06-25 01:29:34.923647 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2023-06-25 01:29:34.979147 (ThreadPoolExecutor-0_0): Using postgres connection "list_main_database".
2023-06-25 01:29:34.979147 (ThreadPoolExecutor-0_0): On list_main_database: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "list_main_database"} */

    select distinct nspname from pg_namespace
  
2023-06-25 01:29:35.009147 (ThreadPoolExecutor-0_0): SQL status: SELECT 4 in 0.03 seconds
2023-06-25 01:29:35.014147 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_main_database_public".
2023-06-25 01:29:35.014147 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2023-06-25 01:29:35.015147 (ThreadPoolExecutor-1_0): Using postgres connection "list_main_database_public".
2023-06-25 01:29:35.015147 (ThreadPoolExecutor-1_0): On list_main_database_public: BEGIN
2023-06-25 01:29:35.043647 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.03 seconds
2023-06-25 01:29:35.044147 (ThreadPoolExecutor-1_0): Using postgres connection "list_main_database_public".
2023-06-25 01:29:35.044147 (ThreadPoolExecutor-1_0): On list_main_database_public: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "list_main_database_public"} */
select
      'main_database' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'main_database' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2023-06-25 01:29:35.046647 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2023-06-25 01:29:35.047647 (ThreadPoolExecutor-1_0): On list_main_database_public: ROLLBACK
2023-06-25 01:29:35.053647 (MainThread): Using postgres connection "master".
2023-06-25 01:29:35.053647 (MainThread): On master: BEGIN
2023-06-25 01:29:35.082147 (MainThread): SQL status: BEGIN in 0.03 seconds
2023-06-25 01:29:35.082147 (MainThread): Using postgres connection "master".
2023-06-25 01:29:35.082147 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2023-06-25 01:29:35.085647 (MainThread): SQL status: SELECT 0 in 0.00 seconds
2023-06-25 01:29:35.086147 (MainThread): On master: ROLLBACK
2023-06-25 01:29:35.086647 (MainThread): Using postgres connection "master".
2023-06-25 01:29:35.086647 (MainThread): On master: BEGIN
2023-06-25 01:29:35.086647 (MainThread): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:29:35.087147 (MainThread): On master: COMMIT
2023-06-25 01:29:35.087147 (MainThread): Using postgres connection "master".
2023-06-25 01:29:35.087147 (MainThread): On master: COMMIT
2023-06-25 01:29:35.087147 (MainThread): SQL status: COMMIT in 0.00 seconds
2023-06-25 01:29:35.087647 (MainThread): 21:29:35 | Concurrency: 1 threads (target='dev')
2023-06-25 01:29:35.087647 (MainThread): 21:29:35 | 
2023-06-25 01:29:35.089647 (Thread-1): Began running node model.transform_data.transform_data
2023-06-25 01:29:35.089647 (Thread-1): 21:29:35 | 1 of 1 START view model public.transform_data........................ [RUN]
2023-06-25 01:29:35.090147 (Thread-1): Acquiring new postgres connection "model.transform_data.transform_data".
2023-06-25 01:29:35.090147 (Thread-1): Opening a new connection, currently in state init
2023-06-25 01:29:35.090147 (Thread-1): Compiling model.transform_data.transform_data
2023-06-25 01:29:35.098147 (Thread-1): Writing injected SQL for node "model.transform_data.transform_data"
2023-06-25 01:29:35.098647 (Thread-1): finished collecting timing info
2023-06-25 01:29:35.118647 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:29:35.119147 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */
drop view if exists "main_database"."public"."transform_data__dbt_tmp" cascade
2023-06-25 01:29:35.149279 (Thread-1): SQL status: DROP VIEW in 0.03 seconds
2023-06-25 01:29:35.150779 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:29:35.151279 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */
drop view if exists "main_database"."public"."transform_data__dbt_backup" cascade
2023-06-25 01:29:35.151279 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2023-06-25 01:29:35.152280 (Thread-1): Writing runtime SQL for node "model.transform_data.transform_data"
2023-06-25 01:29:35.152780 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:29:35.152780 (Thread-1): On model.transform_data.transform_data: BEGIN
2023-06-25 01:29:35.153280 (Thread-1): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:29:35.153280 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:29:35.153280 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */

  create view "main_database"."public"."transform_data__dbt_tmp" as (
    INSERT INTO public.transactions ("address", "amount", "timestamp")
SELECT
  "address",
  "amount",
  "timestamp"
FROM
  public.transactions
WHERE
  "timestamp" > CURRENT_TIMESTAMP - INTERVAL '2 years';
  );

2023-06-25 01:29:35.153280 (Thread-1): Postgres error: syntax error at or near "INSERT"
LINE 4:     INSERT INTO public.transactions ("address", "amount", "t...
            ^

2023-06-25 01:29:35.153779 (Thread-1): On model.transform_data.transform_data: ROLLBACK
2023-06-25 01:29:35.153779 (Thread-1): finished collecting timing info
2023-06-25 01:29:35.154279 (Thread-1): Database Error in model transform_data (models\transformations\transform_data.sql)
  syntax error at or near "INSERT"
  LINE 4:     INSERT INTO public.transactions ("address", "amount", "t...
              ^
  compiled SQL at target\run\transform_data\transformations\transform_data.sql
Traceback (most recent call last):
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\postgres\connections.py", line 46, in exception_handler
    yield
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near "INSERT"
LINE 4:     INSERT INTO public.transactions ("address", "amount", "t...
            ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 223, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 166, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 268, in run
    return self.execute(compiled_node, manifest)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 450, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 60, in macro
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\base\impl.py", line 220, in execute
    fetch=fetch
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 116, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 82, in add_query
    return connection, cursor
  File "c:\users\me\appdata\local\programs\python\python37\lib\contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\postgres\connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model transform_data (models\transformations\transform_data.sql)
  syntax error at or near "INSERT"
  LINE 4:     INSERT INTO public.transactions ("address", "amount", "t...
              ^
  compiled SQL at target\run\transform_data\transformations\transform_data.sql
2023-06-25 01:29:35.155779 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '45a16e3e-8b00-4cd6-8fe3-d90d2e4a6cf8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000215980AB4E0>]}
2023-06-25 01:29:35.155779 (Thread-1): 21:29:35 | 1 of 1 ERROR creating view model public.transform_data............... [ERROR in 0.07s]
2023-06-25 01:29:35.156779 (Thread-1): Finished running node model.transform_data.transform_data
2023-06-25 01:29:35.204617 (MainThread): Using postgres connection "master".
2023-06-25 01:29:35.204617 (MainThread): On master: BEGIN
2023-06-25 01:29:35.204617 (MainThread): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:29:35.205116 (MainThread): On master: COMMIT
2023-06-25 01:29:35.205116 (MainThread): Using postgres connection "master".
2023-06-25 01:29:35.205116 (MainThread): On master: COMMIT
2023-06-25 01:29:35.205116 (MainThread): SQL status: COMMIT in 0.00 seconds
2023-06-25 01:29:35.205616 (MainThread): 21:29:35 | 
2023-06-25 01:29:35.205616 (MainThread): 21:29:35 | Finished running 1 view model in 0.29s.
2023-06-25 01:29:35.206117 (MainThread): Connection 'master' was left open.
2023-06-25 01:29:35.206117 (MainThread): On master: Close
2023-06-25 01:29:35.206117 (MainThread): Connection 'list_main_database' was left open.
2023-06-25 01:29:35.206117 (MainThread): On list_main_database: Close
2023-06-25 01:29:35.206117 (MainThread): Connection 'list_main_database_public' was left open.
2023-06-25 01:29:35.206117 (MainThread): On list_main_database_public: Close
2023-06-25 01:29:35.206616 (MainThread): Connection 'model.transform_data.transform_data' was left open.
2023-06-25 01:29:35.206616 (MainThread): On model.transform_data.transform_data: Close
2023-06-25 01:29:35.209045 (MainThread): 
2023-06-25 01:29:35.209045 (MainThread): Completed with 1 error and 0 warnings:
2023-06-25 01:29:35.209549 (MainThread): 
2023-06-25 01:29:35.209549 (MainThread): Database Error in model transform_data (models\transformations\transform_data.sql)
2023-06-25 01:29:35.210050 (MainThread):   syntax error at or near "INSERT"
2023-06-25 01:29:35.210050 (MainThread):   LINE 4:     INSERT INTO public.transactions ("address", "amount", "t...
2023-06-25 01:29:35.210549 (MainThread):               ^
2023-06-25 01:29:35.210549 (MainThread):   compiled SQL at target\run\transform_data\transformations\transform_data.sql
2023-06-25 01:29:35.210549 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2023-06-25 01:29:35.211048 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021598049898>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000215EFCC7CC0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000215980BF2B0>]}
2023-06-25 01:29:35.211048 (MainThread): Flushing usage events
2023-06-25 01:29:38.148489 (MainThread): Running with dbt=0.16.0
2023-06-25 01:29:38.182489 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='C:\\Users\\Me\\.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2023-06-25 01:29:38.182989 (MainThread): Tracking: tracking
2023-06-25 01:29:38.183488 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000259D5A2C0B8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000259D5A2CBE0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000259D5960438>]}
2023-06-25 01:29:38.194988 (MainThread): Partial parsing not enabled
2023-06-25 01:29:38.196989 (MainThread): Parsing macros\core.sql
2023-06-25 01:29:38.200489 (MainThread): Parsing macros\adapters\common.sql
2023-06-25 01:29:38.231488 (MainThread): Parsing macros\etc\datetime.sql
2023-06-25 01:29:38.238489 (MainThread): Parsing macros\etc\get_custom_alias.sql
2023-06-25 01:29:38.239489 (MainThread): Parsing macros\etc\get_custom_database.sql
2023-06-25 01:29:38.239988 (MainThread): Parsing macros\etc\get_custom_schema.sql
2023-06-25 01:29:38.241489 (MainThread): Parsing macros\etc\get_relation_comment.sql
2023-06-25 01:29:38.243489 (MainThread): Parsing macros\etc\is_incremental.sql
2023-06-25 01:29:38.244488 (MainThread): Parsing macros\etc\query.sql
2023-06-25 01:29:38.245489 (MainThread): Parsing macros\materializations\helpers.sql
2023-06-25 01:29:38.250989 (MainThread): Parsing macros\materializations\common\merge.sql
2023-06-25 01:29:38.260488 (MainThread): Parsing macros\materializations\incremental\helpers.sql
2023-06-25 01:29:38.261988 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2023-06-25 01:29:38.266489 (MainThread): Parsing macros\materializations\seed\seed.sql
2023-06-25 01:29:38.282488 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2023-06-25 01:29:38.306989 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2023-06-25 01:29:38.308489 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2023-06-25 01:29:38.320489 (MainThread): Parsing macros\materializations\table\table.sql
2023-06-25 01:29:38.325488 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2023-06-25 01:29:38.329489 (MainThread): Parsing macros\materializations\view\view.sql
2023-06-25 01:29:38.333988 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2023-06-25 01:29:38.335489 (MainThread): Parsing macros\schema_tests\not_null.sql
2023-06-25 01:29:38.336490 (MainThread): Parsing macros\schema_tests\relationships.sql
2023-06-25 01:29:38.337488 (MainThread): Parsing macros\schema_tests\unique.sql
2023-06-25 01:29:38.338489 (MainThread): Parsing macros\adapters.sql
2023-06-25 01:29:38.351488 (MainThread): Parsing macros\catalog.sql
2023-06-25 01:29:38.352989 (MainThread): Parsing macros\relations.sql
2023-06-25 01:29:38.353988 (MainThread): Parsing macros\materializations\snapshot_merge.sql
2023-06-25 01:29:38.366989 (MainThread): Partial parsing not enabled
2023-06-25 01:29:38.385488 (MainThread): Acquiring new postgres connection "model.transform_data.transform_data".
2023-06-25 01:29:38.385488 (MainThread): Opening a new connection, currently in state init
2023-06-25 01:29:38.594989 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:29:38.594989 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:29:38.594989 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:29:38.594989 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:29:38.594989 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:29:38.595489 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:29:38.595489 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:29:38.625989 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:29:38.625989 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:29:38.744020 (MainThread): scipy not found, skipping conversion test.
2023-06-25 01:29:38.745020 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2023-06-25 01:29:38.745521 (MainThread): Found 1 model, 0 tests, 0 snapshots, 0 analyses, 127 macros, 0 operations, 0 seed files, 0 sources
2023-06-25 01:29:38.745992 (MainThread): 
2023-06-25 01:29:38.746528 (MainThread): Acquiring new postgres connection "master".
2023-06-25 01:29:38.746528 (MainThread): Opening a new connection, currently in state init
2023-06-25 01:29:38.750525 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_main_database".
2023-06-25 01:29:38.750525 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2023-06-25 01:29:38.805488 (ThreadPoolExecutor-0_0): Using postgres connection "list_main_database".
2023-06-25 01:29:38.805488 (ThreadPoolExecutor-0_0): On list_main_database: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "list_main_database"} */

    select distinct nspname from pg_namespace
  
2023-06-25 01:29:38.835488 (ThreadPoolExecutor-0_0): SQL status: SELECT 4 in 0.03 seconds
2023-06-25 01:29:38.840489 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_main_database_public".
2023-06-25 01:29:38.840489 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2023-06-25 01:29:38.841489 (ThreadPoolExecutor-1_0): Using postgres connection "list_main_database_public".
2023-06-25 01:29:38.841489 (ThreadPoolExecutor-1_0): On list_main_database_public: BEGIN
2023-06-25 01:29:38.870489 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.03 seconds
2023-06-25 01:29:38.870989 (ThreadPoolExecutor-1_0): Using postgres connection "list_main_database_public".
2023-06-25 01:29:38.870989 (ThreadPoolExecutor-1_0): On list_main_database_public: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "list_main_database_public"} */
select
      'main_database' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'main_database' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2023-06-25 01:29:38.873521 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2023-06-25 01:29:38.874490 (ThreadPoolExecutor-1_0): On list_main_database_public: ROLLBACK
2023-06-25 01:29:38.880523 (MainThread): Using postgres connection "master".
2023-06-25 01:29:38.880523 (MainThread): On master: BEGIN
2023-06-25 01:29:38.909989 (MainThread): SQL status: BEGIN in 0.03 seconds
2023-06-25 01:29:38.909989 (MainThread): Using postgres connection "master".
2023-06-25 01:29:38.909989 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2023-06-25 01:29:38.913488 (MainThread): SQL status: SELECT 0 in 0.00 seconds
2023-06-25 01:29:38.913989 (MainThread): On master: ROLLBACK
2023-06-25 01:29:38.913989 (MainThread): Using postgres connection "master".
2023-06-25 01:29:38.914489 (MainThread): On master: BEGIN
2023-06-25 01:29:38.914489 (MainThread): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:29:38.914489 (MainThread): On master: COMMIT
2023-06-25 01:29:38.914489 (MainThread): Using postgres connection "master".
2023-06-25 01:29:38.914489 (MainThread): On master: COMMIT
2023-06-25 01:29:38.914989 (MainThread): SQL status: COMMIT in 0.00 seconds
2023-06-25 01:29:38.914989 (MainThread): 21:29:38 | Concurrency: 1 threads (target='dev')
2023-06-25 01:29:38.915490 (MainThread): 21:29:38 | 
2023-06-25 01:29:38.916989 (Thread-1): Began running node model.transform_data.transform_data
2023-06-25 01:29:38.916989 (Thread-1): 21:29:38 | 1 of 1 START view model public.transform_data........................ [RUN]
2023-06-25 01:29:38.917490 (Thread-1): Acquiring new postgres connection "model.transform_data.transform_data".
2023-06-25 01:29:38.917490 (Thread-1): Opening a new connection, currently in state init
2023-06-25 01:29:38.917490 (Thread-1): Compiling model.transform_data.transform_data
2023-06-25 01:29:38.925488 (Thread-1): Writing injected SQL for node "model.transform_data.transform_data"
2023-06-25 01:29:38.926489 (Thread-1): finished collecting timing info
2023-06-25 01:29:38.946489 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:29:38.946489 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */
drop view if exists "main_database"."public"."transform_data__dbt_tmp" cascade
2023-06-25 01:29:38.974762 (Thread-1): SQL status: DROP VIEW in 0.03 seconds
2023-06-25 01:29:38.976291 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:29:38.976291 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */
drop view if exists "main_database"."public"."transform_data__dbt_backup" cascade
2023-06-25 01:29:38.976762 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2023-06-25 01:29:38.977292 (Thread-1): Writing runtime SQL for node "model.transform_data.transform_data"
2023-06-25 01:29:38.978264 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:29:38.978264 (Thread-1): On model.transform_data.transform_data: BEGIN
2023-06-25 01:29:38.978264 (Thread-1): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:29:38.978264 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:29:38.978763 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */

  create view "main_database"."public"."transform_data__dbt_tmp" as (
    INSERT INTO public.transactions ("address", "amount", "timestamp")
SELECT
  "address",
  "amount",
  "timestamp"
FROM
  public.transactions
WHERE
  "timestamp" > CURRENT_TIMESTAMP - INTERVAL '2 years';
  );

2023-06-25 01:29:38.978763 (Thread-1): Postgres error: syntax error at or near "INSERT"
LINE 4:     INSERT INTO public.transactions ("address", "amount", "t...
            ^

2023-06-25 01:29:38.978763 (Thread-1): On model.transform_data.transform_data: ROLLBACK
2023-06-25 01:29:38.979266 (Thread-1): finished collecting timing info
2023-06-25 01:29:38.979266 (Thread-1): Database Error in model transform_data (models\transformations\transform_data.sql)
  syntax error at or near "INSERT"
  LINE 4:     INSERT INTO public.transactions ("address", "amount", "t...
              ^
  compiled SQL at target\run\transform_data\transformations\transform_data.sql
Traceback (most recent call last):
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\postgres\connections.py", line 46, in exception_handler
    yield
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near "INSERT"
LINE 4:     INSERT INTO public.transactions ("address", "amount", "t...
            ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 223, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 166, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 268, in run
    return self.execute(compiled_node, manifest)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 450, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 60, in macro
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\base\impl.py", line 220, in execute
    fetch=fetch
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 116, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 82, in add_query
    return connection, cursor
  File "c:\users\me\appdata\local\programs\python\python37\lib\contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\postgres\connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model transform_data (models\transformations\transform_data.sql)
  syntax error at or near "INSERT"
  LINE 4:     INSERT INTO public.transactions ("address", "amount", "t...
              ^
  compiled SQL at target\run\transform_data\transformations\transform_data.sql
2023-06-25 01:29:38.980791 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'df247e40-abdb-4608-9fd9-41c5c60d015b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000259FD5A3B38>]}
2023-06-25 01:29:38.981292 (Thread-1): 21:29:38 | 1 of 1 ERROR creating view model public.transform_data............... [ERROR in 0.06s]
2023-06-25 01:29:38.981762 (Thread-1): Finished running node model.transform_data.transform_data
2023-06-25 01:29:39.025913 (MainThread): Using postgres connection "master".
2023-06-25 01:29:39.026413 (MainThread): On master: BEGIN
2023-06-25 01:29:39.027420 (MainThread): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:29:39.027913 (MainThread): On master: COMMIT
2023-06-25 01:29:39.027913 (MainThread): Using postgres connection "master".
2023-06-25 01:29:39.028384 (MainThread): On master: COMMIT
2023-06-25 01:29:39.029413 (MainThread): SQL status: COMMIT in 0.00 seconds
2023-06-25 01:29:39.030438 (MainThread): 21:29:39 | 
2023-06-25 01:29:39.031371 (MainThread): 21:29:39 | Finished running 1 view model in 0.28s.
2023-06-25 01:29:39.032384 (MainThread): Connection 'master' was left open.
2023-06-25 01:29:39.032934 (MainThread): On master: Close
2023-06-25 01:29:39.033412 (MainThread): Connection 'list_main_database' was left open.
2023-06-25 01:29:39.033913 (MainThread): On list_main_database: Close
2023-06-25 01:29:39.034412 (MainThread): Connection 'list_main_database_public' was left open.
2023-06-25 01:29:39.034915 (MainThread): On list_main_database_public: Close
2023-06-25 01:29:39.035877 (MainThread): Connection 'model.transform_data.transform_data' was left open.
2023-06-25 01:29:39.035877 (MainThread): On model.transform_data.transform_data: Close
2023-06-25 01:29:39.041405 (MainThread): 
2023-06-25 01:29:39.041859 (MainThread): Completed with 1 error and 0 warnings:
2023-06-25 01:29:39.041859 (MainThread): 
2023-06-25 01:29:39.042359 (MainThread): Database Error in model transform_data (models\transformations\transform_data.sql)
2023-06-25 01:29:39.042359 (MainThread):   syntax error at or near "INSERT"
2023-06-25 01:29:39.042859 (MainThread):   LINE 4:     INSERT INTO public.transactions ("address", "amount", "t...
2023-06-25 01:29:39.042859 (MainThread):               ^
2023-06-25 01:29:39.043359 (MainThread):   compiled SQL at target\run\transform_data\transformations\transform_data.sql
2023-06-25 01:29:39.043359 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2023-06-25 01:29:39.043359 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000259FDF1B3C8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000259D5AD19B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000259FDF8EA20>]}
2023-06-25 01:29:39.043859 (MainThread): Flushing usage events
2023-06-25 01:31:35.413379 (MainThread): Running with dbt=0.16.0
2023-06-25 01:31:35.447879 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='C:\\Users\\Me\\.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target='dev', test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2023-06-25 01:31:35.447879 (MainThread): Tracking: tracking
2023-06-25 01:31:35.448879 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D357E9A2E8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D357EB0CC0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D357EB0240>]}
2023-06-25 01:31:35.459879 (MainThread): Partial parsing not enabled
2023-06-25 01:31:35.462379 (MainThread): Parsing macros\core.sql
2023-06-25 01:31:35.465879 (MainThread): Parsing macros\adapters\common.sql
2023-06-25 01:31:35.497379 (MainThread): Parsing macros\etc\datetime.sql
2023-06-25 01:31:35.503879 (MainThread): Parsing macros\etc\get_custom_alias.sql
2023-06-25 01:31:35.504879 (MainThread): Parsing macros\etc\get_custom_database.sql
2023-06-25 01:31:35.505379 (MainThread): Parsing macros\etc\get_custom_schema.sql
2023-06-25 01:31:35.506879 (MainThread): Parsing macros\etc\get_relation_comment.sql
2023-06-25 01:31:35.508879 (MainThread): Parsing macros\etc\is_incremental.sql
2023-06-25 01:31:35.509879 (MainThread): Parsing macros\etc\query.sql
2023-06-25 01:31:35.510879 (MainThread): Parsing macros\materializations\helpers.sql
2023-06-25 01:31:35.516379 (MainThread): Parsing macros\materializations\common\merge.sql
2023-06-25 01:31:35.526379 (MainThread): Parsing macros\materializations\incremental\helpers.sql
2023-06-25 01:31:35.527379 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2023-06-25 01:31:35.532379 (MainThread): Parsing macros\materializations\seed\seed.sql
2023-06-25 01:31:35.547879 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2023-06-25 01:31:35.572379 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2023-06-25 01:31:35.573879 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2023-06-25 01:31:35.586379 (MainThread): Parsing macros\materializations\table\table.sql
2023-06-25 01:31:35.591379 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2023-06-25 01:31:35.594879 (MainThread): Parsing macros\materializations\view\view.sql
2023-06-25 01:31:35.599879 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2023-06-25 01:31:35.601379 (MainThread): Parsing macros\schema_tests\not_null.sql
2023-06-25 01:31:35.601879 (MainThread): Parsing macros\schema_tests\relationships.sql
2023-06-25 01:31:35.602879 (MainThread): Parsing macros\schema_tests\unique.sql
2023-06-25 01:31:35.604379 (MainThread): Parsing macros\adapters.sql
2023-06-25 01:31:35.616879 (MainThread): Parsing macros\catalog.sql
2023-06-25 01:31:35.618879 (MainThread): Parsing macros\relations.sql
2023-06-25 01:31:35.619879 (MainThread): Parsing macros\materializations\snapshot_merge.sql
2023-06-25 01:31:35.632379 (MainThread): Partial parsing not enabled
2023-06-25 01:31:35.650879 (MainThread): Acquiring new postgres connection "model.transform_data.transform_data".
2023-06-25 01:31:35.650879 (MainThread): Opening a new connection, currently in state init
2023-06-25 01:31:35.860379 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:31:35.860879 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:31:35.860879 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:31:35.860879 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:31:35.860879 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:31:35.860879 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:31:35.860879 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:31:35.892379 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:31:35.892379 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:31:36.011879 (MainThread): scipy not found, skipping conversion test.
2023-06-25 01:31:36.012879 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2023-06-25 01:31:36.012879 (MainThread): Found 1 model, 0 tests, 0 snapshots, 0 analyses, 127 macros, 0 operations, 0 seed files, 0 sources
2023-06-25 01:31:36.013879 (MainThread): 
2023-06-25 01:31:36.013879 (MainThread): Acquiring new postgres connection "master".
2023-06-25 01:31:36.014379 (MainThread): Opening a new connection, currently in state init
2023-06-25 01:31:36.017880 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_main_database".
2023-06-25 01:31:36.017880 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2023-06-25 01:31:36.073879 (ThreadPoolExecutor-0_0): Using postgres connection "list_main_database".
2023-06-25 01:31:36.074380 (ThreadPoolExecutor-0_0): On list_main_database: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "list_main_database"} */

    select distinct nspname from pg_namespace
  
2023-06-25 01:31:36.104896 (ThreadPoolExecutor-0_0): SQL status: SELECT 4 in 0.03 seconds
2023-06-25 01:31:36.110149 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_main_database_public".
2023-06-25 01:31:36.110650 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2023-06-25 01:31:36.111149 (ThreadPoolExecutor-1_0): Using postgres connection "list_main_database_public".
2023-06-25 01:31:36.111651 (ThreadPoolExecutor-1_0): On list_main_database_public: BEGIN
2023-06-25 01:31:36.140147 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.03 seconds
2023-06-25 01:31:36.140147 (ThreadPoolExecutor-1_0): Using postgres connection "list_main_database_public".
2023-06-25 01:31:36.140659 (ThreadPoolExecutor-1_0): On list_main_database_public: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "list_main_database_public"} */
select
      'main_database' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'main_database' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2023-06-25 01:31:36.143149 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2023-06-25 01:31:36.144149 (ThreadPoolExecutor-1_0): On list_main_database_public: ROLLBACK
2023-06-25 01:31:36.150119 (MainThread): Using postgres connection "master".
2023-06-25 01:31:36.150119 (MainThread): On master: BEGIN
2023-06-25 01:31:36.179491 (MainThread): SQL status: BEGIN in 0.03 seconds
2023-06-25 01:31:36.179491 (MainThread): Using postgres connection "master".
2023-06-25 01:31:36.179491 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2023-06-25 01:31:36.183397 (MainThread): SQL status: SELECT 0 in 0.00 seconds
2023-06-25 01:31:36.183902 (MainThread): On master: ROLLBACK
2023-06-25 01:31:36.184212 (MainThread): Using postgres connection "master".
2023-06-25 01:31:36.184212 (MainThread): On master: BEGIN
2023-06-25 01:31:36.184212 (MainThread): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:31:36.184716 (MainThread): On master: COMMIT
2023-06-25 01:31:36.184716 (MainThread): Using postgres connection "master".
2023-06-25 01:31:36.184716 (MainThread): On master: COMMIT
2023-06-25 01:31:36.184716 (MainThread): SQL status: COMMIT in 0.00 seconds
2023-06-25 01:31:36.185216 (MainThread): 21:31:36 | Concurrency: 1 threads (target='dev')
2023-06-25 01:31:36.185216 (MainThread): 21:31:36 | 
2023-06-25 01:31:36.187216 (Thread-1): Began running node model.transform_data.transform_data
2023-06-25 01:31:36.187216 (Thread-1): 21:31:36 | 1 of 1 START view model public.transform_data........................ [RUN]
2023-06-25 01:31:36.187715 (Thread-1): Acquiring new postgres connection "model.transform_data.transform_data".
2023-06-25 01:31:36.187715 (Thread-1): Opening a new connection, currently in state init
2023-06-25 01:31:36.187715 (Thread-1): Compiling model.transform_data.transform_data
2023-06-25 01:31:36.195715 (Thread-1): Writing injected SQL for node "model.transform_data.transform_data"
2023-06-25 01:31:36.196215 (Thread-1): finished collecting timing info
2023-06-25 01:31:36.216216 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:31:36.216715 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */
drop view if exists "main_database"."public"."transform_data__dbt_tmp" cascade
2023-06-25 01:31:36.248071 (Thread-1): SQL status: DROP VIEW in 0.03 seconds
2023-06-25 01:31:36.250071 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:31:36.250071 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */
drop view if exists "main_database"."public"."transform_data__dbt_backup" cascade
2023-06-25 01:31:36.250071 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2023-06-25 01:31:36.251071 (Thread-1): Writing runtime SQL for node "model.transform_data.transform_data"
2023-06-25 01:31:36.251571 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:31:36.251571 (Thread-1): On model.transform_data.transform_data: BEGIN
2023-06-25 01:31:36.252071 (Thread-1): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:31:36.252071 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:31:36.252071 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */

  create view "main_database"."public"."transform_data__dbt_tmp" as (
    INSERT INTO public.transactions ("address", "amount", "timestamp")
SELECT
  "address",
  "amount",
  "timestamp"
FROM
  public.transactions
WHERE
  "timestamp" > CURRENT_TIMESTAMP - INTERVAL '2 years';
  );

2023-06-25 01:31:36.252571 (Thread-1): Postgres error: syntax error at or near "INSERT"
LINE 4:     INSERT INTO public.transactions ("address", "amount", "t...
            ^

2023-06-25 01:31:36.252571 (Thread-1): On model.transform_data.transform_data: ROLLBACK
2023-06-25 01:31:36.252571 (Thread-1): finished collecting timing info
2023-06-25 01:31:36.253072 (Thread-1): Database Error in model transform_data (models\transformations\transform_data.sql)
  syntax error at or near "INSERT"
  LINE 4:     INSERT INTO public.transactions ("address", "amount", "t...
              ^
  compiled SQL at target\run\transform_data\transformations\transform_data.sql
Traceback (most recent call last):
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\postgres\connections.py", line 46, in exception_handler
    yield
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near "INSERT"
LINE 4:     INSERT INTO public.transactions ("address", "amount", "t...
            ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 223, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 166, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 268, in run
    return self.execute(compiled_node, manifest)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 450, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 60, in macro
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\base\impl.py", line 220, in execute
    fetch=fetch
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 116, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 82, in add_query
    return connection, cursor
  File "c:\users\me\appdata\local\programs\python\python37\lib\contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\postgres\connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model transform_data (models\transformations\transform_data.sql)
  syntax error at or near "INSERT"
  LINE 4:     INSERT INTO public.transactions ("address", "amount", "t...
              ^
  compiled SQL at target\run\transform_data\transformations\transform_data.sql
2023-06-25 01:31:36.254571 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '38925d38-1be6-4168-8dac-12afc794e62d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D30052AA20>]}
2023-06-25 01:31:36.254571 (Thread-1): 21:31:36 | 1 of 1 ERROR creating view model public.transform_data............... [ERROR in 0.07s]
2023-06-25 01:31:36.255571 (Thread-1): Finished running node model.transform_data.transform_data
2023-06-25 01:31:36.288923 (MainThread): Using postgres connection "master".
2023-06-25 01:31:36.289388 (MainThread): On master: BEGIN
2023-06-25 01:31:36.289883 (MainThread): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:31:36.290416 (MainThread): On master: COMMIT
2023-06-25 01:31:36.290916 (MainThread): Using postgres connection "master".
2023-06-25 01:31:36.291416 (MainThread): On master: COMMIT
2023-06-25 01:31:36.292417 (MainThread): SQL status: COMMIT in 0.00 seconds
2023-06-25 01:31:36.293420 (MainThread): 21:31:36 | 
2023-06-25 01:31:36.293865 (MainThread): 21:31:36 | Finished running 1 view model in 0.28s.
2023-06-25 01:31:36.293865 (MainThread): Connection 'master' was left open.
2023-06-25 01:31:36.293865 (MainThread): On master: Close
2023-06-25 01:31:36.293865 (MainThread): Connection 'list_main_database' was left open.
2023-06-25 01:31:36.293865 (MainThread): On list_main_database: Close
2023-06-25 01:31:36.294397 (MainThread): Connection 'list_main_database_public' was left open.
2023-06-25 01:31:36.294397 (MainThread): On list_main_database_public: Close
2023-06-25 01:31:36.294397 (MainThread): Connection 'model.transform_data.transform_data' was left open.
2023-06-25 01:31:36.294397 (MainThread): On model.transform_data.transform_data: Close
2023-06-25 01:31:36.296896 (MainThread): 
2023-06-25 01:31:36.296896 (MainThread): Completed with 1 error and 0 warnings:
2023-06-25 01:31:36.297400 (MainThread): 
2023-06-25 01:31:36.297400 (MainThread): Database Error in model transform_data (models\transformations\transform_data.sql)
2023-06-25 01:31:36.297899 (MainThread):   syntax error at or near "INSERT"
2023-06-25 01:31:36.297899 (MainThread):   LINE 4:     INSERT INTO public.transactions ("address", "amount", "t...
2023-06-25 01:31:36.298399 (MainThread):               ^
2023-06-25 01:31:36.298399 (MainThread):   compiled SQL at target\run\transform_data\transformations\transform_data.sql
2023-06-25 01:31:36.298899 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2023-06-25 01:31:36.298899 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D30045B8D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D3580D6D30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D30054FE48>]}
2023-06-25 01:31:36.298899 (MainThread): Flushing usage events
2023-06-25 01:32:28.892482 (MainThread): Running with dbt=0.16.0
2023-06-25 01:32:28.926482 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='C:\\Users\\Me\\.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2023-06-25 01:32:28.926982 (MainThread): Tracking: tracking
2023-06-25 01:32:28.927982 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000143F94E1860>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000143F94E1CC0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000143F94E9A58>]}
2023-06-25 01:32:28.939482 (MainThread): Partial parsing not enabled
2023-06-25 01:32:28.941482 (MainThread): Parsing macros\core.sql
2023-06-25 01:32:28.944981 (MainThread): Parsing macros\adapters\common.sql
2023-06-25 01:32:28.976481 (MainThread): Parsing macros\etc\datetime.sql
2023-06-25 01:32:28.982982 (MainThread): Parsing macros\etc\get_custom_alias.sql
2023-06-25 01:32:28.983981 (MainThread): Parsing macros\etc\get_custom_database.sql
2023-06-25 01:32:28.984481 (MainThread): Parsing macros\etc\get_custom_schema.sql
2023-06-25 01:32:28.986482 (MainThread): Parsing macros\etc\get_relation_comment.sql
2023-06-25 01:32:28.987982 (MainThread): Parsing macros\etc\is_incremental.sql
2023-06-25 01:32:28.988982 (MainThread): Parsing macros\etc\query.sql
2023-06-25 01:32:28.989981 (MainThread): Parsing macros\materializations\helpers.sql
2023-06-25 01:32:28.995981 (MainThread): Parsing macros\materializations\common\merge.sql
2023-06-25 01:32:29.005482 (MainThread): Parsing macros\materializations\incremental\helpers.sql
2023-06-25 01:32:29.006982 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2023-06-25 01:32:29.011482 (MainThread): Parsing macros\materializations\seed\seed.sql
2023-06-25 01:32:29.026982 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2023-06-25 01:32:29.051481 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2023-06-25 01:32:29.052982 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2023-06-25 01:32:29.065482 (MainThread): Parsing macros\materializations\table\table.sql
2023-06-25 01:32:29.070481 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2023-06-25 01:32:29.074482 (MainThread): Parsing macros\materializations\view\view.sql
2023-06-25 01:32:29.078981 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2023-06-25 01:32:29.080482 (MainThread): Parsing macros\schema_tests\not_null.sql
2023-06-25 01:32:29.081482 (MainThread): Parsing macros\schema_tests\relationships.sql
2023-06-25 01:32:29.081982 (MainThread): Parsing macros\schema_tests\unique.sql
2023-06-25 01:32:29.083481 (MainThread): Parsing macros\adapters.sql
2023-06-25 01:32:29.096482 (MainThread): Parsing macros\catalog.sql
2023-06-25 01:32:29.098482 (MainThread): Parsing macros\relations.sql
2023-06-25 01:32:29.099481 (MainThread): Parsing macros\materializations\snapshot_merge.sql
2023-06-25 01:32:29.111982 (MainThread): Partial parsing not enabled
2023-06-25 01:32:29.130481 (MainThread): Acquiring new postgres connection "model.transform_data.transform_data".
2023-06-25 01:32:29.130481 (MainThread): Opening a new connection, currently in state init
2023-06-25 01:32:29.341482 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:32:29.341482 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:32:29.341482 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:32:29.341482 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:32:29.341482 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:32:29.341482 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:32:29.341482 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:32:29.372483 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:32:29.372983 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:32:29.493482 (MainThread): scipy not found, skipping conversion test.
2023-06-25 01:32:29.494482 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2023-06-25 01:32:29.494482 (MainThread): Found 1 model, 0 tests, 0 snapshots, 0 analyses, 127 macros, 0 operations, 0 seed files, 0 sources
2023-06-25 01:32:29.495484 (MainThread): 
2023-06-25 01:32:29.495983 (MainThread): Acquiring new postgres connection "master".
2023-06-25 01:32:29.495983 (MainThread): Opening a new connection, currently in state init
2023-06-25 01:32:29.499482 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_main_database".
2023-06-25 01:32:29.499482 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2023-06-25 01:32:29.556982 (ThreadPoolExecutor-0_0): Using postgres connection "list_main_database".
2023-06-25 01:32:29.556982 (ThreadPoolExecutor-0_0): On list_main_database: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "list_main_database"} */

    select distinct nspname from pg_namespace
  
2023-06-25 01:32:29.587981 (ThreadPoolExecutor-0_0): SQL status: SELECT 4 in 0.03 seconds
2023-06-25 01:32:29.592981 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_main_database_public".
2023-06-25 01:32:29.593483 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2023-06-25 01:32:29.593983 (ThreadPoolExecutor-1_0): Using postgres connection "list_main_database_public".
2023-06-25 01:32:29.594482 (ThreadPoolExecutor-1_0): On list_main_database_public: BEGIN
2023-06-25 01:32:29.622736 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.03 seconds
2023-06-25 01:32:29.622736 (ThreadPoolExecutor-1_0): Using postgres connection "list_main_database_public".
2023-06-25 01:32:29.623186 (ThreadPoolExecutor-1_0): On list_main_database_public: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "list_main_database_public"} */
select
      'main_database' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'main_database' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2023-06-25 01:32:29.625715 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2023-06-25 01:32:29.626714 (ThreadPoolExecutor-1_0): On list_main_database_public: ROLLBACK
2023-06-25 01:32:29.632684 (MainThread): Using postgres connection "master".
2023-06-25 01:32:29.632684 (MainThread): On master: BEGIN
2023-06-25 01:32:29.661754 (MainThread): SQL status: BEGIN in 0.03 seconds
2023-06-25 01:32:29.661754 (MainThread): Using postgres connection "master".
2023-06-25 01:32:29.661754 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2023-06-25 01:32:29.665548 (MainThread): SQL status: SELECT 0 in 0.00 seconds
2023-06-25 01:32:29.666053 (MainThread): On master: ROLLBACK
2023-06-25 01:32:29.666053 (MainThread): Using postgres connection "master".
2023-06-25 01:32:29.666053 (MainThread): On master: BEGIN
2023-06-25 01:32:29.666626 (MainThread): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:32:29.666626 (MainThread): On master: COMMIT
2023-06-25 01:32:29.666626 (MainThread): Using postgres connection "master".
2023-06-25 01:32:29.666626 (MainThread): On master: COMMIT
2023-06-25 01:32:29.667131 (MainThread): SQL status: COMMIT in 0.00 seconds
2023-06-25 01:32:29.667131 (MainThread): 21:32:29 | Concurrency: 1 threads (target='dev')
2023-06-25 01:32:29.667131 (MainThread): 21:32:29 | 
2023-06-25 01:32:29.669130 (Thread-1): Began running node model.transform_data.transform_data
2023-06-25 01:32:29.669130 (Thread-1): 21:32:29 | 1 of 1 START view model public.transform_data........................ [RUN]
2023-06-25 01:32:29.669629 (Thread-1): Acquiring new postgres connection "model.transform_data.transform_data".
2023-06-25 01:32:29.669629 (Thread-1): Opening a new connection, currently in state init
2023-06-25 01:32:29.669629 (Thread-1): Compiling model.transform_data.transform_data
2023-06-25 01:32:29.677630 (Thread-1): Writing injected SQL for node "model.transform_data.transform_data"
2023-06-25 01:32:29.678130 (Thread-1): finished collecting timing info
2023-06-25 01:32:29.698629 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:32:29.698629 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */
drop view if exists "main_database"."public"."transform_data__dbt_tmp" cascade
2023-06-25 01:32:29.728003 (Thread-1): SQL status: DROP VIEW in 0.03 seconds
2023-06-25 01:32:29.729502 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:32:29.730002 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */
drop view if exists "main_database"."public"."transform_data__dbt_backup" cascade
2023-06-25 01:32:29.730002 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2023-06-25 01:32:29.731002 (Thread-1): Writing runtime SQL for node "model.transform_data.transform_data"
2023-06-25 01:32:29.731502 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:32:29.731502 (Thread-1): On model.transform_data.transform_data: BEGIN
2023-06-25 01:32:29.732004 (Thread-1): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:32:29.732004 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:32:29.732004 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */

  create view "main_database"."public"."transform_data__dbt_tmp" as (
    INSERT INTO public.transactions ("address", "amount", "timestamp")
SELECT
  "address",
  "amount",
  "timestamp"
FROM
  public.transactions
WHERE
  "timestamp" > CURRENT_TIMESTAMP - INTERVAL '2 years';
  );

2023-06-25 01:32:29.732004 (Thread-1): Postgres error: syntax error at or near "INSERT"
LINE 4:     INSERT INTO public.transactions ("address", "amount", "t...
            ^

2023-06-25 01:32:29.732503 (Thread-1): On model.transform_data.transform_data: ROLLBACK
2023-06-25 01:32:29.732503 (Thread-1): finished collecting timing info
2023-06-25 01:32:29.733002 (Thread-1): Database Error in model transform_data (models\transformations\transform_data.sql)
  syntax error at or near "INSERT"
  LINE 4:     INSERT INTO public.transactions ("address", "amount", "t...
              ^
  compiled SQL at target\run\transform_data\transformations\transform_data.sql
Traceback (most recent call last):
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\postgres\connections.py", line 46, in exception_handler
    yield
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near "INSERT"
LINE 4:     INSERT INTO public.transactions ("address", "amount", "t...
            ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 223, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 166, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 268, in run
    return self.execute(compiled_node, manifest)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\node_runners.py", line 450, in execute
    result = MacroGenerator(materialization_macro, context)()
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 60, in macro
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 231, in __call__
    return self.call_macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\clients\jinja.py", line 161, in call_macro
    return macro(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\jinja2\runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\base\impl.py", line 220, in execute
    fetch=fetch
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 116, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\sql\connections.py", line 82, in add_query
    return connection, cursor
  File "c:\users\me\appdata\local\programs\python\python37\lib\contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "c:\users\me\appdata\local\programs\python\python37\lib\site-packages\dbt\adapters\postgres\connections.py", line 58, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model transform_data (models\transformations\transform_data.sql)
  syntax error at or near "INSERT"
  LINE 4:     INSERT INTO public.transactions ("address", "amount", "t...
              ^
  compiled SQL at target\run\transform_data\transformations\transform_data.sql
2023-06-25 01:32:29.734502 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6281f658-49a6-45a6-95f4-4177734b05f9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000143FFAD4518>]}
2023-06-25 01:32:29.734502 (Thread-1): 21:32:29 | 1 of 1 ERROR creating view model public.transform_data............... [ERROR in 0.06s]
2023-06-25 01:32:29.735503 (Thread-1): Finished running node model.transform_data.transform_data
2023-06-25 01:32:29.783768 (MainThread): Using postgres connection "master".
2023-06-25 01:32:29.784270 (MainThread): On master: BEGIN
2023-06-25 01:32:29.785269 (MainThread): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:32:29.785768 (MainThread): On master: COMMIT
2023-06-25 01:32:29.786268 (MainThread): Using postgres connection "master".
2023-06-25 01:32:29.786268 (MainThread): On master: COMMIT
2023-06-25 01:32:29.787272 (MainThread): SQL status: COMMIT in 0.00 seconds
2023-06-25 01:32:29.787272 (MainThread): 21:32:29 | 
2023-06-25 01:32:29.787735 (MainThread): 21:32:29 | Finished running 1 view model in 0.29s.
2023-06-25 01:32:29.787735 (MainThread): Connection 'master' was left open.
2023-06-25 01:32:29.788205 (MainThread): On master: Close
2023-06-25 01:32:29.788205 (MainThread): Connection 'list_main_database' was left open.
2023-06-25 01:32:29.788205 (MainThread): On list_main_database: Close
2023-06-25 01:32:29.788205 (MainThread): Connection 'list_main_database_public' was left open.
2023-06-25 01:32:29.788205 (MainThread): On list_main_database_public: Close
2023-06-25 01:32:29.788704 (MainThread): Connection 'model.transform_data.transform_data' was left open.
2023-06-25 01:32:29.788704 (MainThread): On model.transform_data.transform_data: Close
2023-06-25 01:32:29.791204 (MainThread): 
2023-06-25 01:32:29.791204 (MainThread): Completed with 1 error and 0 warnings:
2023-06-25 01:32:29.791704 (MainThread): 
2023-06-25 01:32:29.792204 (MainThread): Database Error in model transform_data (models\transformations\transform_data.sql)
2023-06-25 01:32:29.792204 (MainThread):   syntax error at or near "INSERT"
2023-06-25 01:32:29.792704 (MainThread):   LINE 4:     INSERT INTO public.transactions ("address", "amount", "t...
2023-06-25 01:32:29.792704 (MainThread):               ^
2023-06-25 01:32:29.792704 (MainThread):   compiled SQL at target\run\transform_data\transformations\transform_data.sql
2023-06-25 01:32:29.793204 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2023-06-25 01:32:29.793204 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000143FFA9D898>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000143F9657D30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000143FFAD4C18>]}
2023-06-25 01:32:29.793204 (MainThread): Flushing usage events
2023-06-25 01:33:10.433997 (MainThread): Running with dbt=0.16.0
2023-06-25 01:33:10.468497 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='C:\\Users\\Me\\.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2023-06-25 01:33:10.468998 (MainThread): Tracking: tracking
2023-06-25 01:33:10.469497 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A461D71CF8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A461D71DA0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A461D79E48>]}
2023-06-25 01:33:10.481997 (MainThread): Partial parsing not enabled
2023-06-25 01:33:10.484497 (MainThread): Parsing macros\core.sql
2023-06-25 01:33:10.487997 (MainThread): Parsing macros\adapters\common.sql
2023-06-25 01:33:10.519497 (MainThread): Parsing macros\etc\datetime.sql
2023-06-25 01:33:10.525997 (MainThread): Parsing macros\etc\get_custom_alias.sql
2023-06-25 01:33:10.526997 (MainThread): Parsing macros\etc\get_custom_database.sql
2023-06-25 01:33:10.527497 (MainThread): Parsing macros\etc\get_custom_schema.sql
2023-06-25 01:33:10.529497 (MainThread): Parsing macros\etc\get_relation_comment.sql
2023-06-25 01:33:10.530997 (MainThread): Parsing macros\etc\is_incremental.sql
2023-06-25 01:33:10.531997 (MainThread): Parsing macros\etc\query.sql
2023-06-25 01:33:10.532997 (MainThread): Parsing macros\materializations\helpers.sql
2023-06-25 01:33:10.538997 (MainThread): Parsing macros\materializations\common\merge.sql
2023-06-25 01:33:10.548497 (MainThread): Parsing macros\materializations\incremental\helpers.sql
2023-06-25 01:33:10.549997 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2023-06-25 01:33:10.554997 (MainThread): Parsing macros\materializations\seed\seed.sql
2023-06-25 01:33:10.570497 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2023-06-25 01:33:10.595497 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2023-06-25 01:33:10.596997 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2023-06-25 01:33:10.610997 (MainThread): Parsing macros\materializations\table\table.sql
2023-06-25 01:33:10.615997 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2023-06-25 01:33:10.620497 (MainThread): Parsing macros\materializations\view\view.sql
2023-06-25 01:33:10.624997 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2023-06-25 01:33:10.626497 (MainThread): Parsing macros\schema_tests\not_null.sql
2023-06-25 01:33:10.627497 (MainThread): Parsing macros\schema_tests\relationships.sql
2023-06-25 01:33:10.628497 (MainThread): Parsing macros\schema_tests\unique.sql
2023-06-25 01:33:10.629497 (MainThread): Parsing macros\adapters.sql
2023-06-25 01:33:10.642497 (MainThread): Parsing macros\catalog.sql
2023-06-25 01:33:10.644497 (MainThread): Parsing macros\relations.sql
2023-06-25 01:33:10.645497 (MainThread): Parsing macros\materializations\snapshot_merge.sql
2023-06-25 01:33:10.658997 (MainThread): Partial parsing not enabled
2023-06-25 01:33:10.677997 (MainThread): Acquiring new postgres connection "model.transform_data.transform_data".
2023-06-25 01:33:10.677997 (MainThread): Opening a new connection, currently in state init
2023-06-25 01:33:10.887997 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:33:10.887997 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:33:10.887997 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:33:10.888497 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:33:10.888497 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:33:10.888497 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:33:10.888497 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:33:10.918996 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:33:10.919497 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:33:11.041998 (MainThread): scipy not found, skipping conversion test.
2023-06-25 01:33:11.042998 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2023-06-25 01:33:11.043497 (MainThread): Found 1 model, 0 tests, 0 snapshots, 0 analyses, 127 macros, 0 operations, 0 seed files, 0 sources
2023-06-25 01:33:11.043998 (MainThread): 
2023-06-25 01:33:11.044499 (MainThread): Acquiring new postgres connection "master".
2023-06-25 01:33:11.044499 (MainThread): Opening a new connection, currently in state init
2023-06-25 01:33:11.048044 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_main_database".
2023-06-25 01:33:11.048044 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2023-06-25 01:33:11.102996 (ThreadPoolExecutor-0_0): Using postgres connection "list_main_database".
2023-06-25 01:33:11.102996 (ThreadPoolExecutor-0_0): On list_main_database: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "list_main_database"} */

    select distinct nspname from pg_namespace
  
2023-06-25 01:33:11.135497 (ThreadPoolExecutor-0_0): SQL status: SELECT 4 in 0.03 seconds
2023-06-25 01:33:11.140997 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_main_database_public".
2023-06-25 01:33:11.140997 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2023-06-25 01:33:11.141997 (ThreadPoolExecutor-1_0): Using postgres connection "list_main_database_public".
2023-06-25 01:33:11.141997 (ThreadPoolExecutor-1_0): On list_main_database_public: BEGIN
2023-06-25 01:33:11.171498 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.03 seconds
2023-06-25 01:33:11.171998 (ThreadPoolExecutor-1_0): Using postgres connection "list_main_database_public".
2023-06-25 01:33:11.171998 (ThreadPoolExecutor-1_0): On list_main_database_public: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "list_main_database_public"} */
select
      'main_database' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'main_database' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2023-06-25 01:33:11.174997 (ThreadPoolExecutor-1_0): SQL status: SELECT 1 in 0.00 seconds
2023-06-25 01:33:11.175997 (ThreadPoolExecutor-1_0): On list_main_database_public: ROLLBACK
2023-06-25 01:33:11.181497 (MainThread): Using postgres connection "master".
2023-06-25 01:33:11.181497 (MainThread): On master: BEGIN
2023-06-25 01:33:11.212498 (MainThread): SQL status: BEGIN in 0.03 seconds
2023-06-25 01:33:11.212498 (MainThread): Using postgres connection "master".
2023-06-25 01:33:11.212498 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2023-06-25 01:33:11.215998 (MainThread): SQL status: SELECT 0 in 0.00 seconds
2023-06-25 01:33:11.216497 (MainThread): On master: ROLLBACK
2023-06-25 01:33:11.216997 (MainThread): Using postgres connection "master".
2023-06-25 01:33:11.216997 (MainThread): On master: BEGIN
2023-06-25 01:33:11.217498 (MainThread): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:33:11.217498 (MainThread): On master: COMMIT
2023-06-25 01:33:11.217498 (MainThread): Using postgres connection "master".
2023-06-25 01:33:11.217498 (MainThread): On master: COMMIT
2023-06-25 01:33:11.217498 (MainThread): SQL status: COMMIT in 0.00 seconds
2023-06-25 01:33:11.217998 (MainThread): 21:33:11 | Concurrency: 1 threads (target='dev')
2023-06-25 01:33:11.217998 (MainThread): 21:33:11 | 
2023-06-25 01:33:11.219998 (Thread-1): Began running node model.transform_data.transform_data
2023-06-25 01:33:11.219998 (Thread-1): 21:33:11 | 1 of 1 START view model public.transform_data........................ [RUN]
2023-06-25 01:33:11.220548 (Thread-1): Acquiring new postgres connection "model.transform_data.transform_data".
2023-06-25 01:33:11.220548 (Thread-1): Opening a new connection, currently in state init
2023-06-25 01:33:11.220548 (Thread-1): Compiling model.transform_data.transform_data
2023-06-25 01:33:11.228526 (Thread-1): Writing injected SQL for node "model.transform_data.transform_data"
2023-06-25 01:33:11.229500 (Thread-1): finished collecting timing info
2023-06-25 01:33:11.249496 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:33:11.249496 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */
drop view if exists "main_database"."public"."transform_data__dbt_tmp" cascade
2023-06-25 01:33:11.278997 (Thread-1): SQL status: DROP VIEW in 0.03 seconds
2023-06-25 01:33:11.280498 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:33:11.280498 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */
drop view if exists "main_database"."public"."transform_data__dbt_backup" cascade
2023-06-25 01:33:11.281027 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2023-06-25 01:33:11.282026 (Thread-1): Writing runtime SQL for node "model.transform_data.transform_data"
2023-06-25 01:33:11.282499 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:33:11.282499 (Thread-1): On model.transform_data.transform_data: BEGIN
2023-06-25 01:33:11.282998 (Thread-1): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:33:11.282998 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:33:11.282998 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */

  create view "main_database"."public"."transform_data__dbt_tmp" as (
    SELECT
  address,
  amount,
  timestamp
FROM
  public.transactions
WHERE
  timestamp > CURRENT_TIMESTAMP - INTERVAL '2 years'
  );

2023-06-25 01:33:11.284998 (Thread-1): SQL status: CREATE VIEW in 0.00 seconds
2023-06-25 01:33:11.285996 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:33:11.286496 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */
alter table "main_database"."public"."transform_data__dbt_tmp" rename to "transform_data"
2023-06-25 01:33:11.286496 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2023-06-25 01:33:11.287029 (Thread-1): On model.transform_data.transform_data: COMMIT
2023-06-25 01:33:11.287029 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:33:11.287498 (Thread-1): On model.transform_data.transform_data: COMMIT
2023-06-25 01:33:11.287498 (Thread-1): SQL status: COMMIT in 0.00 seconds
2023-06-25 01:33:11.288496 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:33:11.288996 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */
drop view if exists "main_database"."public"."transform_data__dbt_backup" cascade
2023-06-25 01:33:11.288996 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2023-06-25 01:33:11.290496 (Thread-1): finished collecting timing info
2023-06-25 01:33:11.290996 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '79a52dfa-b838-4244-b48d-1a8c88ea0378', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A40A422208>]}
2023-06-25 01:33:11.290996 (Thread-1): 21:33:11 | 1 of 1 OK created view model public.transform_data................... [CREATE VIEW in 0.07s]
2023-06-25 01:33:11.291496 (Thread-1): Finished running node model.transform_data.transform_data
2023-06-25 01:33:11.329500 (MainThread): Using postgres connection "master".
2023-06-25 01:33:11.329500 (MainThread): On master: BEGIN
2023-06-25 01:33:11.329500 (MainThread): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:33:11.329998 (MainThread): On master: COMMIT
2023-06-25 01:33:11.329998 (MainThread): Using postgres connection "master".
2023-06-25 01:33:11.329998 (MainThread): On master: COMMIT
2023-06-25 01:33:11.329998 (MainThread): SQL status: COMMIT in 0.00 seconds
2023-06-25 01:33:11.330498 (MainThread): 21:33:11 | 
2023-06-25 01:33:11.330498 (MainThread): 21:33:11 | Finished running 1 view model in 0.29s.
2023-06-25 01:33:11.330997 (MainThread): Connection 'master' was left open.
2023-06-25 01:33:11.330997 (MainThread): On master: Close
2023-06-25 01:33:11.330997 (MainThread): Connection 'list_main_database' was left open.
2023-06-25 01:33:11.330997 (MainThread): On list_main_database: Close
2023-06-25 01:33:11.330997 (MainThread): Connection 'list_main_database_public' was left open.
2023-06-25 01:33:11.330997 (MainThread): On list_main_database_public: Close
2023-06-25 01:33:11.331497 (MainThread): Connection 'model.transform_data.transform_data' was left open.
2023-06-25 01:33:11.331497 (MainThread): On model.transform_data.transform_data: Close
2023-06-25 01:33:11.333997 (MainThread): 
2023-06-25 01:33:11.333997 (MainThread): Completed successfully
2023-06-25 01:33:11.334497 (MainThread): 
Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2023-06-25 01:33:11.334497 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A40A3A7E10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A40A3A7D68>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A461EEA198>]}
2023-06-25 01:33:11.334497 (MainThread): Flushing usage events
2023-06-25 01:33:14.101290 (MainThread): Running with dbt=0.16.0
2023-06-25 01:33:14.134821 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='C:\\Users\\Me\\.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target='dev', test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2023-06-25 01:33:14.135320 (MainThread): Tracking: tracking
2023-06-25 01:33:14.136322 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AAE9DA0B38>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AAE9DA06D8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AAE9DA8E48>]}
2023-06-25 01:33:14.147791 (MainThread): Partial parsing not enabled
2023-06-25 01:33:14.149790 (MainThread): Parsing macros\core.sql
2023-06-25 01:33:14.153290 (MainThread): Parsing macros\adapters\common.sql
2023-06-25 01:33:14.184290 (MainThread): Parsing macros\etc\datetime.sql
2023-06-25 01:33:14.191290 (MainThread): Parsing macros\etc\get_custom_alias.sql
2023-06-25 01:33:14.191790 (MainThread): Parsing macros\etc\get_custom_database.sql
2023-06-25 01:33:14.192790 (MainThread): Parsing macros\etc\get_custom_schema.sql
2023-06-25 01:33:14.194290 (MainThread): Parsing macros\etc\get_relation_comment.sql
2023-06-25 01:33:14.195790 (MainThread): Parsing macros\etc\is_incremental.sql
2023-06-25 01:33:14.197290 (MainThread): Parsing macros\etc\query.sql
2023-06-25 01:33:14.198290 (MainThread): Parsing macros\materializations\helpers.sql
2023-06-25 01:33:14.203790 (MainThread): Parsing macros\materializations\common\merge.sql
2023-06-25 01:33:14.213290 (MainThread): Parsing macros\materializations\incremental\helpers.sql
2023-06-25 01:33:14.214790 (MainThread): Parsing macros\materializations\incremental\incremental.sql
2023-06-25 01:33:14.219290 (MainThread): Parsing macros\materializations\seed\seed.sql
2023-06-25 01:33:14.234790 (MainThread): Parsing macros\materializations\snapshot\snapshot.sql
2023-06-25 01:33:14.259290 (MainThread): Parsing macros\materializations\snapshot\snapshot_merge.sql
2023-06-25 01:33:14.260790 (MainThread): Parsing macros\materializations\snapshot\strategies.sql
2023-06-25 01:33:14.273290 (MainThread): Parsing macros\materializations\table\table.sql
2023-06-25 01:33:14.278290 (MainThread): Parsing macros\materializations\view\create_or_replace_view.sql
2023-06-25 01:33:14.281790 (MainThread): Parsing macros\materializations\view\view.sql
2023-06-25 01:33:14.286790 (MainThread): Parsing macros\schema_tests\accepted_values.sql
2023-06-25 01:33:14.288290 (MainThread): Parsing macros\schema_tests\not_null.sql
2023-06-25 01:33:14.288790 (MainThread): Parsing macros\schema_tests\relationships.sql
2023-06-25 01:33:14.289790 (MainThread): Parsing macros\schema_tests\unique.sql
2023-06-25 01:33:14.291290 (MainThread): Parsing macros\adapters.sql
2023-06-25 01:33:14.303790 (MainThread): Parsing macros\catalog.sql
2023-06-25 01:33:14.305790 (MainThread): Parsing macros\relations.sql
2023-06-25 01:33:14.306790 (MainThread): Parsing macros\materializations\snapshot_merge.sql
2023-06-25 01:33:14.319290 (MainThread): Partial parsing not enabled
2023-06-25 01:33:14.337790 (MainThread): Acquiring new postgres connection "model.transform_data.transform_data".
2023-06-25 01:33:14.338290 (MainThread): Opening a new connection, currently in state init
2023-06-25 01:33:14.549337 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:33:14.549337 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:33:14.549337 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:33:14.549337 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:33:14.549337 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:33:14.549337 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:33:14.549337 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:33:14.580337 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:33:14.580837 (MainThread): distutils Version classes are deprecated. Use packaging.version instead.
2023-06-25 01:33:14.700837 (MainThread): scipy not found, skipping conversion test.
2023-06-25 01:33:14.701337 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2023-06-25 01:33:14.701837 (MainThread): Found 1 model, 0 tests, 0 snapshots, 0 analyses, 127 macros, 0 operations, 0 seed files, 0 sources
2023-06-25 01:33:14.702837 (MainThread): 
2023-06-25 01:33:14.702837 (MainThread): Acquiring new postgres connection "master".
2023-06-25 01:33:14.702837 (MainThread): Opening a new connection, currently in state init
2023-06-25 01:33:14.706838 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_main_database".
2023-06-25 01:33:14.706838 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2023-06-25 01:33:14.762336 (ThreadPoolExecutor-0_0): Using postgres connection "list_main_database".
2023-06-25 01:33:14.762336 (ThreadPoolExecutor-0_0): On list_main_database: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "list_main_database"} */

    select distinct nspname from pg_namespace
  
2023-06-25 01:33:14.792337 (ThreadPoolExecutor-0_0): SQL status: SELECT 4 in 0.03 seconds
2023-06-25 01:33:14.797838 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_main_database_public".
2023-06-25 01:33:14.797838 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2023-06-25 01:33:14.798836 (ThreadPoolExecutor-1_0): Using postgres connection "list_main_database_public".
2023-06-25 01:33:14.798836 (ThreadPoolExecutor-1_0): On list_main_database_public: BEGIN
2023-06-25 01:33:14.828338 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.03 seconds
2023-06-25 01:33:14.828338 (ThreadPoolExecutor-1_0): Using postgres connection "list_main_database_public".
2023-06-25 01:33:14.828338 (ThreadPoolExecutor-1_0): On list_main_database_public: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "list_main_database_public"} */
select
      'main_database' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'main_database' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2023-06-25 01:33:14.831337 (ThreadPoolExecutor-1_0): SQL status: SELECT 2 in 0.00 seconds
2023-06-25 01:33:14.832866 (ThreadPoolExecutor-1_0): On list_main_database_public: ROLLBACK
2023-06-25 01:33:14.838337 (MainThread): Using postgres connection "master".
2023-06-25 01:33:14.838337 (MainThread): On master: BEGIN
2023-06-25 01:33:14.867837 (MainThread): SQL status: BEGIN in 0.03 seconds
2023-06-25 01:33:14.867837 (MainThread): Using postgres connection "master".
2023-06-25 01:33:14.867837 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2023-06-25 01:33:14.871371 (MainThread): SQL status: SELECT 1 in 0.00 seconds
2023-06-25 01:33:14.872337 (MainThread): On master: ROLLBACK
2023-06-25 01:33:14.872837 (MainThread): Using postgres connection "master".
2023-06-25 01:33:14.872837 (MainThread): On master: BEGIN
2023-06-25 01:33:14.873338 (MainThread): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:33:14.873338 (MainThread): On master: COMMIT
2023-06-25 01:33:14.873338 (MainThread): Using postgres connection "master".
2023-06-25 01:33:14.873338 (MainThread): On master: COMMIT
2023-06-25 01:33:14.873338 (MainThread): SQL status: COMMIT in 0.00 seconds
2023-06-25 01:33:14.873837 (MainThread): 21:33:14 | Concurrency: 1 threads (target='dev')
2023-06-25 01:33:14.873837 (MainThread): 21:33:14 | 
2023-06-25 01:33:14.875838 (Thread-1): Began running node model.transform_data.transform_data
2023-06-25 01:33:14.875838 (Thread-1): 21:33:14 | 1 of 1 START view model public.transform_data........................ [RUN]
2023-06-25 01:33:14.876390 (Thread-1): Acquiring new postgres connection "model.transform_data.transform_data".
2023-06-25 01:33:14.876390 (Thread-1): Opening a new connection, currently in state init
2023-06-25 01:33:14.876390 (Thread-1): Compiling model.transform_data.transform_data
2023-06-25 01:33:14.884336 (Thread-1): Writing injected SQL for node "model.transform_data.transform_data"
2023-06-25 01:33:14.884836 (Thread-1): finished collecting timing info
2023-06-25 01:33:14.904836 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:33:14.905336 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */
drop view if exists "main_database"."public"."transform_data__dbt_tmp" cascade
2023-06-25 01:33:14.936535 (Thread-1): SQL status: DROP VIEW in 0.03 seconds
2023-06-25 01:33:14.938039 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:33:14.938539 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */
drop view if exists "main_database"."public"."transform_data__dbt_backup" cascade
2023-06-25 01:33:14.938539 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2023-06-25 01:33:14.939539 (Thread-1): Writing runtime SQL for node "model.transform_data.transform_data"
2023-06-25 01:33:14.940039 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:33:14.940039 (Thread-1): On model.transform_data.transform_data: BEGIN
2023-06-25 01:33:14.940541 (Thread-1): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:33:14.940541 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:33:14.940541 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */

  create view "main_database"."public"."transform_data__dbt_tmp" as (
    SELECT
  address,
  amount,
  timestamp
FROM
  public.transactions
WHERE
  timestamp > CURRENT_TIMESTAMP - INTERVAL '2 years'
  );

2023-06-25 01:33:14.942579 (Thread-1): SQL status: CREATE VIEW in 0.00 seconds
2023-06-25 01:33:14.944539 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:33:14.945039 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */
alter table "main_database"."public"."transform_data" rename to "transform_data__dbt_backup"
2023-06-25 01:33:14.945039 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2023-06-25 01:33:14.946539 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:33:14.946539 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */
alter table "main_database"."public"."transform_data__dbt_tmp" rename to "transform_data"
2023-06-25 01:33:14.947039 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2023-06-25 01:33:14.947540 (Thread-1): On model.transform_data.transform_data: COMMIT
2023-06-25 01:33:14.947540 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:33:14.947540 (Thread-1): On model.transform_data.transform_data: COMMIT
2023-06-25 01:33:14.948071 (Thread-1): SQL status: COMMIT in 0.00 seconds
2023-06-25 01:33:14.949072 (Thread-1): Using postgres connection "model.transform_data.transform_data".
2023-06-25 01:33:14.949072 (Thread-1): On model.transform_data.transform_data: /* {"app": "dbt", "dbt_version": "0.16.0", "profile_name": "dev", "target_name": "dev", "node_id": "model.transform_data.transform_data"} */
drop view if exists "main_database"."public"."transform_data__dbt_backup" cascade
2023-06-25 01:33:14.950039 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2023-06-25 01:33:14.951039 (Thread-1): finished collecting timing info
2023-06-25 01:33:14.951539 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ebe919f2-bd7f-4cfa-93f7-5ddb7634b477', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AAE9FB2710>]}
2023-06-25 01:33:14.952039 (Thread-1): 21:33:14 | 1 of 1 OK created view model public.transform_data................... [CREATE VIEW in 0.08s]
2023-06-25 01:33:14.952540 (Thread-1): Finished running node model.transform_data.transform_data
2023-06-25 01:33:14.975984 (MainThread): Using postgres connection "master".
2023-06-25 01:33:14.975984 (MainThread): On master: BEGIN
2023-06-25 01:33:14.976518 (MainThread): SQL status: BEGIN in 0.00 seconds
2023-06-25 01:33:14.976518 (MainThread): On master: COMMIT
2023-06-25 01:33:14.976518 (MainThread): Using postgres connection "master".
2023-06-25 01:33:14.976518 (MainThread): On master: COMMIT
2023-06-25 01:33:14.977002 (MainThread): SQL status: COMMIT in 0.00 seconds
2023-06-25 01:33:14.977002 (MainThread): 21:33:14 | 
2023-06-25 01:33:14.977002 (MainThread): 21:33:14 | Finished running 1 view model in 0.27s.
2023-06-25 01:33:14.977489 (MainThread): Connection 'master' was left open.
2023-06-25 01:33:14.977489 (MainThread): On master: Close
2023-06-25 01:33:14.977489 (MainThread): Connection 'list_main_database' was left open.
2023-06-25 01:33:14.977489 (MainThread): On list_main_database: Close
2023-06-25 01:33:14.978018 (MainThread): Connection 'list_main_database_public' was left open.
2023-06-25 01:33:14.978018 (MainThread): On list_main_database_public: Close
2023-06-25 01:33:14.978018 (MainThread): Connection 'model.transform_data.transform_data' was left open.
2023-06-25 01:33:14.978018 (MainThread): On model.transform_data.transform_data: Close
2023-06-25 01:33:14.980423 (MainThread): 
2023-06-25 01:33:14.980928 (MainThread): Completed successfully
2023-06-25 01:33:14.980928 (MainThread): 
Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2023-06-25 01:33:14.981428 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AAE9F71A90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AAE9F300B8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AA9239A198>]}
2023-06-25 01:33:14.981428 (MainThread): Flushing usage events
